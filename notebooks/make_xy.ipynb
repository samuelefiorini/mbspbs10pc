{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cPickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load matched samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              AVG_AGE SEX PINSTATE  SEQ_LENGTH  CLASS\n",
      "4106989574  49.937220   F  ACT+NSW         445      1\n",
      "3416643592  62.809322   F      QLD         471      1\n",
      "895586988   54.787709   F      QLD         127      1\n",
      "815892493   53.303030   M  VIC+TAS         131      1\n",
      "167198734   79.793750   F  ACT+NSW         319      1\n",
      "(4906, 5)\n"
     ]
    }
   ],
   "source": [
    "matched_df = pd.read_csv('../tmp/learning_tasks/METONLY_vs_METAFTER/matched_CEM_table.csv', header=0, index_col=0)\n",
    "print(matched_df.head())\n",
    "print(matched_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dump_files):\n",
    "    \"\"\"Extract sequences, extra info and patient id from dump pkl.\"\"\"\n",
    "    # Positive raw data load\n",
    "    raw_data = []\n",
    "    extra_info = []\n",
    "    indexes = []\n",
    "    for f in tqdm(dump_files, desc='Loading dump files'):\n",
    "        _tmp = pkl.load(open(os.path.join('..', 'tmp', f), 'rb'))\n",
    "        _raw_data, _extra_info = _tmp['raw_data'], _tmp['extra_info']\n",
    "        for k in _extra_info.index:\n",
    "            if len(_raw_data[k])>0: # Skip empty sequences\n",
    "                raw_data.append(_raw_data[k])\n",
    "                extra_info.append([_extra_info.loc[k]['SEX'], _extra_info.loc[k]['AGE']])\n",
    "                indexes.append(k)\n",
    "    return raw_data, extra_info, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_files = filter(lambda x: 'raw_data' in x, os.listdir('../tmp/'))\n",
    "positive_dump_files = filter(lambda x: 'METAFTER' in x, dump_files)\n",
    "negative_dump_files = filter(lambda x: 'METONLY' in x, dump_files)\n",
    "# negative_dump_files = filter(lambda x: 'METONLY' in x, dump_files)\n",
    "# positive_dump_files = filter(lambda x: 'class_1' in x, dump_files)\n",
    "# negative_dump_files = filter(lambda x: 'class_0' in x, dump_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequences should be like `['A', 8, 'M', 0, ...]` where letters are btos and numbers are weeks from one btos to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dump files: 100%|██████████| 6/6 [00:01<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2485, 'positive samples')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_raw_data, pos_extra_info, pos_id = load_data(positive_dump_files)\n",
    "print(len(pos_id), 'positive samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dump files: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20799, 'negative samples')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neg_raw_data, neg_extra_info, neg_id = load_data(negative_dump_files)\n",
    "print(len(neg_id), 'negative samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only the matched samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2453, 2)\n",
      "                                                          Seq  Class\n",
      "4106989574  I0G0T0I0G0T0P0P0P0P0G0T0P0P0I0T0T0G0G2E1P0P0P0...      1\n",
      "3416643592  T0G0P0P0P0P0T0G0T0G0T0G0T0G0T0G0T0T0G0S0G0T0T0...      1\n",
      "895586988   G0T0T0T1T0T0G0T2P0P0P0G0T0G0T0P0P0E0G0G0T0T1T0...      1\n",
      "815892493   T0G1T0G1I1O0G0T2G1G0T0G3G0T0T0G1G0T0T0G2G0T0T0...      1\n",
      "167198734   G0T0L0L0L0D0T0G0T0P0L0H0P0T0T0T0G0T0G0G0G2P0G0...      1\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data=pos_raw_data, index=pos_id, columns=['Seq'])\n",
    "df1 = pd.merge(matched_df[matched_df['CLASS'] == 1], df1, left_index=True, right_index=True, how='left')[['Seq']]\n",
    "df1['Class'] = 1\n",
    "print(df1.shape)\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2453, 2)\n",
      "                                                          Seq  Class\n",
      "1729085487  I0T0G0I0G0T0I0T0G2T0G2T0G1T0T0G0T2T0G2E0T0G0T0...      0\n",
      "5718368392            T0G0G0T0G0T3T0G0T0G0G0P0P0P0G0P0G0G2T0G      0\n",
      "3394125964  T0G3T0G0P0P0P0G0T0P0P0T0G0T0G0G0T0E0G0T0P0P0H0...      0\n",
      "299098338   O0G0G0G2G0P0P0P0P0I0G0G0I0G2G0G0G0I1S0E0S0S0G0...      0\n",
      "4105928953  T0G1G0T0T0G0T0G1G0T1G0T0G0T0T0G1T0G0P0P0P0P0I0...      0\n"
     ]
    }
   ],
   "source": [
    "df0 = pd.DataFrame(data=neg_raw_data, index=neg_id, columns=['Seq'])\n",
    "df0 = pd.merge(matched_df[matched_df['CLASS'] == 0], df0, left_index=True, right_index=True, how='left')[['Seq']]\n",
    "df0['Class'] = 0\n",
    "print(df0.shape)\n",
    "print(df0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          Seq  Class\n",
      "4106989574  I0G0T0I0G0T0P0P0P0P0G0T0P0P0I0T0T0G0G2E1P0P0P0...      1\n",
      "3416643592  T0G0P0P0P0P0T0G0T0G0T0G0T0G0T0G0T0T0G0S0G0T0T0...      1\n",
      "895586988   G0T0T0T1T0T0G0T2P0P0P0G0T0G0T0P0P0E0G0G0T0T1T0...      1\n",
      "815892493   T0G1T0G1I1O0G0T2G1G0T0G3G0T0T0G1G0T0T0G2G0T0T0...      1\n",
      "167198734   G0T0L0L0L0D0T0G0T0P0L0H0P0T0T0T0G0T0G0G0G2P0G0...      1\n",
      "                                                          Seq  Class\n",
      "1285472189  G0T1G0T0T0G0I0T0G0G0T0E0G0P0P0G0T0P0P1T0G0S0P0...      0\n",
      "741023696   I0P0H0P0P0G0T1G0G0G0G0G0T0P0P0P0P3G0G0G0G0P0P0...      0\n",
      "2871513372  T0G0G0P0P0T0G0T1G0T0G0T1G0P0T0S0P1S0P0P0T0G0T1...      0\n",
      "939843565   E0S0T0G2E2P0P0P0P0E2T0G0P0P0P0P1D0T3P0P0P0P0P0...      0\n",
      "1816772590  P0P0P0P2T0G1G0T3E1O2T0G0P0P0P0P0T0G0G0T0T0G0G0...      0\n",
      "(4906, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat((df1, df0))\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../tmp/matched_sequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple assessment\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score,\n",
    "                             precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef,\n",
    "                             make_scorer)\n",
    "\n",
    "def roc_auc_scorer(estimator, X, y):\n",
    "    return roc_auc_score(y, estimator.predict_proba(X)[:,1])\n",
    "\n",
    "_metrics = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'ROC_AUC': roc_auc_scorer,\n",
    "            'Precision': make_scorer(precision_score),\n",
    "            'Recall': make_scorer(recall_score),\n",
    "            'F1': make_scorer(f1_score),\n",
    "            'MCC': make_scorer(matthews_corrcoef)}\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(analyzer='char',\n",
    "                                           ngram_range=[1, max_ngram],\n",
    "                                           max_features=max_features)),\n",
    "                 ('mdl', RandomForestClassifier(n_estimators=500,\n",
    "                                                max_features=0.01,\n",
    "                                                n_jobs=-1))])\n",
    "\n",
    "scores = cross_validate(pipe, df['Seq'], df['Class'], cv=5, scoring=_metrics)\n",
    "scores = pd.DataFrame(scores).transpose()\n",
    "scores[r'avg $\\pm$ std'] = [r'{:1.3f} $\\pm$ {:1.3f}'.format(m, s) for m,s in zip(np.mean(scores.values, axis=1), np.std(scores.values, axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>avg $\\pm$ std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>4.400229</td>\n",
       "      <td>4.063035</td>\n",
       "      <td>3.884362</td>\n",
       "      <td>3.885545</td>\n",
       "      <td>4.017691</td>\n",
       "      <td>4.050 $\\pm$ 0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>5.203311</td>\n",
       "      <td>6.101732</td>\n",
       "      <td>9.316240</td>\n",
       "      <td>9.189075</td>\n",
       "      <td>6.742716</td>\n",
       "      <td>7.311 $\\pm$ 1.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Accuracy</th>\n",
       "      <td>0.474542</td>\n",
       "      <td>0.470468</td>\n",
       "      <td>0.520367</td>\n",
       "      <td>0.487755</td>\n",
       "      <td>0.417347</td>\n",
       "      <td>0.474 $\\pm$ 0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_F1</th>\n",
       "      <td>0.515038</td>\n",
       "      <td>0.438445</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.364557</td>\n",
       "      <td>0.363434</td>\n",
       "      <td>0.425 $\\pm$ 0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MCC</th>\n",
       "      <td>-0.051642</td>\n",
       "      <td>-0.059451</td>\n",
       "      <td>0.042418</td>\n",
       "      <td>-0.026568</td>\n",
       "      <td>-0.167730</td>\n",
       "      <td>-0.053 $\\pm$ 0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Precision</th>\n",
       "      <td>0.478185</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.528249</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.400491</td>\n",
       "      <td>0.471 $\\pm$ 0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_ROC_AUC</th>\n",
       "      <td>0.440468</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>0.540036</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.360346</td>\n",
       "      <td>0.458 $\\pm$ 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Recall</th>\n",
       "      <td>0.558045</td>\n",
       "      <td>0.413442</td>\n",
       "      <td>0.380855</td>\n",
       "      <td>0.293878</td>\n",
       "      <td>0.332653</td>\n",
       "      <td>0.396 $\\pm$ 0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Accuracy</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.999490</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_F1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999745</td>\n",
       "      <td>1.000 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_MCC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_ROC_AUC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999833</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000 $\\pm$ 0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4  \\\n",
       "fit_time         4.400229  4.063035  3.884362  3.885545  4.017691   \n",
       "score_time       5.203311  6.101732  9.316240  9.189075  6.742716   \n",
       "test_Accuracy    0.474542  0.470468  0.520367  0.487755  0.417347   \n",
       "test_F1          0.515038  0.438445  0.442604  0.364557  0.363434   \n",
       "test_MCC        -0.051642 -0.059451  0.042418 -0.026568 -0.167730   \n",
       "test_Precision   0.478185  0.466667  0.528249  0.480000  0.400491   \n",
       "test_ROC_AUC     0.440468  0.483325  0.540036  0.463415  0.360346   \n",
       "test_Recall      0.558045  0.413442  0.380855  0.293878  0.332653   \n",
       "train_Accuracy   1.000000  0.999490  0.999490  0.999491  0.999745   \n",
       "train_F1         1.000000  0.999491  0.999491  0.999491  0.999745   \n",
       "train_MCC        1.000000  0.998981  0.998981  0.998982  0.999491   \n",
       "train_Precision  1.000000  0.998982  0.998982  0.998982  0.999491   \n",
       "train_ROC_AUC    1.000000  0.999833  0.999873  0.999865  1.000000   \n",
       "train_Recall     1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "\n",
       "                      avg $\\pm$ std  \n",
       "fit_time          4.050 $\\pm$ 0.189  \n",
       "score_time        7.311 $\\pm$ 1.660  \n",
       "test_Accuracy     0.474 $\\pm$ 0.033  \n",
       "test_F1           0.425 $\\pm$ 0.057  \n",
       "test_MCC         -0.053 $\\pm$ 0.068  \n",
       "test_Precision    0.471 $\\pm$ 0.041  \n",
       "test_ROC_AUC      0.458 $\\pm$ 0.059  \n",
       "test_Recall       0.396 $\\pm$ 0.091  \n",
       "train_Accuracy    1.000 $\\pm$ 0.000  \n",
       "train_F1          1.000 $\\pm$ 0.000  \n",
       "train_MCC         0.999 $\\pm$ 0.000  \n",
       "train_Precision   0.999 $\\pm$ 0.000  \n",
       "train_ROC_AUC     1.000 $\\pm$ 0.000  \n",
       "train_Recall      1.000 $\\pm$ 0.000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Tfidf\n",
      "Save dataset\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Tfidf representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "max_ngram = 6\n",
    "max_features = 100\n",
    "\n",
    "print('Creating Tfidf')\n",
    "tfidf = TfidfVectorizer(analyzer='char', ngram_range=[1, max_ngram], max_features=max_features)\n",
    "X = tfidf.fit_transform(df['Seq']).todense()\n",
    "\n",
    "# Feature names\n",
    "feat_names = tfidf.vocabulary_.keys()\n",
    "\n",
    "# Tfidf - DataFrame\n",
    "dfx = pd.DataFrame(data=X, index=df.index, columns=feat_names)\n",
    "dfy = pd.DataFrame(data=df['Class'], index=df.index, columns=['Class'])\n",
    "\n",
    "print('Save dataset')\n",
    "dfx.to_csv('Tfidf_{}-gram_data.csv'.format(max_ngram))\n",
    "dfy.to_csv('Tfidf_{}-gram_labels.csv'.format(max_ngram))\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max ngram: ', 1)\n",
      "Creating BOW...\n",
      "Save dataset\n",
      "done.\n",
      "('max ngram: ', 2)\n",
      "Creating BOW...\n",
      "Save dataset\n",
      "done.\n",
      "('max ngram: ', 3)\n",
      "Creating BOW...\n",
      "Save dataset\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Bag-of-words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create 3 data sets\n",
    "for max_ngram in [1, 2, 3]:\n",
    "    print('max ngram: ', max_ngram)\n",
    "    bow = CountVectorizer(analyzer='char', ngram_range=[1, max_ngram])\n",
    "    \n",
    "    print('Creating BOW...')\n",
    "    X = bow.fit_transform(df['Seq']).todense()\n",
    "    \n",
    "    # Feature names\n",
    "    feat_names = bow.vocabulary_.keys()\n",
    "    \n",
    "    # BOW - DataFrame\n",
    "    dfx = pd.DataFrame(data=X, index=df.index, columns=feat_names)\n",
    "    dfy = pd.DataFrame(data=df['Class'], index=df.index, columns=['Class'])\n",
    "    \n",
    "    print('Save dataset')\n",
    "    dfx.to_csv('BOW_{}-gram_data.csv'.format(max_ngram))\n",
    "    dfy.to_csv('BOW_{}-gram_labels.csv'.format(max_ngram))\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the desired BOW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4906, 100)\n"
     ]
    }
   ],
   "source": [
    "ngram=6\n",
    "\n",
    "# _dfx = pd.read_csv('../tmp/learning_tasks/METONLY_vs_METAFTER/BOW-datasets/BOW_{}-gram_data.csv'.format(ngram), header=0, index_col=0)\n",
    "# _dfy = pd.read_csv('../tmp/learning_tasks/METONLY_vs_METAFTER/BOW-datasets/BOW_{}-gram_labels.csv'.format(ngram), header=0, index_col=0)\n",
    "# _dfx = pd.read_csv('../tmp/learning_tasks/METONLY_vs_METAFTER/BOW-datasets/Tfidf_{}-gram_data.csv'.format(ngram), header=0, index_col=0)\n",
    "# _dfy = pd.read_csv('../tmp/learning_tasks/METONLY_vs_METAFTER/BOW-datasets/Tfidf_{}-gram_labels.csv'.format(ngram), header=0, index_col=0)\n",
    "\n",
    "_dfx = pd.read_csv('Tfidf_{}-gram_data.csv'.format(ngram), header=0, index_col=0)\n",
    "_dfy = pd.read_csv('Tfidf_{}-gram_labels.csv'.format(ngram), header=0, index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "X = _dfx.values\n",
    "y = _dfy.values\n",
    "feat_names = _dfx.columns\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple assessment\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score,\n",
    "                             precision_score, recall_score,\n",
    "                             f1_score, matthews_corrcoef,\n",
    "                             make_scorer)\n",
    "\n",
    "def roc_auc_scorer(estimator, X, y):\n",
    "    return roc_auc_score(y, estimator.predict_proba(X)[:,1])\n",
    "\n",
    "_metrics = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'ROC_AUC': roc_auc_scorer,\n",
    "            'Precision': make_scorer(precision_score),\n",
    "            'Recall': make_scorer(recall_score),\n",
    "            'F1': make_scorer(f1_score),\n",
    "            'MCC': make_scorer(matthews_corrcoef)}\n",
    "\n",
    "pipe = Pipeline([('pp', StandardScaler()),\n",
    "                 ('mdl', GradientBoostingClassifier(n_estimators=100))])\n",
    "\n",
    "scores = cross_validate(pipe, X, y, cv=5, scoring=_metrics, n_jobs=-1)\n",
    "scores = pd.DataFrame(scores).transpose()\n",
    "scores[r'avg $\\pm$ std'] = [r'{:1.3f} $\\pm$ {:1.3f}'.format(m, s) for m,s in zip(np.mean(scores.values, axis=1), np.std(scores.values, axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>avg $\\pm$ std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>3.139723</td>\n",
       "      <td>3.029330</td>\n",
       "      <td>2.957031</td>\n",
       "      <td>3.089540</td>\n",
       "      <td>3.110246</td>\n",
       "      <td>3.065 $\\pm$ 0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.027867</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.026022</td>\n",
       "      <td>0.025202</td>\n",
       "      <td>0.026 $\\pm$ 0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Accuracy</th>\n",
       "      <td>0.458248</td>\n",
       "      <td>0.509165</td>\n",
       "      <td>0.522403</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.413265</td>\n",
       "      <td>0.476 $\\pm$ 0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_F1</th>\n",
       "      <td>0.492366</td>\n",
       "      <td>0.494759</td>\n",
       "      <td>0.444970</td>\n",
       "      <td>0.362047</td>\n",
       "      <td>0.392819</td>\n",
       "      <td>0.437 $\\pm$ 0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_MCC</th>\n",
       "      <td>-0.084268</td>\n",
       "      <td>0.018360</td>\n",
       "      <td>0.046660</td>\n",
       "      <td>-0.046039</td>\n",
       "      <td>-0.173864</td>\n",
       "      <td>-0.048 $\\pm$ 0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Precision</th>\n",
       "      <td>0.463196</td>\n",
       "      <td>0.509719</td>\n",
       "      <td>0.531073</td>\n",
       "      <td>0.466238</td>\n",
       "      <td>0.407002</td>\n",
       "      <td>0.475 $\\pm$ 0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_ROC_AUC</th>\n",
       "      <td>0.436140</td>\n",
       "      <td>0.513106</td>\n",
       "      <td>0.536081</td>\n",
       "      <td>0.470516</td>\n",
       "      <td>0.352074</td>\n",
       "      <td>0.462 $\\pm$ 0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_Recall</th>\n",
       "      <td>0.525458</td>\n",
       "      <td>0.480652</td>\n",
       "      <td>0.382892</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.379592</td>\n",
       "      <td>0.413 $\\pm$ 0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Accuracy</th>\n",
       "      <td>0.774720</td>\n",
       "      <td>0.771407</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.777127</td>\n",
       "      <td>0.798268</td>\n",
       "      <td>0.780 $\\pm$ 0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_F1</th>\n",
       "      <td>0.750846</td>\n",
       "      <td>0.758936</td>\n",
       "      <td>0.764516</td>\n",
       "      <td>0.762551</td>\n",
       "      <td>0.800604</td>\n",
       "      <td>0.767 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_MCC</th>\n",
       "      <td>0.559815</td>\n",
       "      <td>0.545742</td>\n",
       "      <td>0.556533</td>\n",
       "      <td>0.558479</td>\n",
       "      <td>0.596700</td>\n",
       "      <td>0.563 $\\pm$ 0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Precision</th>\n",
       "      <td>0.839849</td>\n",
       "      <td>0.802729</td>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.815912</td>\n",
       "      <td>0.791439</td>\n",
       "      <td>0.812 $\\pm$ 0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_ROC_AUC</th>\n",
       "      <td>0.864836</td>\n",
       "      <td>0.859353</td>\n",
       "      <td>0.870713</td>\n",
       "      <td>0.857965</td>\n",
       "      <td>0.879520</td>\n",
       "      <td>0.866 $\\pm$ 0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Recall</th>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.719674</td>\n",
       "      <td>0.724771</td>\n",
       "      <td>0.715741</td>\n",
       "      <td>0.809985</td>\n",
       "      <td>0.730 $\\pm$ 0.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1         2         3         4  \\\n",
       "fit_time         3.139723  3.029330  2.957031  3.089540  3.110246   \n",
       "score_time       0.025618  0.027867  0.025506  0.026022  0.025202   \n",
       "test_Accuracy    0.458248  0.509165  0.522403  0.478571  0.413265   \n",
       "test_F1          0.492366  0.494759  0.444970  0.362047  0.392819   \n",
       "test_MCC        -0.084268  0.018360  0.046660 -0.046039 -0.173864   \n",
       "test_Precision   0.463196  0.509719  0.531073  0.466238  0.407002   \n",
       "test_ROC_AUC     0.436140  0.513106  0.536081  0.470516  0.352074   \n",
       "test_Recall      0.525458  0.480652  0.382892  0.295918  0.379592   \n",
       "train_Accuracy   0.774720  0.771407  0.776758  0.777127  0.798268   \n",
       "train_F1         0.750846  0.758936  0.764516  0.762551  0.800604   \n",
       "train_MCC        0.559815  0.545742  0.556533  0.558479  0.596700   \n",
       "train_Precision  0.839849  0.802729  0.808874  0.815912  0.791439   \n",
       "train_ROC_AUC    0.864836  0.859353  0.870713  0.857965  0.879520   \n",
       "train_Recall     0.678899  0.719674  0.724771  0.715741  0.809985   \n",
       "\n",
       "                      avg $\\pm$ std  \n",
       "fit_time          3.065 $\\pm$ 0.065  \n",
       "score_time        0.026 $\\pm$ 0.001  \n",
       "test_Accuracy     0.476 $\\pm$ 0.039  \n",
       "test_F1           0.437 $\\pm$ 0.053  \n",
       "test_MCC         -0.048 $\\pm$ 0.078  \n",
       "test_Precision    0.475 $\\pm$ 0.043  \n",
       "test_ROC_AUC      0.462 $\\pm$ 0.065  \n",
       "test_Recall       0.413 $\\pm$ 0.081  \n",
       "train_Accuracy    0.780 $\\pm$ 0.010  \n",
       "train_F1          0.767 $\\pm$ 0.017  \n",
       "train_MCC         0.563 $\\pm$ 0.017  \n",
       "train_Precision   0.812 $\\pm$ 0.016  \n",
       "train_ROC_AUC     0.866 $\\pm$ 0.008  \n",
       "train_Recall      0.730 $\\pm$ 0.043  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=500)\n",
    "_, _idx = next(sss.split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('pp', StandardScaler()),\n",
    "                 ('dr', Isomap(n_components=3))])\n",
    "\n",
    "pipe.fit(X)\n",
    "x_r = pipe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=300)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "xs = x_r[_idx, 0]\n",
    "ys = x_r[_idx, 1]\n",
    "zs = x_r[_idx, 2]\n",
    "ax.scatter(xs, ys, zs, c=y[_idx].ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
