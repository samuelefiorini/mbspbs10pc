{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samu/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/samu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from mbspbs10pc import mbs_online\n",
    "reload(mbs_online);\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv', header=0).rename({'Unnamed: 0': 'PIN'}, axis=1)[['PIN', 'CLASS']].set_index('PIN')\n",
    "data = pd.read_csv('../../tmp/raw_sequences.csv', header=0, index_col=0).loc[labels.index, 'seq']\n",
    "\n",
    "df = pd.DataFrame(columns=['Seq', 'Class', 'mbs_seq', 'times_seq'], index=data.index)\n",
    "\n",
    "df.loc[:, 'Seq'] = data\n",
    "df.loc[:, 'Class'] = labels['CLASS']\n",
    "\n",
    "for idx in df.index:\n",
    "    _tmp = df.loc[idx, 'Seq'].split(' ')\n",
    "    df.loc[idx, 'mbs_seq'] = ' '.join(_tmp[::2])\n",
    "    df.loc[idx, 'times_seq'] = ' '.join(_tmp[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Class</th>\n",
       "      <th>mbs_seq</th>\n",
       "      <th>times_seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568483</th>\n",
       "      <td>10990 0 23 1 725 0 10990 0 10990 0 10990 0 109...</td>\n",
       "      <td>1</td>\n",
       "      <td>10990 23 725 10990 10990 10990 10993 23 85311 ...</td>\n",
       "      <td>0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923748</th>\n",
       "      <td>66653 0 65070 0 66515 0 10962 0 105 0 56807 2 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>66653 65070 66515 10962 105 56807 10990 23 109...</td>\n",
       "      <td>0 0 0 0 0 2 0 1 2 0 0 0 0 0 0 0 0 0 0 0 1 2 1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035328</th>\n",
       "      <td>66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>66536 74995 66512 66551 66608 66716 66560 7392...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 1 2 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239386</th>\n",
       "      <td>10991 0 23 3 73928 0 66560 0 66515 0 66551 0 6...</td>\n",
       "      <td>1</td>\n",
       "      <td>10991 23 73928 66560 66515 66551 66536 2517 10...</td>\n",
       "      <td>0 3 0 0 0 0 0 0 1 0 0 0 0 1 3 0 0 0 0 0 0 2 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244533</th>\n",
       "      <td>10990 0 23 2 23 0 10990 0 73928 0 66500 0 6656...</td>\n",
       "      <td>1</td>\n",
       "      <td>10990 23 23 10990 73928 66500 66560 66551 23 1...</td>\n",
       "      <td>0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Seq  Class  \\\n",
       "PIN                                                                 \n",
       "568483   10990 0 23 1 725 0 10990 0 10990 0 10990 0 109...      1   \n",
       "923748   66653 0 65070 0 66515 0 10962 0 105 0 56807 2 ...      0   \n",
       "2035328  66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...      0   \n",
       "2239386  10991 0 23 3 73928 0 66560 0 66515 0 66551 0 6...      1   \n",
       "2244533  10990 0 23 2 23 0 10990 0 73928 0 66500 0 6656...      1   \n",
       "\n",
       "                                                   mbs_seq  \\\n",
       "PIN                                                          \n",
       "568483   10990 23 725 10990 10990 10990 10993 23 85311 ...   \n",
       "923748   66653 65070 66515 10962 105 56807 10990 23 109...   \n",
       "2035328  66536 74995 66512 66551 66608 66716 66560 7392...   \n",
       "2239386  10991 23 73928 66560 66515 66551 66536 2517 10...   \n",
       "2244533  10990 23 23 10990 73928 66500 66560 66551 23 1...   \n",
       "\n",
       "                                                 times_seq  \n",
       "PIN                                                         \n",
       "568483   0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ...  \n",
       "923748   0 0 0 0 0 2 0 1 2 0 0 0 0 0 0 0 0 0 0 0 1 2 1 ...  \n",
       "2035328  0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 1 2 0 0 0 0 0 0 ...  \n",
       "2239386  0 3 0 0 0 0 0 0 1 0 0 0 0 1 3 0 0 0 0 0 0 2 0 ...  \n",
       "2244533  0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773\n",
      "[65096, 65093, 65090]\n"
     ]
    }
   ],
   "source": [
    "# Define tokenizer object\n",
    "seq_tokenizer = Tokenizer(char_level=False, lower=False, split=' ')\n",
    "\n",
    "# Fit on corpus and extract tokenized sequences\n",
    "seq_tokenizer.fit_on_texts(df['mbs_seq'])\n",
    "mbs_tokens = map(int, seq_tokenizer.word_index.keys())\n",
    "print(len(mbs_tokens))\n",
    "print(mbs_tokens[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tokens from `item_map.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ../mbspbs10pc/data/item_map.tsv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e9dfe322495a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitem_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mbspbs10pc/data/item_map.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mitem_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samu/miniconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samu/miniconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samu/miniconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samu/miniconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samu/miniconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ../mbspbs10pc/data/item_map.tsv does not exist"
     ]
    }
   ],
   "source": [
    "item_map = pd.read_csv('../mbspbs10pc/data/item_map.tsv', sep='\\t', header=0, index_col=0)\n",
    "item_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = item_map.loc[mbs_tokens, 'Mapped_Item_Desc'].to_frame().dropna()\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_mapped_items_desc = {}\n",
    "for idx in df.index:\n",
    "    word_list = regexp_tokenizer.tokenize(df.loc[idx].values[0])  # tokenize\n",
    "    word_list = filter(lambda x: len(x)>3, word_list)  # remove short words \n",
    "    cleaned_mapped_items_desc[idx] = [word.lower() for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the GloVe word-embeddings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dir = '../glove6B/'\n",
    "D = 50\n",
    "# D = 100\n",
    "# D = 200\n",
    "# D = 300\n",
    "with open(os.path.join(glove_dir, 'glove.6B.{}d.txt'.format(D))) as f:\n",
    "    embeddings_index = {}\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this copes with descriptions like: \"3 or more tests described in item 73802\"\n",
    "\n",
    "embedding = {}\n",
    "for mbs_item in cleaned_mapped_items_desc.keys(): # for each mbs item\n",
    "    word_list = list(cleaned_mapped_items_desc[mbs_item]) # get the clean word list (copy)\n",
    "    tail = []  # buffer where to save all the tails\n",
    "    for word in word_list:\n",
    "        if word.isdigit() and int(word) in cleaned_mapped_items_desc:\n",
    "            tail.extend(cleaned_mapped_items_desc[int(word)])\n",
    "    word_list.extend(tail) # collapse all word in a single list\n",
    "    \n",
    "    embedding_vector = [] # and create the mebedding\n",
    "    for word in word_list:\n",
    "        if word in embeddings_index:\n",
    "            embedding_vector.append(embeddings_index[word])\n",
    "    if len(embedding_vector) == 0:\n",
    "        print('Dummy encoding for {}'.format(mbs_item))\n",
    "        embedding[mbs_item] = np.random.randn(D)\n",
    "    else:\n",
    "        embedding_vector = np.array(embedding_vector)\n",
    "        embedding[mbs_item] = np.mean(embedding_vector, axis=0) # average up all the vectors        \n",
    "embedding = pd.DataFrame.from_dict(embedding, orient='index')\n",
    "embedding = pd.DataFrame(Normalizer().fit_transform(embedding.values), # then finally normalize everything\n",
    "                         index=embedding.index)\n",
    "embedding.to_csv('../../tmp/embedding.{}d.csv'.format(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBS embedding viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimred = TSNE(n_components=3)\n",
    "# embedding_r = dimred.fit_transform(embedding.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(dpi=500)\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# # idx = np.random.randint(embedding_r.shape[0], size=(60,))\n",
    "# xx, yy, zz = embedding_r[idx, 0], embedding_r[idx, 1], embedding_r[idx, 2]\n",
    "\n",
    "# ax.scatter(xx, yy, zz)\n",
    "\n",
    "# for x, y, z, txt in zip(xx, yy, zz, embedding.index):\n",
    "#     ax.text(x, y, z, str(txt), zdir='y', fontsize=4)\n",
    "\n",
    "# ax.set_xlabel('x1')\n",
    "# ax.set_ylabel('x2')\n",
    "# ax.set_zlabel('x3');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
