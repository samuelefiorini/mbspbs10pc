{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from tangle.mbspbs10pc import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    \"\"\"Test set not returned on purpose.\"\"\"\n",
    "    \n",
    "    labelsfile = '../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv'\n",
    "    datafile = '../../tmp/item_days_raw_data_.pkl'\n",
    "    dataset = utils.load_data_labels(datafile, labelsfile)\n",
    "    padded_mbs_seq, padded_timespan_seq, _ = utils.tokenize(dataset)\n",
    "    maxlen = padded_mbs_seq.shape[1]\n",
    "\n",
    "    # Split in training, validation, test sets\n",
    "    tr_set, v_set, ts_set = utils.train_validation_test_split(\n",
    "        [padded_mbs_seq, padded_timespan_seq], dataset['Class'],\n",
    "        test_size=0.4, validation_size=0.1,\n",
    "        verbose=False, random_state0=1, random_state1=0)\n",
    "\n",
    "    x_train, y_train = tr_set[0], tr_set[1]\n",
    "    x_valid, y_valid = v_set[0], v_set[1]\n",
    "    \n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "def create_model(x_train, y_train, x_valid, y_valid):\n",
    "    from keras import optimizers as opt\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from keras.models import Model\n",
    "    from keras.regularizers import l2\n",
    "    from keras.layers import LSTM, Bidirectional, Dense, Dot, Dropout, LSTM\n",
    "    from keras.layers import Embedding, GlobalAveragePooling1D, Input, Multiply\n",
    "    from tangle.layers import TimespanGuidedNeuralAttention\n",
    "\n",
    "    # Hyperparameters\n",
    "    n_recurrent = {{choice([16, 32, 64, 128])}}\n",
    "    n_attention = {{choice([16, 32, 64, 128])}}\n",
    "    dr_rate_0 = {{uniform(0, 1)}}\n",
    "    n_dense = {{choice([16, 32, 64, 128])}}\n",
    "    dr_rate_1 = {{uniform(0, 1)}}\n",
    "    lr = {{uniform(1e-5, 1e-1)}}\n",
    "    embedding_trainable = {{choice([True, False])}}\n",
    "    batch_size = {{choice([64, 128, 256])}}\n",
    "    \n",
    "    # Channel 1: MBS\n",
    "    mbs_input = Input(shape=(250,), name='mbs_input')\n",
    "    e = Embedding(2774, 50, name='mbs_embedding')(mbs_input)\n",
    "    x1 = Bidirectional(LSTM(n_recurrent, return_sequences=True), name='mbs_lstm')(e)\n",
    "\n",
    "    # Channel 2: Timespans\n",
    "    timespan_input = Input(shape=(250, 1), name='timespan_input')\n",
    "    x2 = Bidirectional(LSTM(n_recurrent, return_sequences=True), name='timespan_lstm')(timespan_input)\n",
    "    \n",
    "    # Timespan-guided neural attention weights\n",
    "    alpha = TimespanGuidedNeuralAttention(n_attention, name='tangle_attention')([x1, x2])\n",
    "\n",
    "    # Combine channels to get contribution and context\n",
    "    c = Multiply(name='contribution')([alpha, x1])\n",
    "    x = Dot(axes=1, name='context')([c, e])\n",
    "\n",
    "    # Output\n",
    "    x = GlobalAveragePooling1D(name='pooling')(x)\n",
    "    x = Dropout(dr_rate_0, name='dropout_0')(x) # tune dropout rate\n",
    "    x = Dense(n_dense, activation='linear', name='fc')(x)\n",
    "    x = Dropout(dr_rate_1, name='dropout_1')(x)  # tune dropout rate\n",
    "    output = Dense(1, activation='sigmoid', name='fc_output', activity_regularizer=l2({{uniform(1e-5, 1e-3)}}))(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[mbs_input, timespan_input],\n",
    "                  outputs=[output])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=opt.RMSprop(lr=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    # Init the embedding matrix\n",
    "    embedding = pd.read_csv('../../tmp/embedding.50d.csv', header=0, index_col=0)    \n",
    "    model.get_layer('mbs_embedding').set_weights([embedding.values])\n",
    "    model.get_layer('mbs_embedding').trainable = embedding_trainable\n",
    "    \n",
    "    # Fit model\n",
    "    model.fit(x_train, y_train, epochs=100,\n",
    "              callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=1),\n",
    "                         EarlyStopping(monitor='val_loss', patience=15)] ,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(x_valid, y_valid))\n",
    "    \n",
    "    # Evaluate model\n",
    "    score, acc = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    print('score: {}'.format(score))\n",
    "    print('acc: {}'.format(acc))\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import metrics\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tangle.mbspbs10pc import utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers as opt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.sequence import pad_sequences\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM, Bidirectional, Dense, Dot, Dropout, LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Embedding, GlobalAveragePooling1D, Input, Multiply\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tangle.layers import TimespanGuidedNeuralAttention\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers as opt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing.sequence import pad_sequences\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM, Bidirectional, Dense, Dot, Dropout, LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Embedding, GlobalAveragePooling1D, Input, Multiply\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tangle.layers import TimespanGuidedNeuralAttention\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'n_recurrent': hp.choice('n_recurrent', [16, 32, 64, 128]),\n",
      "        'n_recurrent_1': hp.choice('n_recurrent_1', [16, 32, 64, 128]),\n",
      "        'dr_rate_0': hp.uniform('dr_rate_0', 0, 1),\n",
      "        'n_recurrent_2': hp.choice('n_recurrent_2', [16, 32, 64, 128]),\n",
      "        'dr_rate_0_1': hp.uniform('dr_rate_0_1', 0, 1),\n",
      "        'lr': hp.uniform('lr', 1e-5, 1e-1),\n",
      "        'embedding_trainable': hp.choice('embedding_trainable', [True, False]),\n",
      "        'batch_size': hp.choice('batch_size', [64, 128, 256]),\n",
      "        'l2': hp.uniform('l2', 1e-5, 1e-3),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \"\"\"Test set not returned on purpose.\"\"\"\n",
      "  3: \n",
      "  4: labelsfile = '../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv'\n",
      "  5: datafile = '../../tmp/item_days_raw_data_.pkl'\n",
      "  6: dataset = utils.load_data_labels(datafile, labelsfile)\n",
      "  7: padded_mbs_seq, padded_timespan_seq, _ = utils.tokenize(dataset)\n",
      "  8: maxlen = padded_mbs_seq.shape[1]\n",
      "  9: \n",
      " 10: # Split in training, validation, test sets\n",
      " 11: tr_set, v_set, ts_set = utils.train_validation_test_split(\n",
      " 12:     [padded_mbs_seq, padded_timespan_seq], dataset['Class'],\n",
      " 13:     test_size=0.4, validation_size=0.1,\n",
      " 14:     verbose=False, random_state0=1, random_state1=0)\n",
      " 15: \n",
      " 16: x_train, y_train = tr_set[0], tr_set[1]\n",
      " 17: x_valid, y_valid = v_set[0], v_set[1]\n",
      " 18: \n",
      " 19: \n",
      " 20: \n",
      " 21: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3: \n",
      "   4:     # Hyperparameters\n",
      "   5:     n_recurrent = space['n_recurrent']\n",
      "   6:     n_attention = space['n_recurrent_1']\n",
      "   7:     dr_rate_0 = space['dr_rate_0']\n",
      "   8:     n_dense = space['n_recurrent_2']\n",
      "   9:     dr_rate_1 = space['dr_rate_0_1']\n",
      "  10:     lr = space['lr']\n",
      "  11:     embedding_trainable = space['embedding_trainable']\n",
      "  12:     batch_size = space['batch_size']\n",
      "  13:     \n",
      "  14:     # Channel 1: MBS\n",
      "  15:     mbs_input = Input(shape=(250,), name='mbs_input')\n",
      "  16:     e = Embedding(2774, 50, name='mbs_embedding')(mbs_input)\n",
      "  17:     x1 = Bidirectional(LSTM(n_recurrent, return_sequences=True), name='mbs_lstm')(e)\n",
      "  18: \n",
      "  19:     # Channel 2: Timespans\n",
      "  20:     timespan_input = Input(shape=(250, 1), name='timespan_input')\n",
      "  21:     x2 = Bidirectional(LSTM(n_recurrent, return_sequences=True), name='timespan_lstm')(timespan_input)\n",
      "  22:     \n",
      "  23:     # Timespan-guided neural attention weights\n",
      "  24:     alpha = TimespanGuidedNeuralAttention(n_attention, name='tangle_attention')([x1, x2])\n",
      "  25: \n",
      "  26:     # Combine channels to get contribution and context\n",
      "  27:     c = Multiply(name='contribution')([alpha, x1])\n",
      "  28:     x = Dot(axes=1, name='context')([c, e])\n",
      "  29: \n",
      "  30:     # Output\n",
      "  31:     x = GlobalAveragePooling1D(name='pooling')(x)\n",
      "  32:     x = Dropout(dr_rate_0, name='dropout_0')(x) # tune dropout rate\n",
      "  33:     x = Dense(n_dense, activation='linear', name='fc')(x)\n",
      "  34:     x = Dropout(dr_rate_1, name='dropout_1')(x)  # tune dropout rate\n",
      "  35:     output = Dense(1, activation='sigmoid', name='fc_output', activity_regularizer=l2(space['l2']))(x)\n",
      "  36: \n",
      "  37:     # Define the model\n",
      "  38:     model = Model(inputs=[mbs_input, timespan_input],\n",
      "  39:                   outputs=[output])\n",
      "  40: \n",
      "  41:     # Compile the model\n",
      "  42:     model.compile(optimizer=opt.RMSprop(lr=lr),\n",
      "  43:                   loss='binary_crossentropy',\n",
      "  44:                   metrics=['acc'])\n",
      "  45:     \n",
      "  46:     # Init the embedding matrix\n",
      "  47:     embedding = pd.read_csv('../../tmp/embedding.50d.csv', header=0, index_col=0)    \n",
      "  48:     model.get_layer('mbs_embedding').set_weights([embedding.values])\n",
      "  49:     model.get_layer('mbs_embedding').trainable = embedding_trainable\n",
      "  50:     \n",
      "  51:     # Fit model\n",
      "  52:     model.fit(x_train, y_train, epochs=100,\n",
      "  53:               callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=1),\n",
      "  54:                          EarlyStopping(monitor='val_loss', patience=15)] ,\n",
      "  55:               batch_size=batch_size,\n",
      "  56:               validation_data=(x_valid, y_valid))\n",
      "  57:     \n",
      "  58:     # Evaluate model\n",
      "  59:     score, acc = model.evaluate(x_valid, y_valid, verbose=0)\n",
      "  60:     print('score: {}'.format(score))\n",
      "  61:     print('acc: {}'.format(acc))\n",
      "  62:     \n",
      "  63:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  64: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samu/miniconda2/lib/python2.7/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 85s 13ms/step - loss: 0.8963 - acc: 0.5567 - val_loss: 0.6921 - val_acc: 0.6184\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.6593 - acc: 0.6529 - val_loss: 0.6718 - val_acc: 0.6298\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.6255 - acc: 0.6930 - val_loss: 0.6440 - val_acc: 0.6454\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.6004 - acc: 0.7035 - val_loss: 0.8186 - val_acc: 0.5745\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5947 - acc: 0.7174 - val_loss: 0.6424 - val_acc: 0.6738\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5725 - acc: 0.7270 - val_loss: 0.7016 - val_acc: 0.5773\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5690 - acc: 0.7305 - val_loss: 0.6358 - val_acc: 0.6837\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5734 - acc: 0.7328 - val_loss: 0.6389 - val_acc: 0.7021\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.5603 - acc: 0.7411 - val_loss: 0.6318 - val_acc: 0.6624\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5525 - acc: 0.7488 - val_loss: 0.6234 - val_acc: 0.6879\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 86s 14ms/step - loss: 0.5452 - acc: 0.7519 - val_loss: 0.6645 - val_acc: 0.6879\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.5369 - acc: 0.7560 - val_loss: 0.7118 - val_acc: 0.5362\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5493 - acc: 0.7508 - val_loss: 0.6097 - val_acc: 0.6667\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.5418 - acc: 0.7627 - val_loss: 0.7077 - val_acc: 0.6823\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.5399 - acc: 0.7630 - val_loss: 0.7357 - val_acc: 0.6894\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5191 - acc: 0.7737 - val_loss: 0.6866 - val_acc: 0.6340\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.5273 - acc: 0.7698 - val_loss: 0.6088 - val_acc: 0.7064\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.5150 - acc: 0.7743 - val_loss: 0.6907 - val_acc: 0.6482\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5282 - acc: 0.7571 - val_loss: 0.6782 - val_acc: 0.6752\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.5307 - acc: 0.7677 - val_loss: 0.6761 - val_acc: 0.6766\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.5279 - acc: 0.7578 - val_loss: 0.6940 - val_acc: 0.6936\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5330 - acc: 0.7586 - val_loss: 0.6711 - val_acc: 0.6950\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5130 - acc: 0.7772 - val_loss: 0.7197 - val_acc: 0.6695\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5431 - acc: 0.7581 - val_loss: 0.6907 - val_acc: 0.6454\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5332 - acc: 0.7597 - val_loss: 0.7608 - val_acc: 0.6426\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0346284881234.\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4825 - acc: 0.7838 - val_loss: 0.6956 - val_acc: 0.6950\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.4801 - acc: 0.7962 - val_loss: 0.7577 - val_acc: 0.7021\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.4562 - acc: 0.8059 - val_loss: 0.6498 - val_acc: 0.6780\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.4447 - acc: 0.8122 - val_loss: 0.8389 - val_acc: 0.6851\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.4340 - acc: 0.8229 - val_loss: 0.8368 - val_acc: 0.6723\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 85s 13ms/step - loss: 0.4269 - acc: 0.8196 - val_loss: 0.9708 - val_acc: 0.6809\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4250 - acc: 0.8251 - val_loss: 0.8552 - val_acc: 0.6823\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0173142440617.\n",
      "score: 0.831152569483\n",
      "acc: 0.682269503546\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.7093 - acc: 0.4988 - val_loss: 0.7468 - val_acc: 0.4993\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.7057 - acc: 0.5021 - val_loss: 0.7035 - val_acc: 0.4993\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.7054 - acc: 0.4919 - val_loss: 0.7204 - val_acc: 0.4993\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.7083 - acc: 0.5069 - val_loss: 0.7032 - val_acc: 0.4979\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 158s 25ms/step - loss: 0.7055 - acc: 0.5076 - val_loss: 0.6972 - val_acc: 0.5121\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.7062 - acc: 0.5083 - val_loss: 0.6861 - val_acc: 0.5915\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.6963 - acc: 0.5463 - val_loss: 0.6654 - val_acc: 0.5504\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.6917 - acc: 0.5515 - val_loss: 0.6713 - val_acc: 0.6383\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6864 - acc: 0.5647 - val_loss: 0.6905 - val_acc: 0.5348\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6876 - acc: 0.5726 - val_loss: 0.6818 - val_acc: 0.6383\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.6959 - acc: 0.5616 - val_loss: 0.6264 - val_acc: 0.6667\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.6881 - acc: 0.5761 - val_loss: 0.7379 - val_acc: 0.4638\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.6865 - acc: 0.5740 - val_loss: 0.6601 - val_acc: 0.5560\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.6959 - acc: 0.5543 - val_loss: 0.6594 - val_acc: 0.6170\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.6826 - acc: 0.5767 - val_loss: 0.6605 - val_acc: 0.6780\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.6967 - acc: 0.5586 - val_loss: 0.6792 - val_acc: 0.5418\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.7003 - acc: 0.5491 - val_loss: 0.6584 - val_acc: 0.6255\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.7072 - acc: 0.5390 - val_loss: 0.6654 - val_acc: 0.6099\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.7024 - acc: 0.5468 - val_loss: 0.6523 - val_acc: 0.6213\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0212643053383.\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.6896 - acc: 0.5639 - val_loss: 0.6547 - val_acc: 0.6270\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.6836 - acc: 0.5701 - val_loss: 0.6433 - val_acc: 0.6525\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.6738 - acc: 0.5792 - val_loss: 0.6876 - val_acc: 0.6128\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.6795 - acc: 0.5874 - val_loss: 0.6305 - val_acc: 0.6723\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.6757 - acc: 0.5950 - val_loss: 0.6545 - val_acc: 0.6652\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.6660 - acc: 0.6108 - val_loss: 0.6797 - val_acc: 0.5943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.6677 - acc: 0.6035 - val_loss: 0.6347 - val_acc: 0.6582\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0106321526691.\n",
      "score: 0.630621042826\n",
      "acc: 0.658156028369\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7484 - acc: 0.4931 - val_loss: 0.7056 - val_acc: 0.5418\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7056 - acc: 0.5356 - val_loss: 0.6749 - val_acc: 0.5801\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.6871 - acc: 0.5901 - val_loss: 0.6487 - val_acc: 0.6837\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6647 - acc: 0.6319 - val_loss: 0.6767 - val_acc: 0.6071\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6637 - acc: 0.6458 - val_loss: 0.6231 - val_acc: 0.6851\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6590 - acc: 0.6488 - val_loss: 0.6621 - val_acc: 0.6582\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.6653 - acc: 0.6278 - val_loss: 0.6653 - val_acc: 0.6454\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6542 - acc: 0.6415 - val_loss: 0.7065 - val_acc: 0.6340\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.6620 - acc: 0.6321 - val_loss: 0.6481 - val_acc: 0.6496\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6457 - acc: 0.6549 - val_loss: 0.6585 - val_acc: 0.6099\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.6488 - acc: 0.6560 - val_loss: 0.6569 - val_acc: 0.6113\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6268 - acc: 0.6717 - val_loss: 0.6676 - val_acc: 0.5830\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6350 - acc: 0.6712 - val_loss: 0.6561 - val_acc: 0.6511\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0363792702556.\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.6192 - acc: 0.6849 - val_loss: 0.6299 - val_acc: 0.6496\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6190 - acc: 0.6767 - val_loss: 0.6298 - val_acc: 0.6652\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6087 - acc: 0.6955 - val_loss: 0.6240 - val_acc: 0.6681\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5939 - acc: 0.7062 - val_loss: 0.6277 - val_acc: 0.6851\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5802 - acc: 0.7245 - val_loss: 0.6179 - val_acc: 0.6766\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5725 - acc: 0.7250 - val_loss: 0.5870 - val_acc: 0.7149\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6042 - acc: 0.6933 - val_loss: 0.6307 - val_acc: 0.6553\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6100 - acc: 0.6885 - val_loss: 0.6405 - val_acc: 0.6440\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5940 - acc: 0.7037 - val_loss: 0.6423 - val_acc: 0.6539\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5757 - acc: 0.7155 - val_loss: 0.6182 - val_acc: 0.6936\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5740 - acc: 0.7232 - val_loss: 0.6939 - val_acc: 0.6879\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5661 - acc: 0.7294 - val_loss: 0.6671 - val_acc: 0.6809\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5699 - acc: 0.7231 - val_loss: 0.6029 - val_acc: 0.6894\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5735 - acc: 0.7224 - val_loss: 0.6144 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0181896351278.\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5410 - acc: 0.7453 - val_loss: 0.5880 - val_acc: 0.7092\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5236 - acc: 0.7582 - val_loss: 0.5980 - val_acc: 0.6979\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5037 - acc: 0.7726 - val_loss: 0.5861 - val_acc: 0.6794\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5080 - acc: 0.7683 - val_loss: 0.6185 - val_acc: 0.6879\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5166 - acc: 0.7614 - val_loss: 0.5995 - val_acc: 0.6965\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5020 - acc: 0.7712 - val_loss: 0.6533 - val_acc: 0.7035\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4866 - acc: 0.7857 - val_loss: 0.6122 - val_acc: 0.6993\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4993 - acc: 0.7727 - val_loss: 0.5873 - val_acc: 0.7078\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4831 - acc: 0.7879 - val_loss: 0.5654 - val_acc: 0.7220\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4749 - acc: 0.7925 - val_loss: 0.6351 - val_acc: 0.7035\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4627 - acc: 0.8018 - val_loss: 0.5839 - val_acc: 0.7106\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5008 - acc: 0.7808 - val_loss: 0.6384 - val_acc: 0.6879\n",
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5103 - acc: 0.7690 - val_loss: 0.6172 - val_acc: 0.6723\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4832 - acc: 0.7931 - val_loss: 0.6432 - val_acc: 0.6865\n",
      "Epoch 42/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4695 - acc: 0.7950 - val_loss: 0.5968 - val_acc: 0.7206\n",
      "Epoch 43/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4510 - acc: 0.8103 - val_loss: 0.7079 - val_acc: 0.6894\n",
      "Epoch 44/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4630 - acc: 0.8027 - val_loss: 0.6534 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00909481756389.\n",
      "Epoch 45/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4464 - acc: 0.8115 - val_loss: 0.7533 - val_acc: 0.6879\n",
      "Epoch 46/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4300 - acc: 0.8175 - val_loss: 0.6574 - val_acc: 0.6950\n",
      "Epoch 47/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4016 - acc: 0.8335 - val_loss: 0.6567 - val_acc: 0.6993\n",
      "Epoch 48/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.3875 - acc: 0.8445 - val_loss: 0.6987 - val_acc: 0.6950\n",
      "Epoch 49/100\n",
      "6341/6341 [==============================] - 85s 13ms/step - loss: 0.3828 - acc: 0.8458 - val_loss: 0.6856 - val_acc: 0.6823\n",
      "Epoch 50/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.3658 - acc: 0.8573 - val_loss: 0.6837 - val_acc: 0.7007\n",
      "Epoch 51/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.3456 - acc: 0.8685 - val_loss: 0.8230 - val_acc: 0.6922\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00454740878195.\n",
      "score: 0.807381199332\n",
      "acc: 0.69219858156\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 44s 7ms/step - loss: 1.2307 - acc: 0.4972 - val_loss: 0.7410 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 44s 7ms/step - loss: 0.8526 - acc: 0.4953 - val_loss: 0.7396 - val_acc: 0.5007\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7839 - acc: 0.4985 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 41s 7ms/step - loss: 0.7997 - acc: 0.5021 - val_loss: 0.7447 - val_acc: 0.4993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.8028 - acc: 0.4976 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.8178 - acc: 0.4971 - val_loss: 0.7393 - val_acc: 0.5007\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.8047 - acc: 0.4924 - val_loss: 0.7399 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 42s 7ms/step - loss: 0.8111 - acc: 0.4912 - val_loss: 0.7402 - val_acc: 0.5007\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.8026 - acc: 0.5010 - val_loss: 0.7391 - val_acc: 0.5007\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.8230 - acc: 0.4974 - val_loss: 0.7394 - val_acc: 0.5007\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7832 - acc: 0.5083 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0267563611269.\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7657 - acc: 0.5065 - val_loss: 0.7396 - val_acc: 0.5007\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7665 - acc: 0.5061 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7689 - acc: 0.4979 - val_loss: 0.7392 - val_acc: 0.5007\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7727 - acc: 0.5024 - val_loss: 0.7392 - val_acc: 0.5007\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 41s 7ms/step - loss: 0.7676 - acc: 0.5018 - val_loss: 0.7395 - val_acc: 0.5007\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 43s 7ms/step - loss: 0.7641 - acc: 0.4979 - val_loss: 0.7392 - val_acc: 0.5007\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7641 - acc: 0.5056 - val_loss: 0.7394 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0133781805634.\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7561 - acc: 0.5009 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7496 - acc: 0.5073 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 43s 7ms/step - loss: 0.7505 - acc: 0.5045 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7500 - acc: 0.5026 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 43s 7ms/step - loss: 0.7513 - acc: 0.4998 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7493 - acc: 0.5073 - val_loss: 0.7390 - val_acc: 0.5007\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 42s 7ms/step - loss: 0.7509 - acc: 0.4999 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7518 - acc: 0.4979 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7509 - acc: 0.4938 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 41s 7ms/step - loss: 0.7507 - acc: 0.5029 - val_loss: 0.7393 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00668909028172.\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7476 - acc: 0.4983 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7470 - acc: 0.4911 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7488 - acc: 0.4968 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7455 - acc: 0.4950 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7447 - acc: 0.4952 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7489 - acc: 0.4987 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7452 - acc: 0.5024 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00334454514086.\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7467 - acc: 0.5021 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7454 - acc: 0.4977 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 35s 5ms/step - loss: 0.7433 - acc: 0.5048 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7454 - acc: 0.4969 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7432 - acc: 0.5017 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7440 - acc: 0.5001 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 42/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7433 - acc: 0.5004 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00167227257043.\n",
      "Epoch 43/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7433 - acc: 0.5039 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 44/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7432 - acc: 0.4983 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 45/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7435 - acc: 0.4990 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 46/100\n",
      "6341/6341 [==============================] - 41s 7ms/step - loss: 0.7436 - acc: 0.4942 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "Epoch 47/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7423 - acc: 0.5007 - val_loss: 0.7389 - val_acc: 0.5007\n",
      "score: 0.703153480875\n",
      "acc: 0.500709219858\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.7115 - acc: 0.4957 - val_loss: 0.6967 - val_acc: 0.4993\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.6937 - acc: 0.5220 - val_loss: 0.6445 - val_acc: 0.5475\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.6689 - acc: 0.5966 - val_loss: 0.6288 - val_acc: 0.6553\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.6546 - acc: 0.6234 - val_loss: 0.6652 - val_acc: 0.6340\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.6340 - acc: 0.6475 - val_loss: 0.7548 - val_acc: 0.6340\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 162s 25ms/step - loss: 0.6073 - acc: 0.6710 - val_loss: 0.6601 - val_acc: 0.5504\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.5957 - acc: 0.6827 - val_loss: 0.6626 - val_acc: 0.6496\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.5689 - acc: 0.7067 - val_loss: 0.6110 - val_acc: 0.7277\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.5632 - acc: 0.7133 - val_loss: 0.5921 - val_acc: 0.6695\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.5426 - acc: 0.7232 - val_loss: 0.5415 - val_acc: 0.7234\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.5385 - acc: 0.7354 - val_loss: 0.5387 - val_acc: 0.7092\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.5228 - acc: 0.7423 - val_loss: 0.5231 - val_acc: 0.7433\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 163s 26ms/step - loss: 0.5152 - acc: 0.7396 - val_loss: 0.5311 - val_acc: 0.7035\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 162s 25ms/step - loss: 0.5152 - acc: 0.7442 - val_loss: 0.5488 - val_acc: 0.7348\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.5104 - acc: 0.7565 - val_loss: 0.5373 - val_acc: 0.7234\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.4936 - acc: 0.7608 - val_loss: 0.9431 - val_acc: 0.2738\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 167s 26ms/step - loss: 0.5140 - acc: 0.7518 - val_loss: 0.5212 - val_acc: 0.7277\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.5078 - acc: 0.7600 - val_loss: 0.6407 - val_acc: 0.6241\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 163s 26ms/step - loss: 0.5038 - acc: 0.7552 - val_loss: 0.5789 - val_acc: 0.7277\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.5012 - acc: 0.7590 - val_loss: 0.5661 - val_acc: 0.7489\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.5045 - acc: 0.7551 - val_loss: 0.5523 - val_acc: 0.7050\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.4923 - acc: 0.7570 - val_loss: 0.5505 - val_acc: 0.6865\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.4889 - acc: 0.7701 - val_loss: 0.5155 - val_acc: 0.7418\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.5164 - acc: 0.7510 - val_loss: 0.6069 - val_acc: 0.6426\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.5117 - acc: 0.7456 - val_loss: 0.6811 - val_acc: 0.6582\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 162s 25ms/step - loss: 0.5156 - acc: 0.7481 - val_loss: 0.6985 - val_acc: 0.6979\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.5115 - acc: 0.7634 - val_loss: 0.6072 - val_acc: 0.7433\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.5145 - acc: 0.7483 - val_loss: 0.6287 - val_acc: 0.7390\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.5414 - acc: 0.7362 - val_loss: 0.6958 - val_acc: 0.6652\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.5410 - acc: 0.7447 - val_loss: 0.5479 - val_acc: 0.7234\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.5364 - acc: 0.7325 - val_loss: 0.5569 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0116583192721.\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 158s 25ms/step - loss: 0.5029 - acc: 0.7515 - val_loss: 0.5532 - val_acc: 0.7305\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 159s 25ms/step - loss: 0.4875 - acc: 0.7638 - val_loss: 0.5591 - val_acc: 0.7362\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.4821 - acc: 0.7704 - val_loss: 0.5898 - val_acc: 0.7135\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 167s 26ms/step - loss: 0.5040 - acc: 0.7619 - val_loss: 0.5208 - val_acc: 0.7305\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.4819 - acc: 0.7690 - val_loss: 0.6525 - val_acc: 0.7191\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.4771 - acc: 0.7756 - val_loss: 0.5928 - val_acc: 0.7007\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.4509 - acc: 0.7923 - val_loss: 0.5640 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.00582915963605.\n",
      "score: 0.563010117155\n",
      "acc: 0.723404255319\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 1.1792 - acc: 0.5187 - val_loss: 0.7082 - val_acc: 0.5092\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6840 - acc: 0.5830 - val_loss: 0.6675 - val_acc: 0.6085\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7170 - acc: 0.5867 - val_loss: 0.6513 - val_acc: 0.6057\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6696 - acc: 0.6409 - val_loss: 0.6282 - val_acc: 0.6482\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5896 - acc: 0.7005 - val_loss: 0.6375 - val_acc: 0.6454\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.6025 - acc: 0.7000 - val_loss: 1.3044 - val_acc: 0.5787\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6071 - acc: 0.6977 - val_loss: 0.6977 - val_acc: 0.5560\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.5470 - acc: 0.7286 - val_loss: 0.6670 - val_acc: 0.6738\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5880 - acc: 0.7302 - val_loss: 0.6801 - val_acc: 0.6596\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5481 - acc: 0.7385 - val_loss: 0.6829 - val_acc: 0.6709\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5461 - acc: 0.7426 - val_loss: 0.7275 - val_acc: 0.6965\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5433 - acc: 0.7478 - val_loss: 0.6862 - val_acc: 0.6794\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0371430069208.\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4678 - acc: 0.7950 - val_loss: 0.6668 - val_acc: 0.6908\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4377 - acc: 0.8136 - val_loss: 0.7845 - val_acc: 0.6738\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4478 - acc: 0.8037 - val_loss: 0.7187 - val_acc: 0.6766\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4529 - acc: 0.8065 - val_loss: 0.6963 - val_acc: 0.7007\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 43s 7ms/step - loss: 0.4449 - acc: 0.8123 - val_loss: 0.7112 - val_acc: 0.6979\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4487 - acc: 0.8043 - val_loss: 0.7303 - val_acc: 0.6809\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4616 - acc: 0.7981 - val_loss: 0.6947 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0185715034604.\n",
      "score: 0.675998228611\n",
      "acc: 0.696453900709\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 45s 7ms/step - loss: 0.8035 - acc: 0.5061 - val_loss: 0.7381 - val_acc: 0.5177\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7473 - acc: 0.4905 - val_loss: 0.7346 - val_acc: 0.5007\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7431 - acc: 0.5092 - val_loss: 0.7356 - val_acc: 0.5007\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7446 - acc: 0.5024 - val_loss: 0.7344 - val_acc: 0.5007\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7470 - acc: 0.4953 - val_loss: 0.7350 - val_acc: 0.5007\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7478 - acc: 0.5034 - val_loss: 0.7349 - val_acc: 0.5007\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7432 - acc: 0.4968 - val_loss: 0.7353 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7462 - acc: 0.4938 - val_loss: 0.7368 - val_acc: 0.5007\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7466 - acc: 0.5012 - val_loss: 0.7355 - val_acc: 0.5007\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7422 - acc: 0.4998 - val_loss: 0.7352 - val_acc: 0.5007\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7481 - acc: 0.4870 - val_loss: 0.7400 - val_acc: 0.5007\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7442 - acc: 0.4966 - val_loss: 0.7351 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0198682341725.\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7394 - acc: 0.4976 - val_loss: 0.7345 - val_acc: 0.5007\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7387 - acc: 0.5012 - val_loss: 0.7353 - val_acc: 0.5007\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7392 - acc: 0.5029 - val_loss: 0.7347 - val_acc: 0.5007\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7397 - acc: 0.4985 - val_loss: 0.7346 - val_acc: 0.5007\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7389 - acc: 0.5065 - val_loss: 0.7367 - val_acc: 0.5007\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7394 - acc: 0.4985 - val_loss: 0.7347 - val_acc: 0.5007\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7401 - acc: 0.4998 - val_loss: 0.7370 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00993411708623.\n",
      "score: 0.699022787091\n",
      "acc: 0.500709219858\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.6891 - acc: 0.5573 - val_loss: 0.6939 - val_acc: 0.5603\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6189 - acc: 0.6688 - val_loss: 0.5904 - val_acc: 0.6908\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.5611 - acc: 0.7221 - val_loss: 0.5670 - val_acc: 0.7078\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.5324 - acc: 0.7346 - val_loss: 0.5586 - val_acc: 0.7106\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.5136 - acc: 0.7423 - val_loss: 0.5805 - val_acc: 0.6794\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.4762 - acc: 0.7753 - val_loss: 0.5135 - val_acc: 0.7475\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4500 - acc: 0.7977 - val_loss: 0.5024 - val_acc: 0.7518\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4420 - acc: 0.8019 - val_loss: 0.5290 - val_acc: 0.7319\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4368 - acc: 0.8054 - val_loss: 0.5389 - val_acc: 0.7262\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4163 - acc: 0.8161 - val_loss: 0.4919 - val_acc: 0.7574\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3735 - acc: 0.8376 - val_loss: 0.5166 - val_acc: 0.7518\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.3795 - acc: 0.8283 - val_loss: 0.4681 - val_acc: 0.7645\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3524 - acc: 0.8494 - val_loss: 0.5537 - val_acc: 0.7589\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3287 - acc: 0.8604 - val_loss: 0.4889 - val_acc: 0.7716\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.3184 - acc: 0.8655 - val_loss: 0.5627 - val_acc: 0.7532\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.3444 - acc: 0.8489 - val_loss: 0.5547 - val_acc: 0.7433\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.3089 - acc: 0.8702 - val_loss: 0.5304 - val_acc: 0.7532\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.2910 - acc: 0.8809 - val_loss: 0.5464 - val_acc: 0.7560\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 87s 14ms/step - loss: 0.2656 - acc: 0.8969 - val_loss: 0.5773 - val_acc: 0.7688\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.2493 - acc: 0.9010 - val_loss: 0.5944 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00404374906793.\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.1981 - acc: 0.9251 - val_loss: 0.6664 - val_acc: 0.7645\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.1674 - acc: 0.9375 - val_loss: 0.6989 - val_acc: 0.7730\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.1359 - acc: 0.9543 - val_loss: 0.7443 - val_acc: 0.7546\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 86s 14ms/step - loss: 0.1214 - acc: 0.9585 - val_loss: 0.8741 - val_acc: 0.7589\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.1034 - acc: 0.9640 - val_loss: 0.9207 - val_acc: 0.7745\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.0808 - acc: 0.9743 - val_loss: 1.1157 - val_acc: 0.7702\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 86s 14ms/step - loss: 0.0771 - acc: 0.9767 - val_loss: 1.2060 - val_acc: 0.7574\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00202187453397.\n",
      "score: 1.19622658007\n",
      "acc: 0.757446808511\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 167s 26ms/step - loss: nan - acc: 0.1124 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 167s 26ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 163s 26ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0367900133133.\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0183950066566.\n",
      "score: nan\n",
      "acc: 0.0\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.6611 - acc: 0.5986 - val_loss: 0.6930 - val_acc: 0.5858\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.5687 - acc: 0.7105 - val_loss: 0.5897 - val_acc: 0.7121\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.5361 - acc: 0.7332 - val_loss: 0.5540 - val_acc: 0.7163\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5111 - acc: 0.7485 - val_loss: 0.5970 - val_acc: 0.7220\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5034 - acc: 0.7575 - val_loss: 0.8410 - val_acc: 0.6539\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 190s 30ms/step - loss: 0.4927 - acc: 0.7668 - val_loss: 0.5740 - val_acc: 0.7106\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 220s 35ms/step - loss: 0.4692 - acc: 0.7784 - val_loss: 0.5875 - val_acc: 0.6610\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 162s 26ms/step - loss: 0.4488 - acc: 0.7914 - val_loss: 0.5604 - val_acc: 0.7035\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 252s 40ms/step - loss: 0.4362 - acc: 0.8007 - val_loss: 0.6055 - val_acc: 0.6766\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.4314 - acc: 0.8008 - val_loss: 0.5953 - val_acc: 0.7234\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 260s 41ms/step - loss: 0.4283 - acc: 0.8016 - val_loss: 0.6223 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0104773398489.\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 165s 26ms/step - loss: 0.3981 - acc: 0.8218 - val_loss: 0.6086 - val_acc: 0.7418\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 257s 41ms/step - loss: 0.3746 - acc: 0.8349 - val_loss: 0.6126 - val_acc: 0.7390\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.3620 - acc: 0.8388 - val_loss: 0.5640 - val_acc: 0.7518\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 219s 35ms/step - loss: 0.3503 - acc: 0.8491 - val_loss: 0.5530 - val_acc: 0.7418\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 183s 29ms/step - loss: 0.3381 - acc: 0.8541 - val_loss: 0.5805 - val_acc: 0.7504\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.3379 - acc: 0.8563 - val_loss: 0.5910 - val_acc: 0.7631\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 246s 39ms/step - loss: 0.3341 - acc: 0.8592 - val_loss: 0.5506 - val_acc: 0.7518\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.3174 - acc: 0.8696 - val_loss: 0.5891 - val_acc: 0.7390\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 249s 39ms/step - loss: 0.3258 - acc: 0.8568 - val_loss: 0.6011 - val_acc: 0.7532\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 163s 26ms/step - loss: 0.3086 - acc: 0.8641 - val_loss: 0.5706 - val_acc: 0.7617\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 256s 40ms/step - loss: 0.2900 - acc: 0.8778 - val_loss: 0.6728 - val_acc: 0.7475\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.2828 - acc: 0.8811 - val_loss: 0.6298 - val_acc: 0.7489\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 252s 40ms/step - loss: 0.2740 - acc: 0.8874 - val_loss: 0.6397 - val_acc: 0.7277\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.2645 - acc: 0.8924 - val_loss: 0.6369 - val_acc: 0.7319\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 232s 37ms/step - loss: 0.2586 - acc: 0.8948 - val_loss: 0.6792 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00523866992444.\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 172s 27ms/step - loss: 0.2275 - acc: 0.9093 - val_loss: 0.6486 - val_acc: 0.7433\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1954 - acc: 0.9227 - val_loss: 0.7747 - val_acc: 0.7603\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 247s 39ms/step - loss: 0.1862 - acc: 0.9252 - val_loss: 0.7494 - val_acc: 0.7404\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.1604 - acc: 0.9398 - val_loss: 0.8397 - val_acc: 0.7489\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 251s 40ms/step - loss: 0.1424 - acc: 0.9469 - val_loss: 0.8877 - val_acc: 0.7702\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.1403 - acc: 0.9464 - val_loss: 0.9695 - val_acc: 0.7433\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 255s 40ms/step - loss: 0.1302 - acc: 0.9519 - val_loss: 0.8939 - val_acc: 0.7518\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00261933496222.\n",
      "score: 0.892284848678\n",
      "acc: 0.751773049645\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.7148 - acc: 0.5228 - val_loss: 0.7067 - val_acc: 0.5149\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.6487 - acc: 0.6450 - val_loss: 0.6302 - val_acc: 0.6610\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5678 - acc: 0.7371 - val_loss: 0.5815 - val_acc: 0.7149\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 169s 27ms/step - loss: 0.5116 - acc: 0.7709 - val_loss: 0.5559 - val_acc: 0.7220\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.4905 - acc: 0.7833 - val_loss: 0.6088 - val_acc: 0.7064\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4494 - acc: 0.8115 - val_loss: 0.5786 - val_acc: 0.7716\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4356 - acc: 0.8197 - val_loss: 0.5109 - val_acc: 0.7560\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 109s 17ms/step - loss: 0.4040 - acc: 0.8368 - val_loss: 0.5298 - val_acc: 0.7532\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 139s 22ms/step - loss: 0.3929 - acc: 0.8385 - val_loss: 0.5098 - val_acc: 0.7589\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.3669 - acc: 0.8598 - val_loss: 0.5062 - val_acc: 0.7560\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.3524 - acc: 0.8615 - val_loss: 0.5206 - val_acc: 0.7603\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 114s 18ms/step - loss: 0.3554 - acc: 0.8607 - val_loss: 0.5725 - val_acc: 0.7660\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.3660 - acc: 0.8559 - val_loss: 0.5613 - val_acc: 0.7617\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.3576 - acc: 0.8622 - val_loss: 0.6799 - val_acc: 0.7489\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.3339 - acc: 0.8707 - val_loss: 0.7066 - val_acc: 0.7248\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3043 - acc: 0.8871 - val_loss: 0.6125 - val_acc: 0.7560\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 166s 26ms/step - loss: 0.2830 - acc: 0.8988 - val_loss: 0.6700 - val_acc: 0.7461\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2735 - acc: 0.9025 - val_loss: 0.7044 - val_acc: 0.7518\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00521104224026.\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.2155 - acc: 0.9293 - val_loss: 0.7634 - val_acc: 0.7603\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.1775 - acc: 0.9421 - val_loss: 0.7895 - val_acc: 0.7645\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 139s 22ms/step - loss: 0.1580 - acc: 0.9558 - val_loss: 0.8712 - val_acc: 0.7674\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 111s 18ms/step - loss: 0.1340 - acc: 0.9644 - val_loss: 0.9679 - val_acc: 0.7730\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.1246 - acc: 0.9696 - val_loss: 1.0495 - val_acc: 0.7688\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.1031 - acc: 0.9789 - val_loss: 1.3654 - val_acc: 0.7461\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.1009 - acc: 0.9741 - val_loss: 1.2613 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00260552112013.\n",
      "score: 1.23535121868\n",
      "acc: 0.76170212766\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.7081 - acc: 0.5188 - val_loss: 0.6745 - val_acc: 0.5702\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.6020 - acc: 0.6813 - val_loss: 0.5885 - val_acc: 0.6908\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.5429 - acc: 0.7306 - val_loss: 0.5463 - val_acc: 0.7348\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.5188 - acc: 0.7428 - val_loss: 0.5549 - val_acc: 0.7135\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4991 - acc: 0.7620 - val_loss: 0.5738 - val_acc: 0.6908\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4806 - acc: 0.7657 - val_loss: 0.5443 - val_acc: 0.7092\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 100s 16ms/step - loss: 0.4583 - acc: 0.7833 - val_loss: 0.5292 - val_acc: 0.7248\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4399 - acc: 0.7958 - val_loss: 0.5355 - val_acc: 0.7404\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4135 - acc: 0.8104 - val_loss: 0.5507 - val_acc: 0.7220\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3853 - acc: 0.8254 - val_loss: 0.5454 - val_acc: 0.7333\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.3702 - acc: 0.8387 - val_loss: 0.5873 - val_acc: 0.7333\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.3542 - acc: 0.8496 - val_loss: 0.5730 - val_acc: 0.7305\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.3279 - acc: 0.8633 - val_loss: 0.6787 - val_acc: 0.7021\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.3133 - acc: 0.8683 - val_loss: 0.6263 - val_acc: 0.7050\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.2805 - acc: 0.8858 - val_loss: 0.8171 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0152568332851.\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 135s 21ms/step - loss: 0.2374 - acc: 0.9068 - val_loss: 0.7428 - val_acc: 0.7149\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 42s 7ms/step - loss: 0.2047 - acc: 0.9197 - val_loss: 0.8975 - val_acc: 0.7248\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.1802 - acc: 0.9349 - val_loss: 0.8743 - val_acc: 0.7078\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.1612 - acc: 0.9387 - val_loss: 0.9426 - val_acc: 0.7191\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.1436 - acc: 0.9502 - val_loss: 1.1049 - val_acc: 0.7291\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.1284 - acc: 0.9577 - val_loss: 1.2008 - val_acc: 0.7064\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.1246 - acc: 0.9585 - val_loss: 1.2446 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00762841664255.\n",
      "score: 1.23504558604\n",
      "acc: 0.726241134752\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 44s 7ms/step - loss: 1.2255 - acc: 0.4974 - val_loss: 0.7234 - val_acc: 0.5021\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7622 - acc: 0.4939 - val_loss: 0.7529 - val_acc: 0.4993\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 132s 21ms/step - loss: 0.7979 - acc: 0.4906 - val_loss: 0.7289 - val_acc: 0.4993\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7767 - acc: 0.5018 - val_loss: 0.7847 - val_acc: 0.4993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7919 - acc: 0.4908 - val_loss: 0.7624 - val_acc: 0.4993\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7763 - acc: 0.5001 - val_loss: 0.7219 - val_acc: 0.5021\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7857 - acc: 0.4908 - val_loss: 0.7314 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7859 - acc: 0.5039 - val_loss: 0.7424 - val_acc: 0.4950\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7946 - acc: 0.4946 - val_loss: 0.7530 - val_acc: 0.4979\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7793 - acc: 0.5162 - val_loss: 0.8299 - val_acc: 0.4993\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 87s 14ms/step - loss: 0.7785 - acc: 0.5092 - val_loss: 0.7231 - val_acc: 0.5489\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.7715 - acc: 0.5117 - val_loss: 0.7192 - val_acc: 0.5050\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7749 - acc: 0.4968 - val_loss: 0.7438 - val_acc: 0.4766\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7814 - acc: 0.4966 - val_loss: 0.7343 - val_acc: 0.5050\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7746 - acc: 0.5028 - val_loss: 0.7183 - val_acc: 0.5319\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7831 - acc: 0.5108 - val_loss: 0.7291 - val_acc: 0.5021\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7612 - acc: 0.5119 - val_loss: 0.7791 - val_acc: 0.5035\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7812 - acc: 0.4955 - val_loss: 0.7343 - val_acc: 0.4908\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7761 - acc: 0.5047 - val_loss: 0.7172 - val_acc: 0.5348\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.7959 - acc: 0.5165 - val_loss: 0.7168 - val_acc: 0.5234\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 87s 14ms/step - loss: 0.7779 - acc: 0.5136 - val_loss: 0.7417 - val_acc: 0.5106\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.7805 - acc: 0.5105 - val_loss: 0.7872 - val_acc: 0.5007\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7748 - acc: 0.5201 - val_loss: 0.7296 - val_acc: 0.5248\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7838 - acc: 0.5067 - val_loss: 0.7356 - val_acc: 0.5106\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.7560 - acc: 0.5368 - val_loss: 0.7228 - val_acc: 0.5447\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7864 - acc: 0.5182 - val_loss: 0.7469 - val_acc: 0.5021\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 55s 9ms/step - loss: nan - acc: 0.4898 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 118s 19ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.04028807953.\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 79s 13ms/step - loss: nan - acc: 0.0000e+00 - val_loss: nan - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.020144039765.\n",
      "score: nan\n",
      "acc: 0.0\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 104s 16ms/step - loss: 0.7141 - acc: 0.5179 - val_loss: 0.6578 - val_acc: 0.6553\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.6165 - acc: 0.6871 - val_loss: 0.5711 - val_acc: 0.7206\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5829 - acc: 0.7139 - val_loss: 0.5757 - val_acc: 0.7021\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5646 - acc: 0.7283 - val_loss: 0.5794 - val_acc: 0.6979\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 174s 27ms/step - loss: 0.5484 - acc: 0.7333 - val_loss: 0.5938 - val_acc: 0.7078\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5305 - acc: 0.7534 - val_loss: 0.6091 - val_acc: 0.6851\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5216 - acc: 0.7519 - val_loss: 0.6804 - val_acc: 0.6482\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5193 - acc: 0.7614 - val_loss: 0.5801 - val_acc: 0.6993\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5076 - acc: 0.7743 - val_loss: 0.5797 - val_acc: 0.7135\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 105s 17ms/step - loss: 0.4913 - acc: 0.7855 - val_loss: 0.6440 - val_acc: 0.7050\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0258650835603.\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4475 - acc: 0.8085 - val_loss: 0.6191 - val_acc: 0.7050\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4293 - acc: 0.8161 - val_loss: 0.5937 - val_acc: 0.7234\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4036 - acc: 0.8412 - val_loss: 0.6638 - val_acc: 0.7078\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 171s 27ms/step - loss: 0.3870 - acc: 0.8461 - val_loss: 0.6607 - val_acc: 0.7149\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.3674 - acc: 0.8548 - val_loss: 0.7477 - val_acc: 0.6936\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3609 - acc: 0.8562 - val_loss: 0.7222 - val_acc: 0.6965\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.3465 - acc: 0.8611 - val_loss: 0.6879 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0129325417802.\n",
      "score: 0.678410352291\n",
      "acc: 0.702127659574\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 182s 29ms/step - loss: 0.7166 - acc: 0.5244 - val_loss: 0.7004 - val_acc: 0.5234\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6621 - acc: 0.6180 - val_loss: 0.6045 - val_acc: 0.6993\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.6167 - acc: 0.6729 - val_loss: 0.6140 - val_acc: 0.6610\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.6018 - acc: 0.6849 - val_loss: 0.5935 - val_acc: 0.6738\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.5951 - acc: 0.6925 - val_loss: 0.5655 - val_acc: 0.7035\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 163s 26ms/step - loss: 0.5918 - acc: 0.7012 - val_loss: 0.5635 - val_acc: 0.7220\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5717 - acc: 0.7128 - val_loss: 0.5745 - val_acc: 0.6879\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5607 - acc: 0.7220 - val_loss: 0.5896 - val_acc: 0.6979\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5563 - acc: 0.7273 - val_loss: 0.5951 - val_acc: 0.6879\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 116s 18ms/step - loss: 0.5551 - acc: 0.7239 - val_loss: 0.5740 - val_acc: 0.6851\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 133s 21ms/step - loss: 0.5550 - acc: 0.7229 - val_loss: 0.5956 - val_acc: 0.6695\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5510 - acc: 0.7371 - val_loss: 0.5800 - val_acc: 0.6950\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5461 - acc: 0.7407 - val_loss: 0.5828 - val_acc: 0.7064\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5518 - acc: 0.7325 - val_loss: 0.6403 - val_acc: 0.6794\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0261354800314.\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 171s 27ms/step - loss: 0.5303 - acc: 0.7504 - val_loss: 0.5878 - val_acc: 0.6950\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4914 - acc: 0.7775 - val_loss: 0.5933 - val_acc: 0.6865\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4714 - acc: 0.7860 - val_loss: 0.5819 - val_acc: 0.7092\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4602 - acc: 0.7978 - val_loss: 0.6028 - val_acc: 0.7106\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 86s 14ms/step - loss: 0.4545 - acc: 0.7980 - val_loss: 0.5640 - val_acc: 0.7078\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 158s 25ms/step - loss: 0.4507 - acc: 0.8095 - val_loss: 0.5815 - val_acc: 0.6965\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.4379 - acc: 0.8101 - val_loss: 0.6025 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0130677400157.\n",
      "score: 0.594906745803\n",
      "acc: 0.693617021277\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.7465 - acc: 0.5020 - val_loss: 0.7004 - val_acc: 0.4993\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.6781 - acc: 0.5986 - val_loss: 0.6041 - val_acc: 0.6766\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 173s 27ms/step - loss: 0.5997 - acc: 0.6900 - val_loss: 0.6238 - val_acc: 0.6652\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5806 - acc: 0.7013 - val_loss: 0.6700 - val_acc: 0.6567\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5731 - acc: 0.7103 - val_loss: 0.5945 - val_acc: 0.6879\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 94s 15ms/step - loss: 0.5699 - acc: 0.7194 - val_loss: 0.5968 - val_acc: 0.6752\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.5591 - acc: 0.7191 - val_loss: 0.6322 - val_acc: 0.7035\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5585 - acc: 0.7224 - val_loss: 0.5955 - val_acc: 0.7035\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5571 - acc: 0.7254 - val_loss: 0.6017 - val_acc: 0.6950\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5580 - acc: 0.7324 - val_loss: 0.5916 - val_acc: 0.6879\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.5467 - acc: 0.7284 - val_loss: 0.6405 - val_acc: 0.6993\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 106s 17ms/step - loss: 0.5389 - acc: 0.7403 - val_loss: 0.5802 - val_acc: 0.6865\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5290 - acc: 0.7474 - val_loss: 0.6284 - val_acc: 0.7007\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5332 - acc: 0.7448 - val_loss: 0.6083 - val_acc: 0.6823\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.5215 - acc: 0.7459 - val_loss: 0.5780 - val_acc: 0.6922\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.5313 - acc: 0.7463 - val_loss: 0.8048 - val_acc: 0.6184\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5200 - acc: 0.7546 - val_loss: 0.6151 - val_acc: 0.6369\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5171 - acc: 0.7552 - val_loss: 0.6190 - val_acc: 0.6794\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 87s 14ms/step - loss: 0.5238 - acc: 0.7551 - val_loss: 0.5985 - val_acc: 0.6936\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.5158 - acc: 0.7567 - val_loss: 0.5705 - val_acc: 0.7064\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5182 - acc: 0.7540 - val_loss: 0.5970 - val_acc: 0.7078\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5278 - acc: 0.7534 - val_loss: 0.5748 - val_acc: 0.7021\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5328 - acc: 0.7429 - val_loss: 0.6146 - val_acc: 0.7050\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 172s 27ms/step - loss: 0.5136 - acc: 0.7532 - val_loss: 0.5994 - val_acc: 0.6695\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.5165 - acc: 0.7483 - val_loss: 0.6023 - val_acc: 0.6894\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5087 - acc: 0.7650 - val_loss: 0.6183 - val_acc: 0.6979\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5018 - acc: 0.7604 - val_loss: 0.6608 - val_acc: 0.6965\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5037 - acc: 0.7633 - val_loss: 0.6767 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0348941758275.\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 168s 27ms/step - loss: 0.4715 - acc: 0.7805 - val_loss: 0.6133 - val_acc: 0.7078\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4519 - acc: 0.7980 - val_loss: 0.6173 - val_acc: 0.6851\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4436 - acc: 0.8038 - val_loss: 0.6201 - val_acc: 0.7121\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.4349 - acc: 0.8051 - val_loss: 0.6582 - val_acc: 0.7007\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 171s 27ms/step - loss: 0.4215 - acc: 0.8081 - val_loss: 0.5709 - val_acc: 0.6993\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.4202 - acc: 0.8112 - val_loss: 0.6706 - val_acc: 0.7021\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.4140 - acc: 0.8138 - val_loss: 0.6081 - val_acc: 0.7064\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0174470879138.\n",
      "score: 0.601065996606\n",
      "acc: 0.706382978723\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 251s 40ms/step - loss: 0.7395 - acc: 0.5007 - val_loss: 0.7689 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.6825 - acc: 0.5710 - val_loss: 0.7118 - val_acc: 0.5532\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.6459 - acc: 0.6335 - val_loss: 0.6116 - val_acc: 0.6965\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 246s 39ms/step - loss: 0.6334 - acc: 0.6660 - val_loss: 0.6992 - val_acc: 0.5546\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.6319 - acc: 0.6668 - val_loss: 0.7146 - val_acc: 0.7092\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 247s 39ms/step - loss: 0.6344 - acc: 0.6671 - val_loss: 0.7910 - val_acc: 0.6525\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.6033 - acc: 0.6914 - val_loss: 0.6900 - val_acc: 0.5319\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 244s 38ms/step - loss: 0.6103 - acc: 0.6830 - val_loss: 0.6551 - val_acc: 0.5716\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6044 - acc: 0.6863 - val_loss: 0.7054 - val_acc: 0.5915\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6089 - acc: 0.6816 - val_loss: 0.6894 - val_acc: 0.6936\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 245s 39ms/step - loss: 0.6257 - acc: 0.6707 - val_loss: 0.6385 - val_acc: 0.6709\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0331399589777.\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.5681 - acc: 0.7130 - val_loss: 0.5798 - val_acc: 0.6865\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 244s 38ms/step - loss: 0.5561 - acc: 0.7182 - val_loss: 0.5816 - val_acc: 0.6865\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.5439 - acc: 0.7363 - val_loss: 0.6024 - val_acc: 0.6837\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 241s 38ms/step - loss: 0.5383 - acc: 0.7404 - val_loss: 0.7226 - val_acc: 0.6823\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.5309 - acc: 0.7426 - val_loss: 0.6765 - val_acc: 0.6794\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 247s 39ms/step - loss: 0.5399 - acc: 0.7336 - val_loss: 0.6211 - val_acc: 0.6965\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.5191 - acc: 0.7524 - val_loss: 0.6264 - val_acc: 0.6823\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 245s 39ms/step - loss: 0.5242 - acc: 0.7491 - val_loss: 0.6528 - val_acc: 0.5872\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.5211 - acc: 0.7426 - val_loss: 0.6150 - val_acc: 0.6738\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0165699794888.\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 246s 39ms/step - loss: 0.5127 - acc: 0.7589 - val_loss: 0.6072 - val_acc: 0.6879\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4843 - acc: 0.7765 - val_loss: 0.6383 - val_acc: 0.6908\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 180s 28ms/step - loss: 0.4610 - acc: 0.7933 - val_loss: 0.6368 - val_acc: 0.6894\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 215s 34ms/step - loss: 0.4535 - acc: 0.7951 - val_loss: 0.6291 - val_acc: 0.6766\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4455 - acc: 0.8063 - val_loss: 0.7055 - val_acc: 0.6993\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 246s 39ms/step - loss: 0.4338 - acc: 0.8136 - val_loss: 0.5622 - val_acc: 0.6979\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.4301 - acc: 0.8106 - val_loss: 0.6564 - val_acc: 0.7106\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 244s 38ms/step - loss: 0.4379 - acc: 0.8068 - val_loss: 0.5656 - val_acc: 0.7050\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.4166 - acc: 0.8185 - val_loss: 0.6824 - val_acc: 0.6979\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 244s 39ms/step - loss: 0.4020 - acc: 0.8303 - val_loss: 0.6735 - val_acc: 0.7262\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4289 - acc: 0.8085 - val_loss: 0.6806 - val_acc: 0.7078\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.4029 - acc: 0.8261 - val_loss: 0.6929 - val_acc: 0.6950\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 249s 39ms/step - loss: 0.4026 - acc: 0.8281 - val_loss: 0.7359 - val_acc: 0.6965\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.4115 - acc: 0.8270 - val_loss: 0.7379 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00828498974442.\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 248s 39ms/step - loss: 0.3816 - acc: 0.8429 - val_loss: 0.6996 - val_acc: 0.7007\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.3506 - acc: 0.8639 - val_loss: 0.6951 - val_acc: 0.7092\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.3313 - acc: 0.8678 - val_loss: 0.7216 - val_acc: 0.6851\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3147 - acc: 0.8797 - val_loss: 0.8283 - val_acc: 0.6965\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.3187 - acc: 0.8742 - val_loss: 0.8337 - val_acc: 0.6993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.2950 - acc: 0.8890 - val_loss: 0.7160 - val_acc: 0.7149\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.2898 - acc: 0.8849 - val_loss: 0.8097 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00414249487221.\n",
      "score: 0.806102385615\n",
      "acc: 0.703546099291\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.9277 - acc: 0.4950 - val_loss: 0.6977 - val_acc: 0.5092\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.7517 - acc: 0.4983 - val_loss: 0.7197 - val_acc: 0.4979\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.7572 - acc: 0.5023 - val_loss: 0.7641 - val_acc: 0.4979\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.7647 - acc: 0.4865 - val_loss: 0.7831 - val_acc: 0.4993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.7736 - acc: 0.5042 - val_loss: 0.7224 - val_acc: 0.4879\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.7518 - acc: 0.4944 - val_loss: 0.7691 - val_acc: 0.4993\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.7588 - acc: 0.4991 - val_loss: 0.7575 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.7550 - acc: 0.5059 - val_loss: 0.7686 - val_acc: 0.5035\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.7561 - acc: 0.5143 - val_loss: 0.8878 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.040528818965.\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.7171 - acc: 0.5190 - val_loss: 0.7060 - val_acc: 0.5064\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.7083 - acc: 0.5297 - val_loss: 0.7223 - val_acc: 0.5050\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.7037 - acc: 0.5334 - val_loss: 0.6949 - val_acc: 0.5305\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.7016 - acc: 0.5405 - val_loss: 1.1677 - val_acc: 0.5007\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.7053 - acc: 0.5512 - val_loss: 0.8629 - val_acc: 0.5206\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.6920 - acc: 0.5668 - val_loss: 0.7492 - val_acc: 0.5078\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6894 - acc: 0.5665 - val_loss: 0.7596 - val_acc: 0.4993\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6991 - acc: 0.5565 - val_loss: 0.7358 - val_acc: 0.5149\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6937 - acc: 0.5625 - val_loss: 0.8496 - val_acc: 0.5376\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6936 - acc: 0.5603 - val_loss: 0.7042 - val_acc: 0.5688\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6907 - acc: 0.5739 - val_loss: 0.7997 - val_acc: 0.5078\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0202644094825.\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.6745 - acc: 0.5854 - val_loss: 0.7356 - val_acc: 0.5489\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6682 - acc: 0.6027 - val_loss: 0.6789 - val_acc: 0.5688\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.6786 - acc: 0.5856 - val_loss: 0.7494 - val_acc: 0.5220\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.6667 - acc: 0.6038 - val_loss: 0.7010 - val_acc: 0.5390\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.6598 - acc: 0.6173 - val_loss: 0.7122 - val_acc: 0.5475\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 143s 22ms/step - loss: 0.6600 - acc: 0.6168 - val_loss: 0.7102 - val_acc: 0.5518\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.6610 - acc: 0.6111 - val_loss: 0.6892 - val_acc: 0.5574\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.6595 - acc: 0.6133 - val_loss: 0.6892 - val_acc: 0.5759\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.6545 - acc: 0.6229 - val_loss: 0.6891 - val_acc: 0.5787\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6560 - acc: 0.6272 - val_loss: 0.7412 - val_acc: 0.5489\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0101322047412.\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6473 - acc: 0.6281 - val_loss: 0.6700 - val_acc: 0.6000\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6355 - acc: 0.6404 - val_loss: 0.6724 - val_acc: 0.5915\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.6363 - acc: 0.6419 - val_loss: 0.6672 - val_acc: 0.5986\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.6361 - acc: 0.6426 - val_loss: 0.6687 - val_acc: 0.6170\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 158s 25ms/step - loss: 0.6241 - acc: 0.6606 - val_loss: 0.6786 - val_acc: 0.6028\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.6247 - acc: 0.6598 - val_loss: 0.6725 - val_acc: 0.6227\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.6184 - acc: 0.6666 - val_loss: 0.6797 - val_acc: 0.6270\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.6182 - acc: 0.6683 - val_loss: 0.6518 - val_acc: 0.6355\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.6147 - acc: 0.6638 - val_loss: 0.6549 - val_acc: 0.6369\n",
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.6071 - acc: 0.6742 - val_loss: 0.6625 - val_acc: 0.6440\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.6116 - acc: 0.6745 - val_loss: 0.6546 - val_acc: 0.6397\n",
      "Epoch 42/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.6036 - acc: 0.6803 - val_loss: 0.6585 - val_acc: 0.6156\n",
      "Epoch 43/100\n",
      "6341/6341 [==============================] - 156s 25ms/step - loss: 0.6033 - acc: 0.6835 - val_loss: 0.6598 - val_acc: 0.6340\n",
      "Epoch 44/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.5869 - acc: 0.6911 - val_loss: 0.6765 - val_acc: 0.6340\n",
      "Epoch 45/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.5922 - acc: 0.6873 - val_loss: 0.6631 - val_acc: 0.6652\n",
      "Epoch 46/100\n",
      "6341/6341 [==============================] - 155s 25ms/step - loss: 0.5821 - acc: 0.7024 - val_loss: 0.6560 - val_acc: 0.6099\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00506610237062.\n",
      "Epoch 47/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.5839 - acc: 0.6959 - val_loss: 0.6692 - val_acc: 0.6170\n",
      "Epoch 48/100\n",
      "6341/6341 [==============================] - 155s 25ms/step - loss: 0.5730 - acc: 0.7038 - val_loss: 0.6856 - val_acc: 0.6227\n",
      "Epoch 49/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.5668 - acc: 0.7111 - val_loss: 0.6689 - val_acc: 0.6312\n",
      "Epoch 50/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.5727 - acc: 0.7065 - val_loss: 0.6767 - val_acc: 0.6383\n",
      "Epoch 51/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.5644 - acc: 0.7155 - val_loss: 0.6582 - val_acc: 0.6284\n",
      "Epoch 52/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.5664 - acc: 0.7116 - val_loss: 0.6513 - val_acc: 0.6454\n",
      "Epoch 53/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.5598 - acc: 0.7152 - val_loss: 0.6695 - val_acc: 0.6326\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.5589 - acc: 0.7158 - val_loss: 0.6700 - val_acc: 0.6440\n",
      "Epoch 55/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5550 - acc: 0.7251 - val_loss: 0.6609 - val_acc: 0.6397\n",
      "Epoch 56/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.5545 - acc: 0.7220 - val_loss: 0.6541 - val_acc: 0.6496\n",
      "Epoch 57/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.5479 - acc: 0.7220 - val_loss: 0.6757 - val_acc: 0.6482\n",
      "Epoch 58/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.5488 - acc: 0.7239 - val_loss: 0.6786 - val_acc: 0.6440\n",
      "Epoch 59/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.5468 - acc: 0.7294 - val_loss: 0.6756 - val_acc: 0.6411\n",
      "Epoch 60/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.5499 - acc: 0.7275 - val_loss: 0.6839 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00253305118531.\n",
      "Epoch 61/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5372 - acc: 0.7358 - val_loss: 0.6818 - val_acc: 0.6482\n",
      "Epoch 62/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.5290 - acc: 0.7384 - val_loss: 0.6853 - val_acc: 0.6496\n",
      "Epoch 63/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.5319 - acc: 0.7404 - val_loss: 0.6965 - val_acc: 0.6511\n",
      "Epoch 64/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.5333 - acc: 0.7445 - val_loss: 0.6993 - val_acc: 0.6369\n",
      "Epoch 65/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.5322 - acc: 0.7423 - val_loss: 0.6854 - val_acc: 0.6312\n",
      "Epoch 66/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.5305 - acc: 0.7422 - val_loss: 0.7038 - val_acc: 0.6454\n",
      "Epoch 67/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.5295 - acc: 0.7508 - val_loss: 0.7032 - val_acc: 0.6355\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00126652559265.\n",
      "score: 0.700755461765\n",
      "acc: 0.635460992908\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 42s 7ms/step - loss: 0.8647 - acc: 0.5032 - val_loss: 0.7228 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7272 - acc: 0.5081 - val_loss: 0.7017 - val_acc: 0.5291\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7310 - acc: 0.5209 - val_loss: 0.7300 - val_acc: 0.4993\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.7251 - acc: 0.5252 - val_loss: 0.7434 - val_acc: 0.4355\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7310 - acc: 0.5089 - val_loss: 0.7337 - val_acc: 0.4582\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7290 - acc: 0.5293 - val_loss: 0.7300 - val_acc: 0.5418\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7274 - acc: 0.5330 - val_loss: 0.7192 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7246 - acc: 0.5288 - val_loss: 0.7137 - val_acc: 0.5035\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7363 - acc: 0.5166 - val_loss: 0.7139 - val_acc: 0.5106\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7263 - acc: 0.5285 - val_loss: 0.7208 - val_acc: 0.5064\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.048044256866.\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7127 - acc: 0.5449 - val_loss: 0.6960 - val_acc: 0.5830\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7012 - acc: 0.5692 - val_loss: 0.6952 - val_acc: 0.5972\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6956 - acc: 0.5947 - val_loss: 0.6803 - val_acc: 0.6057\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6896 - acc: 0.6032 - val_loss: 0.6872 - val_acc: 0.6000\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6955 - acc: 0.5979 - val_loss: 0.6936 - val_acc: 0.6071\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6754 - acc: 0.6291 - val_loss: 0.6916 - val_acc: 0.6142\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6775 - acc: 0.6232 - val_loss: 0.6685 - val_acc: 0.6397\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6625 - acc: 0.6415 - val_loss: 0.6356 - val_acc: 0.6851\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 35s 5ms/step - loss: 0.6617 - acc: 0.6480 - val_loss: 0.6479 - val_acc: 0.6652\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6655 - acc: 0.6335 - val_loss: 0.6600 - val_acc: 0.6539\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6626 - acc: 0.6513 - val_loss: 0.6601 - val_acc: 0.6482\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6518 - acc: 0.6644 - val_loss: 0.6616 - val_acc: 0.6596\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6679 - acc: 0.6466 - val_loss: 0.6692 - val_acc: 0.6440\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6540 - acc: 0.6605 - val_loss: 0.6416 - val_acc: 0.6950\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6403 - acc: 0.6773 - val_loss: 0.6605 - val_acc: 0.6936\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6185 - acc: 0.7037 - val_loss: 0.6342 - val_acc: 0.7064\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6168 - acc: 0.6966 - val_loss: 0.6304 - val_acc: 0.6879\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6116 - acc: 0.7092 - val_loss: 0.6458 - val_acc: 0.6950\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6136 - acc: 0.7067 - val_loss: 0.6509 - val_acc: 0.6695\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6173 - acc: 0.7064 - val_loss: 0.6235 - val_acc: 0.7050\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5984 - acc: 0.7169 - val_loss: 0.6315 - val_acc: 0.7078\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5988 - acc: 0.7283 - val_loss: 0.6140 - val_acc: 0.7262\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5841 - acc: 0.7354 - val_loss: 0.6881 - val_acc: 0.6752\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5875 - acc: 0.7297 - val_loss: 0.6020 - val_acc: 0.7106\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5921 - acc: 0.7229 - val_loss: 0.6409 - val_acc: 0.7021\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6028 - acc: 0.7157 - val_loss: 0.6062 - val_acc: 0.7078\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5898 - acc: 0.7294 - val_loss: 0.6203 - val_acc: 0.7163\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5876 - acc: 0.7418 - val_loss: 0.6109 - val_acc: 0.7092\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5916 - acc: 0.7347 - val_loss: 0.6581 - val_acc: 0.7121\n",
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.5824 - acc: 0.7381 - val_loss: 0.6604 - val_acc: 0.7163\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5701 - acc: 0.7502 - val_loss: 0.5922 - val_acc: 0.7262\n",
      "Epoch 42/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5783 - acc: 0.7355 - val_loss: 0.6220 - val_acc: 0.6993\n",
      "Epoch 43/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5609 - acc: 0.7554 - val_loss: 0.6064 - val_acc: 0.7021\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5752 - acc: 0.7486 - val_loss: 0.6397 - val_acc: 0.7121\n",
      "Epoch 45/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5861 - acc: 0.7382 - val_loss: 0.6159 - val_acc: 0.7305\n",
      "Epoch 46/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5762 - acc: 0.7428 - val_loss: 0.5846 - val_acc: 0.7248\n",
      "Epoch 47/100\n",
      "6341/6341 [==============================] - 35s 5ms/step - loss: 0.5699 - acc: 0.7469 - val_loss: 0.6118 - val_acc: 0.6993\n",
      "Epoch 48/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5729 - acc: 0.7453 - val_loss: 0.6022 - val_acc: 0.7149\n",
      "Epoch 49/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5670 - acc: 0.7456 - val_loss: 0.6923 - val_acc: 0.6681\n",
      "Epoch 50/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5607 - acc: 0.7586 - val_loss: 0.6217 - val_acc: 0.7064\n",
      "Epoch 51/100\n",
      "6341/6341 [==============================] - 35s 5ms/step - loss: 0.5948 - acc: 0.7254 - val_loss: 0.6339 - val_acc: 0.6922\n",
      "Epoch 52/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5616 - acc: 0.7568 - val_loss: 0.6208 - val_acc: 0.6865\n",
      "Epoch 53/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5751 - acc: 0.7504 - val_loss: 0.6418 - val_acc: 0.7035\n",
      "Epoch 54/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5620 - acc: 0.7534 - val_loss: 0.6165 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.024022128433.\n",
      "Epoch 55/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5411 - acc: 0.7709 - val_loss: 0.6120 - val_acc: 0.7305\n",
      "Epoch 56/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5203 - acc: 0.7803 - val_loss: 0.6111 - val_acc: 0.7220\n",
      "Epoch 57/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5147 - acc: 0.7835 - val_loss: 0.6528 - val_acc: 0.7121\n",
      "Epoch 58/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.5016 - acc: 0.7944 - val_loss: 0.6329 - val_acc: 0.7177\n",
      "Epoch 59/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4935 - acc: 0.7986 - val_loss: 0.6669 - val_acc: 0.7348\n",
      "Epoch 60/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4848 - acc: 0.8046 - val_loss: 0.5754 - val_acc: 0.7234\n",
      "Epoch 61/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4706 - acc: 0.8144 - val_loss: 0.6484 - val_acc: 0.7106\n",
      "Epoch 62/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4807 - acc: 0.8108 - val_loss: 0.7798 - val_acc: 0.7177\n",
      "Epoch 63/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4651 - acc: 0.8177 - val_loss: 0.6346 - val_acc: 0.7163\n",
      "Epoch 64/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4578 - acc: 0.8272 - val_loss: 0.6675 - val_acc: 0.7262\n",
      "Epoch 65/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4621 - acc: 0.8194 - val_loss: 0.6441 - val_acc: 0.7064\n",
      "Epoch 66/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.4488 - acc: 0.8303 - val_loss: 0.7219 - val_acc: 0.7262\n",
      "Epoch 67/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4388 - acc: 0.8360 - val_loss: 0.6932 - val_acc: 0.7163\n",
      "Epoch 68/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4532 - acc: 0.8212 - val_loss: 0.7314 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0120110642165.\n",
      "Epoch 69/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4276 - acc: 0.8469 - val_loss: 0.6543 - val_acc: 0.7220\n",
      "Epoch 70/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.4041 - acc: 0.8578 - val_loss: 0.6898 - val_acc: 0.7333\n",
      "Epoch 71/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3922 - acc: 0.8680 - val_loss: 0.6631 - val_acc: 0.7277\n",
      "Epoch 72/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3871 - acc: 0.8664 - val_loss: 0.7229 - val_acc: 0.7333\n",
      "Epoch 73/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3722 - acc: 0.8730 - val_loss: 0.8227 - val_acc: 0.7262\n",
      "Epoch 74/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3746 - acc: 0.8691 - val_loss: 0.7446 - val_acc: 0.7177\n",
      "Epoch 75/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.3703 - acc: 0.8760 - val_loss: 0.7754 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00600553210825.\n",
      "score: 0.72987460097\n",
      "acc: 0.723404255319\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.6944 - acc: 0.5021 - val_loss: 0.6938 - val_acc: 0.5035\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.6928 - acc: 0.5245 - val_loss: 0.6924 - val_acc: 0.5050\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.6864 - acc: 0.5647 - val_loss: 0.6787 - val_acc: 0.5887\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.6525 - acc: 0.6417 - val_loss: 0.6510 - val_acc: 0.6312\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.6006 - acc: 0.6862 - val_loss: 0.6315 - val_acc: 0.6397\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5703 - acc: 0.7171 - val_loss: 0.5475 - val_acc: 0.7163\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5299 - acc: 0.7401 - val_loss: 0.6030 - val_acc: 0.6624\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5041 - acc: 0.7608 - val_loss: 0.6075 - val_acc: 0.6993\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4898 - acc: 0.7636 - val_loss: 0.5150 - val_acc: 0.7191\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4719 - acc: 0.7775 - val_loss: 0.6285 - val_acc: 0.7007\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4602 - acc: 0.7819 - val_loss: 0.4947 - val_acc: 0.7447\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4449 - acc: 0.7988 - val_loss: 0.4730 - val_acc: 0.7617\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4299 - acc: 0.8074 - val_loss: 0.4937 - val_acc: 0.7518\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4143 - acc: 0.8120 - val_loss: 0.4993 - val_acc: 0.7574\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4029 - acc: 0.8150 - val_loss: 0.4508 - val_acc: 0.7858\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3971 - acc: 0.8196 - val_loss: 0.4398 - val_acc: 0.7887\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3835 - acc: 0.8325 - val_loss: 0.4957 - val_acc: 0.7603\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3727 - acc: 0.8350 - val_loss: 0.4609 - val_acc: 0.7830\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3757 - acc: 0.8317 - val_loss: 0.4647 - val_acc: 0.7674\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3685 - acc: 0.8355 - val_loss: 0.4571 - val_acc: 0.7674\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3635 - acc: 0.8412 - val_loss: 0.4628 - val_acc: 0.7603\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3532 - acc: 0.8478 - val_loss: 0.4721 - val_acc: 0.7730\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.3443 - acc: 0.8499 - val_loss: 0.4580 - val_acc: 0.7716\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.3385 - acc: 0.8503 - val_loss: 0.4457 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.000589987379499.\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3122 - acc: 0.8697 - val_loss: 0.4701 - val_acc: 0.7816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3062 - acc: 0.8727 - val_loss: 0.4618 - val_acc: 0.7730\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3020 - acc: 0.8757 - val_loss: 0.4996 - val_acc: 0.7702\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2892 - acc: 0.8778 - val_loss: 0.5080 - val_acc: 0.7631\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2878 - acc: 0.8762 - val_loss: 0.4667 - val_acc: 0.7787\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.2825 - acc: 0.8850 - val_loss: 0.4861 - val_acc: 0.7660\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2816 - acc: 0.8849 - val_loss: 0.4707 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.000294993689749.\n",
      "score: 0.46983316309\n",
      "acc: 0.782978723404\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 85s 13ms/step - loss: 0.7234 - acc: 0.4928 - val_loss: 0.7203 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7082 - acc: 0.5570 - val_loss: 0.7754 - val_acc: 0.5234\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6502 - acc: 0.6609 - val_loss: 0.6095 - val_acc: 0.6879\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.5600 - acc: 0.7381 - val_loss: 0.5504 - val_acc: 0.7504\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5275 - acc: 0.7623 - val_loss: 0.5096 - val_acc: 0.7730\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4999 - acc: 0.7800 - val_loss: 0.5569 - val_acc: 0.7305\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4773 - acc: 0.7950 - val_loss: 0.4932 - val_acc: 0.7787\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4522 - acc: 0.8138 - val_loss: 0.4794 - val_acc: 0.7872\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4434 - acc: 0.8166 - val_loss: 0.4981 - val_acc: 0.7773\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4113 - acc: 0.8360 - val_loss: 0.5241 - val_acc: 0.7617\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3924 - acc: 0.8462 - val_loss: 0.4606 - val_acc: 0.7957\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.3719 - acc: 0.8615 - val_loss: 0.4611 - val_acc: 0.7943\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3501 - acc: 0.8734 - val_loss: 0.4786 - val_acc: 0.7986\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.3226 - acc: 0.8830 - val_loss: 0.4980 - val_acc: 0.7887\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3045 - acc: 0.8904 - val_loss: 0.5211 - val_acc: 0.8000\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2832 - acc: 0.9033 - val_loss: 0.5875 - val_acc: 0.7816\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2609 - acc: 0.9156 - val_loss: 0.5759 - val_acc: 0.7901\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2442 - acc: 0.9232 - val_loss: 0.5347 - val_acc: 0.8028\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.2250 - acc: 0.9308 - val_loss: 0.7141 - val_acc: 0.7730\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00300361518748.\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1720 - acc: 0.9560 - val_loss: 0.7319 - val_acc: 0.7957\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1515 - acc: 0.9644 - val_loss: 0.7798 - val_acc: 0.7816\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.1287 - acc: 0.9726 - val_loss: 0.8721 - val_acc: 0.7957\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1067 - acc: 0.9831 - val_loss: 1.3631 - val_acc: 0.7844\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1040 - acc: 0.9838 - val_loss: 1.2830 - val_acc: 0.7887\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.0924 - acc: 0.9880 - val_loss: 1.4857 - val_acc: 0.7901\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.0918 - acc: 0.9883 - val_loss: 1.4102 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00150180759374.\n",
      "score: 1.36988150335\n",
      "acc: 0.784397163121\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.7224 - acc: 0.4999 - val_loss: 0.7205 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7013 - acc: 0.5706 - val_loss: 0.6850 - val_acc: 0.6312\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6612 - acc: 0.6546 - val_loss: 0.6603 - val_acc: 0.6582\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6315 - acc: 0.6922 - val_loss: 0.6590 - val_acc: 0.6681\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6005 - acc: 0.7177 - val_loss: 0.6286 - val_acc: 0.6879\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5824 - acc: 0.7299 - val_loss: 0.5994 - val_acc: 0.7149\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5585 - acc: 0.7504 - val_loss: 0.5800 - val_acc: 0.7362\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5351 - acc: 0.7661 - val_loss: 0.6288 - val_acc: 0.7149\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4983 - acc: 0.7917 - val_loss: 0.5170 - val_acc: 0.7489\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4741 - acc: 0.7999 - val_loss: 0.5172 - val_acc: 0.7404\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4629 - acc: 0.8098 - val_loss: 0.5054 - val_acc: 0.7787\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4410 - acc: 0.8248 - val_loss: 0.5083 - val_acc: 0.7816\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4449 - acc: 0.8201 - val_loss: 0.6519 - val_acc: 0.7248\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4264 - acc: 0.8320 - val_loss: 0.5704 - val_acc: 0.7447\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4124 - acc: 0.8417 - val_loss: 0.5037 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3964 - acc: 0.8492 - val_loss: 0.5393 - val_acc: 0.7773\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3794 - acc: 0.8573 - val_loss: 0.4789 - val_acc: 0.8028\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3717 - acc: 0.8612 - val_loss: 0.4559 - val_acc: 0.8170\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3563 - acc: 0.8666 - val_loss: 0.4626 - val_acc: 0.8028\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.3402 - acc: 0.8764 - val_loss: 0.5221 - val_acc: 0.7688\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3322 - acc: 0.8795 - val_loss: 0.4573 - val_acc: 0.8170\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3250 - acc: 0.8797 - val_loss: 0.4529 - val_acc: 0.8340\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3185 - acc: 0.8866 - val_loss: 0.6284 - val_acc: 0.7589\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3060 - acc: 0.8921 - val_loss: 0.5027 - val_acc: 0.8099\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2853 - acc: 0.9043 - val_loss: 0.6172 - val_acc: 0.7730\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.2803 - acc: 0.9066 - val_loss: 0.5493 - val_acc: 0.7943\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.2675 - acc: 0.9115 - val_loss: 0.6549 - val_acc: 0.7688\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2551 - acc: 0.9200 - val_loss: 0.5476 - val_acc: 0.8241\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2526 - acc: 0.9193 - val_loss: 0.6432 - val_acc: 0.7915\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2351 - acc: 0.9292 - val_loss: 0.6055 - val_acc: 0.7986\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00123043113854.\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1980 - acc: 0.9472 - val_loss: 0.6741 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1851 - acc: 0.9499 - val_loss: 0.7156 - val_acc: 0.7943\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.1770 - acc: 0.9543 - val_loss: 0.7951 - val_acc: 0.7972\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.1694 - acc: 0.9569 - val_loss: 0.7981 - val_acc: 0.8043\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.1599 - acc: 0.9640 - val_loss: 0.8253 - val_acc: 0.8057\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1545 - acc: 0.9667 - val_loss: 0.8553 - val_acc: 0.7929\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.1449 - acc: 0.9683 - val_loss: 0.9377 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.000615215569269.\n",
      "score: 0.897641405867\n",
      "acc: 0.792907801418\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.7238 - acc: 0.5001 - val_loss: 0.7218 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7220 - acc: 0.5116 - val_loss: 0.7199 - val_acc: 0.5035\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6936 - acc: 0.5975 - val_loss: 0.7071 - val_acc: 0.6468\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6362 - acc: 0.6862 - val_loss: 0.6707 - val_acc: 0.6624\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6036 - acc: 0.7166 - val_loss: 0.6719 - val_acc: 0.6383\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5774 - acc: 0.7398 - val_loss: 0.5958 - val_acc: 0.7191\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5516 - acc: 0.7582 - val_loss: 0.5999 - val_acc: 0.7163\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5344 - acc: 0.7691 - val_loss: 0.5706 - val_acc: 0.7475\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5104 - acc: 0.7849 - val_loss: 0.6272 - val_acc: 0.7277\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4947 - acc: 0.7953 - val_loss: 0.5809 - val_acc: 0.7404\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4791 - acc: 0.8065 - val_loss: 0.5314 - val_acc: 0.7745\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4593 - acc: 0.8172 - val_loss: 0.5158 - val_acc: 0.7716\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4532 - acc: 0.8172 - val_loss: 0.5190 - val_acc: 0.7645\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4392 - acc: 0.8265 - val_loss: 0.4701 - val_acc: 0.7957\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4200 - acc: 0.8361 - val_loss: 0.5045 - val_acc: 0.7759\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4047 - acc: 0.8420 - val_loss: 0.5591 - val_acc: 0.7816\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3902 - acc: 0.8524 - val_loss: 0.4725 - val_acc: 0.8014\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3770 - acc: 0.8595 - val_loss: 0.5259 - val_acc: 0.7830\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3641 - acc: 0.8647 - val_loss: 0.5252 - val_acc: 0.7830\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.3555 - acc: 0.8693 - val_loss: 0.4879 - val_acc: 0.7929\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3417 - acc: 0.8775 - val_loss: 0.4950 - val_acc: 0.7915\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3263 - acc: 0.8852 - val_loss: 0.4824 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00104384217411.\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.2846 - acc: 0.9038 - val_loss: 0.4964 - val_acc: 0.8170\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2792 - acc: 0.9076 - val_loss: 0.4985 - val_acc: 0.8014\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2643 - acc: 0.9147 - val_loss: 0.5550 - val_acc: 0.8014\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2560 - acc: 0.9166 - val_loss: 0.5405 - val_acc: 0.8099\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.2505 - acc: 0.9227 - val_loss: 0.5362 - val_acc: 0.8028\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2409 - acc: 0.9273 - val_loss: 0.6096 - val_acc: 0.7773\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.2407 - acc: 0.9273 - val_loss: 0.5925 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000521921087056.\n",
      "score: 0.555450440631\n",
      "acc: 0.78865248227\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 81s 13ms/step - loss: 0.7315 - acc: 0.5163 - val_loss: 0.7038 - val_acc: 0.5660\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6465 - acc: 0.6661 - val_loss: 0.5931 - val_acc: 0.7106\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5979 - acc: 0.7152 - val_loss: 0.5864 - val_acc: 0.7078\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5623 - acc: 0.7365 - val_loss: 0.6023 - val_acc: 0.7177\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5236 - acc: 0.7683 - val_loss: 0.6220 - val_acc: 0.7248\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4843 - acc: 0.7928 - val_loss: 0.5436 - val_acc: 0.7504\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4579 - acc: 0.8169 - val_loss: 0.5983 - val_acc: 0.7489\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4301 - acc: 0.8308 - val_loss: 0.5359 - val_acc: 0.7475\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4052 - acc: 0.8426 - val_loss: 0.5524 - val_acc: 0.7716\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3762 - acc: 0.8604 - val_loss: 0.6054 - val_acc: 0.7404\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3571 - acc: 0.8678 - val_loss: 0.6344 - val_acc: 0.7532\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3485 - acc: 0.8702 - val_loss: 0.6455 - val_acc: 0.7631\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3245 - acc: 0.8847 - val_loss: 0.6408 - val_acc: 0.7660\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2965 - acc: 0.8973 - val_loss: 0.7818 - val_acc: 0.7433\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.2715 - acc: 0.9133 - val_loss: 0.8031 - val_acc: 0.7560\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.2772 - acc: 0.9125 - val_loss: 0.7873 - val_acc: 0.7291\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00817864947021.\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2022 - acc: 0.9442 - val_loss: 0.9104 - val_acc: 0.7404\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1563 - acc: 0.9634 - val_loss: 1.1783 - val_acc: 0.7390\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.1416 - acc: 0.9696 - val_loss: 1.1815 - val_acc: 0.7546\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1276 - acc: 0.9749 - val_loss: 1.3309 - val_acc: 0.7404\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.1157 - acc: 0.9817 - val_loss: 1.6117 - val_acc: 0.7291\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1128 - acc: 0.9804 - val_loss: 1.5126 - val_acc: 0.7518\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.1012 - acc: 0.9856 - val_loss: 1.8647 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00408932473511.\n",
      "score: 1.82857836804\n",
      "acc: 0.740425531915\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 79s 13ms/step - loss: 0.7232 - acc: 0.5070 - val_loss: 0.7219 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7222 - acc: 0.5075 - val_loss: 0.7182 - val_acc: 0.5617\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7051 - acc: 0.5785 - val_loss: 0.7014 - val_acc: 0.5433\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.6579 - acc: 0.6508 - val_loss: 0.6504 - val_acc: 0.6936\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6211 - acc: 0.7032 - val_loss: 0.5922 - val_acc: 0.7163\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5773 - acc: 0.7403 - val_loss: 0.6080 - val_acc: 0.7291\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5371 - acc: 0.7593 - val_loss: 0.5971 - val_acc: 0.7106\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5249 - acc: 0.7685 - val_loss: 0.5808 - val_acc: 0.7305\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5095 - acc: 0.7819 - val_loss: 0.5296 - val_acc: 0.7660\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5096 - acc: 0.7839 - val_loss: 0.5375 - val_acc: 0.7574\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4977 - acc: 0.7869 - val_loss: 0.5520 - val_acc: 0.7504\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4773 - acc: 0.8003 - val_loss: 0.5090 - val_acc: 0.7688\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4544 - acc: 0.8163 - val_loss: 0.6612 - val_acc: 0.7248\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4394 - acc: 0.8238 - val_loss: 0.5574 - val_acc: 0.7858\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4405 - acc: 0.8243 - val_loss: 0.4862 - val_acc: 0.7915\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4303 - acc: 0.8286 - val_loss: 0.5116 - val_acc: 0.7787\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4247 - acc: 0.8300 - val_loss: 0.4703 - val_acc: 0.8071\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4110 - acc: 0.8402 - val_loss: 0.5244 - val_acc: 0.7674\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4024 - acc: 0.8480 - val_loss: 0.5167 - val_acc: 0.7745\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3997 - acc: 0.8472 - val_loss: 0.4755 - val_acc: 0.7957\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3870 - acc: 0.8548 - val_loss: 0.4904 - val_acc: 0.7830\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3812 - acc: 0.8595 - val_loss: 0.4853 - val_acc: 0.7872\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3727 - acc: 0.8615 - val_loss: 0.4995 - val_acc: 0.7830\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3668 - acc: 0.8650 - val_loss: 0.4907 - val_acc: 0.7887\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3667 - acc: 0.8686 - val_loss: 0.6195 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.000584745081142.\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3235 - acc: 0.8846 - val_loss: 0.4724 - val_acc: 0.8043\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3153 - acc: 0.8879 - val_loss: 0.4958 - val_acc: 0.7972\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3088 - acc: 0.8947 - val_loss: 0.5352 - val_acc: 0.7830\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3061 - acc: 0.8967 - val_loss: 0.4964 - val_acc: 0.8057\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2974 - acc: 0.9044 - val_loss: 0.5765 - val_acc: 0.7887\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2938 - acc: 0.8980 - val_loss: 0.5072 - val_acc: 0.8099\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2839 - acc: 0.9085 - val_loss: 0.5473 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.000292372540571.\n",
      "score: 0.511931981763\n",
      "acc: 0.794326241135\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.7485 - acc: 0.5113 - val_loss: 0.7139 - val_acc: 0.5021\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6585 - acc: 0.6461 - val_loss: 0.6544 - val_acc: 0.6440\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5911 - acc: 0.7112 - val_loss: 0.6775 - val_acc: 0.6496\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5779 - acc: 0.7235 - val_loss: 0.6638 - val_acc: 0.6298\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5582 - acc: 0.7431 - val_loss: 0.6933 - val_acc: 0.6610\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.5416 - acc: 0.7565 - val_loss: 0.5854 - val_acc: 0.7078\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.5164 - acc: 0.7675 - val_loss: 0.6060 - val_acc: 0.7007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5012 - acc: 0.7764 - val_loss: 0.7538 - val_acc: 0.6922\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4827 - acc: 0.7951 - val_loss: 0.6317 - val_acc: 0.7050\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4618 - acc: 0.7988 - val_loss: 0.6883 - val_acc: 0.7149\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4599 - acc: 0.8098 - val_loss: 0.7132 - val_acc: 0.7092\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.4601 - acc: 0.8190 - val_loss: 0.6617 - val_acc: 0.7135\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4219 - acc: 0.8283 - val_loss: 0.7257 - val_acc: 0.7092\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4098 - acc: 0.8309 - val_loss: 0.6755 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0156316459179.\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.3590 - acc: 0.8607 - val_loss: 0.8215 - val_acc: 0.7035\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2944 - acc: 0.8980 - val_loss: 0.9109 - val_acc: 0.6908\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.3057 - acc: 0.8964 - val_loss: 0.9480 - val_acc: 0.6936\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3025 - acc: 0.8980 - val_loss: 0.9372 - val_acc: 0.7106\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2587 - acc: 0.9175 - val_loss: 1.1168 - val_acc: 0.6979\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.2281 - acc: 0.9273 - val_loss: 1.2866 - val_acc: 0.6979\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.2120 - acc: 0.9368 - val_loss: 1.2059 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00781582295895.\n",
      "score: 1.17388012512\n",
      "acc: 0.702127659574\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.7182 - acc: 0.4933 - val_loss: 0.7170 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7179 - acc: 0.4987 - val_loss: 0.7167 - val_acc: 0.5007\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.7176 - acc: 0.4982 - val_loss: 0.7166 - val_acc: 0.5007\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7176 - acc: 0.5026 - val_loss: 0.7166 - val_acc: 0.5007\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.7166 - acc: 0.5009 - val_loss: 0.7163 - val_acc: 0.5021\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.7159 - acc: 0.5181 - val_loss: 0.7158 - val_acc: 0.4950\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.7107 - acc: 0.5509 - val_loss: 0.7081 - val_acc: 0.5589\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7009 - acc: 0.5972 - val_loss: 0.7029 - val_acc: 0.5929\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.6894 - acc: 0.6130 - val_loss: 0.6915 - val_acc: 0.6113\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6752 - acc: 0.6493 - val_loss: 0.6786 - val_acc: 0.6511\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6628 - acc: 0.6551 - val_loss: 0.7011 - val_acc: 0.5943\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.6477 - acc: 0.6715 - val_loss: 0.6482 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6280 - acc: 0.6928 - val_loss: 0.6258 - val_acc: 0.6936\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6141 - acc: 0.7037 - val_loss: 0.6206 - val_acc: 0.6837\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5962 - acc: 0.7198 - val_loss: 0.5937 - val_acc: 0.7078\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5862 - acc: 0.7250 - val_loss: 0.5833 - val_acc: 0.7135\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5769 - acc: 0.7333 - val_loss: 0.5790 - val_acc: 0.7163\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5615 - acc: 0.7434 - val_loss: 0.5694 - val_acc: 0.7333\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5666 - acc: 0.7455 - val_loss: 0.5632 - val_acc: 0.7319\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5330 - acc: 0.7657 - val_loss: 0.5884 - val_acc: 0.7262\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5377 - acc: 0.7567 - val_loss: 0.5776 - val_acc: 0.7248\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5273 - acc: 0.7650 - val_loss: 0.5981 - val_acc: 0.7135\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5113 - acc: 0.7768 - val_loss: 0.5708 - val_acc: 0.7390\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5091 - acc: 0.7778 - val_loss: 0.5350 - val_acc: 0.7376\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4980 - acc: 0.7862 - val_loss: 0.5779 - val_acc: 0.7121\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4916 - acc: 0.7869 - val_loss: 0.5180 - val_acc: 0.7589\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4841 - acc: 0.7880 - val_loss: 0.5332 - val_acc: 0.7504\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4820 - acc: 0.7962 - val_loss: 0.8051 - val_acc: 0.6809\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4788 - acc: 0.7956 - val_loss: 0.5368 - val_acc: 0.7489\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4614 - acc: 0.8052 - val_loss: 0.5689 - val_acc: 0.7262\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4630 - acc: 0.8071 - val_loss: 0.5314 - val_acc: 0.7433\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4582 - acc: 0.8082 - val_loss: 0.4966 - val_acc: 0.7787\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4406 - acc: 0.8175 - val_loss: 0.5104 - val_acc: 0.7532\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4493 - acc: 0.8125 - val_loss: 0.5124 - val_acc: 0.7489\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4382 - acc: 0.8224 - val_loss: 0.5118 - val_acc: 0.7518\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4356 - acc: 0.8160 - val_loss: 0.5129 - val_acc: 0.7603\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4299 - acc: 0.8231 - val_loss: 0.5193 - val_acc: 0.7730\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.4217 - acc: 0.8249 - val_loss: 0.5362 - val_acc: 0.7504\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4230 - acc: 0.8281 - val_loss: 0.5201 - val_acc: 0.7745\n",
      "Epoch 40/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4148 - acc: 0.8297 - val_loss: 0.5129 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.000153362561832.\n",
      "Epoch 41/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3951 - acc: 0.8467 - val_loss: 0.5593 - val_acc: 0.7560\n",
      "Epoch 42/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3911 - acc: 0.8464 - val_loss: 0.4990 - val_acc: 0.7745\n",
      "Epoch 43/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3892 - acc: 0.8527 - val_loss: 0.5041 - val_acc: 0.7660\n",
      "Epoch 44/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3830 - acc: 0.8530 - val_loss: 0.5359 - val_acc: 0.7745\n",
      "Epoch 45/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3818 - acc: 0.8557 - val_loss: 0.5211 - val_acc: 0.7603\n",
      "Epoch 46/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3776 - acc: 0.8579 - val_loss: 0.5038 - val_acc: 0.7745\n",
      "Epoch 47/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.3759 - acc: 0.8573 - val_loss: 0.5104 - val_acc: 0.7645\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 7.66812809161e-05.\n",
      "score: 0.484881453216\n",
      "acc: 0.764539007092\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 82s 13ms/step - loss: 0.7320 - acc: 0.5013 - val_loss: 0.7199 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7188 - acc: 0.5397 - val_loss: 0.7031 - val_acc: 0.6397\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.6353 - acc: 0.6756 - val_loss: 0.5683 - val_acc: 0.7262\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5465 - acc: 0.7474 - val_loss: 0.5314 - val_acc: 0.7348\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 66s 10ms/step - loss: 0.5088 - acc: 0.7787 - val_loss: 0.6270 - val_acc: 0.7461\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.4683 - acc: 0.7997 - val_loss: 0.4818 - val_acc: 0.7830\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.4295 - acc: 0.8237 - val_loss: 0.4969 - val_acc: 0.7858\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4057 - acc: 0.8380 - val_loss: 0.5658 - val_acc: 0.7546\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.3762 - acc: 0.8527 - val_loss: 0.5555 - val_acc: 0.7745\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 66s 10ms/step - loss: 0.3498 - acc: 0.8685 - val_loss: 0.6172 - val_acc: 0.7674\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.3259 - acc: 0.8842 - val_loss: 0.5560 - val_acc: 0.7702\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3047 - acc: 0.8962 - val_loss: 0.6362 - val_acc: 0.7688\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.2812 - acc: 0.9051 - val_loss: 0.6750 - val_acc: 0.7532\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.2679 - acc: 0.9087 - val_loss: 0.7325 - val_acc: 0.7631\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00790237262845.\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.2058 - acc: 0.9421 - val_loss: 0.8180 - val_acc: 0.7660\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 66s 10ms/step - loss: 0.1536 - acc: 0.9642 - val_loss: 1.1154 - val_acc: 0.7546\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.1339 - acc: 0.9735 - val_loss: 1.1985 - val_acc: 0.7688\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 66s 10ms/step - loss: 0.1280 - acc: 0.9733 - val_loss: 1.3197 - val_acc: 0.7433\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.1065 - acc: 0.9838 - val_loss: 1.5403 - val_acc: 0.7617\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.1027 - acc: 0.9830 - val_loss: 1.7435 - val_acc: 0.7532\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.0907 - acc: 0.9893 - val_loss: 1.8033 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00395118631423.\n",
      "score: 1.76482949796\n",
      "acc: 0.768794326241\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.7309 - acc: 0.5020 - val_loss: 0.7123 - val_acc: 0.5021\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7206 - acc: 0.4965 - val_loss: 0.7134 - val_acc: 0.5021\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6829 - acc: 0.5997 - val_loss: 0.6297 - val_acc: 0.6936\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5985 - acc: 0.7133 - val_loss: 0.6183 - val_acc: 0.6681\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.5453 - acc: 0.7541 - val_loss: 0.5295 - val_acc: 0.7475\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5132 - acc: 0.7895 - val_loss: 0.5075 - val_acc: 0.7504\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4716 - acc: 0.8043 - val_loss: 0.5091 - val_acc: 0.7830\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4530 - acc: 0.8213 - val_loss: 0.5028 - val_acc: 0.7688\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4362 - acc: 0.8273 - val_loss: 0.5406 - val_acc: 0.7773\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4188 - acc: 0.8368 - val_loss: 0.5504 - val_acc: 0.7702\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3962 - acc: 0.8455 - val_loss: 0.5293 - val_acc: 0.7872\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3913 - acc: 0.8560 - val_loss: 0.6093 - val_acc: 0.7645\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3793 - acc: 0.8596 - val_loss: 0.5293 - val_acc: 0.7532\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 79s 13ms/step - loss: 0.3608 - acc: 0.8688 - val_loss: 0.7877 - val_acc: 0.7390\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3517 - acc: 0.8762 - val_loss: 0.6240 - val_acc: 0.7404\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3413 - acc: 0.8786 - val_loss: 0.5292 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.013945389539.\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2930 - acc: 0.9021 - val_loss: 0.6602 - val_acc: 0.7688\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2393 - acc: 0.9237 - val_loss: 0.8177 - val_acc: 0.7617\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.2047 - acc: 0.9393 - val_loss: 0.8861 - val_acc: 0.7418\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.1927 - acc: 0.9457 - val_loss: 0.8782 - val_acc: 0.7518\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.1637 - acc: 0.9551 - val_loss: 1.0601 - val_acc: 0.7574\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.1571 - acc: 0.9598 - val_loss: 0.9928 - val_acc: 0.7504\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.1345 - acc: 0.9651 - val_loss: 1.3351 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0069726947695.\n",
      "score: 1.30600360914\n",
      "acc: 0.754609929078\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.7369 - acc: 0.4883 - val_loss: 0.7219 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 67s 10ms/step - loss: 0.7274 - acc: 0.5035 - val_loss: 0.7218 - val_acc: 0.5007\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.7249 - acc: 0.5084 - val_loss: 0.7055 - val_acc: 0.5532\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.6835 - acc: 0.6092 - val_loss: 0.6213 - val_acc: 0.6865\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.6374 - acc: 0.6660 - val_loss: 0.6078 - val_acc: 0.6794\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.6015 - acc: 0.7016 - val_loss: 0.5540 - val_acc: 0.7376\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.5597 - acc: 0.7376 - val_loss: 0.5636 - val_acc: 0.7305\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5383 - acc: 0.7515 - val_loss: 0.6024 - val_acc: 0.7390\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.5215 - acc: 0.7750 - val_loss: 0.5194 - val_acc: 0.7759\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4895 - acc: 0.7914 - val_loss: 0.5797 - val_acc: 0.7546\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4691 - acc: 0.7953 - val_loss: 0.5469 - val_acc: 0.7418\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4382 - acc: 0.8208 - val_loss: 0.5610 - val_acc: 0.7617\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4144 - acc: 0.8290 - val_loss: 0.5805 - val_acc: 0.7589\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.3874 - acc: 0.8425 - val_loss: 0.6600 - val_acc: 0.7447\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3732 - acc: 0.8552 - val_loss: 0.8588 - val_acc: 0.7262\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3558 - acc: 0.8634 - val_loss: 0.6647 - val_acc: 0.7546\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.3312 - acc: 0.8773 - val_loss: 0.8147 - val_acc: 0.7447\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00637420173734.\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.2667 - acc: 0.9085 - val_loss: 0.8984 - val_acc: 0.7546\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2247 - acc: 0.9248 - val_loss: 1.1182 - val_acc: 0.7362\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.2067 - acc: 0.9270 - val_loss: 1.2811 - val_acc: 0.7447\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.1795 - acc: 0.9352 - val_loss: 1.4402 - val_acc: 0.7447\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.1657 - acc: 0.9459 - val_loss: 1.6525 - val_acc: 0.7447\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.1642 - acc: 0.9464 - val_loss: 2.0840 - val_acc: 0.7433\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.1644 - acc: 0.9391 - val_loss: 2.1098 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00318710086867.\n",
      "score: 2.07282895583\n",
      "acc: 0.730496453901\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 80s 13ms/step - loss: 0.7624 - acc: 0.5693 - val_loss: 0.6061 - val_acc: 0.6965\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5991 - acc: 0.7157 - val_loss: 0.5721 - val_acc: 0.7390\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5489 - acc: 0.7521 - val_loss: 0.5960 - val_acc: 0.7121\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5331 - acc: 0.7653 - val_loss: 0.5892 - val_acc: 0.7277\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5236 - acc: 0.7645 - val_loss: 0.6080 - val_acc: 0.6723\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4939 - acc: 0.7934 - val_loss: 0.5900 - val_acc: 0.7589\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4932 - acc: 0.7959 - val_loss: 0.6750 - val_acc: 0.6851\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4888 - acc: 0.7944 - val_loss: 0.6553 - val_acc: 0.7433\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4648 - acc: 0.8073 - val_loss: 0.7443 - val_acc: 0.7234\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.4599 - acc: 0.8171 - val_loss: 0.7029 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0215291809291.\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3836 - acc: 0.8514 - val_loss: 0.6396 - val_acc: 0.7348\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.3582 - acc: 0.8707 - val_loss: 0.6235 - val_acc: 0.7589\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3312 - acc: 0.8789 - val_loss: 0.7390 - val_acc: 0.7504\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.3086 - acc: 0.8899 - val_loss: 0.7673 - val_acc: 0.7376\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2875 - acc: 0.9008 - val_loss: 0.7717 - val_acc: 0.7404\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.2713 - acc: 0.9088 - val_loss: 0.8809 - val_acc: 0.7376\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2443 - acc: 0.9196 - val_loss: 0.8640 - val_acc: 0.7248\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0107645904645.\n",
      "score: 0.835629331183\n",
      "acc: 0.724822695035\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 87s 14ms/step - loss: 0.7599 - acc: 0.5024 - val_loss: 0.7337 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7097 - acc: 0.5613 - val_loss: 0.7083 - val_acc: 0.5518\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6859 - acc: 0.6177 - val_loss: 0.6564 - val_acc: 0.6184\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.6754 - acc: 0.6251 - val_loss: 0.6586 - val_acc: 0.6099\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 79s 12ms/step - loss: 0.6766 - acc: 0.6300 - val_loss: 0.7516 - val_acc: 0.5504\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.6721 - acc: 0.6332 - val_loss: 0.6753 - val_acc: 0.6567\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6811 - acc: 0.6174 - val_loss: 0.6530 - val_acc: 0.6610\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.6768 - acc: 0.6275 - val_loss: 0.6517 - val_acc: 0.6567\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.6721 - acc: 0.6374 - val_loss: 0.6693 - val_acc: 0.6383\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.6986 - acc: 0.6021 - val_loss: 0.6732 - val_acc: 0.6468\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6911 - acc: 0.6097 - val_loss: 0.6553 - val_acc: 0.6312\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6931 - acc: 0.6158 - val_loss: 0.6536 - val_acc: 0.6255\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6875 - acc: 0.6125 - val_loss: 0.6640 - val_acc: 0.6383\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6980 - acc: 0.6020 - val_loss: 0.6594 - val_acc: 0.6312\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6904 - acc: 0.6086 - val_loss: 0.6536 - val_acc: 0.6340\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.6993 - acc: 0.6037 - val_loss: 0.6611 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0494517125189.\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6592 - acc: 0.6512 - val_loss: 0.6528 - val_acc: 0.6511\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6516 - acc: 0.6625 - val_loss: 0.6669 - val_acc: 0.6426\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6347 - acc: 0.6765 - val_loss: 0.6393 - val_acc: 0.6752\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.6499 - acc: 0.6679 - val_loss: 0.6531 - val_acc: 0.6681\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6387 - acc: 0.6688 - val_loss: 0.6276 - val_acc: 0.6738\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6473 - acc: 0.6661 - val_loss: 0.6337 - val_acc: 0.6752\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.6326 - acc: 0.6802 - val_loss: 0.6321 - val_acc: 0.6695\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.6311 - acc: 0.6854 - val_loss: 0.6231 - val_acc: 0.6851\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6287 - acc: 0.6874 - val_loss: 0.6404 - val_acc: 0.6738\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.6483 - acc: 0.6654 - val_loss: 0.6548 - val_acc: 0.6440\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 66s 10ms/step - loss: 0.6490 - acc: 0.6695 - val_loss: 0.6402 - val_acc: 0.6440\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6392 - acc: 0.6718 - val_loss: 0.6672 - val_acc: 0.6539\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 67s 11ms/step - loss: 0.6414 - acc: 0.6781 - val_loss: 0.6914 - val_acc: 0.6482\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6328 - acc: 0.6841 - val_loss: 0.6640 - val_acc: 0.6851\n",
      "Epoch 31/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6333 - acc: 0.6827 - val_loss: 0.6707 - val_acc: 0.6894\n",
      "Epoch 32/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6158 - acc: 0.6917 - val_loss: 0.6652 - val_acc: 0.6709\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0247258562595.\n",
      "Epoch 33/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.6108 - acc: 0.7087 - val_loss: 0.6518 - val_acc: 0.6780\n",
      "Epoch 34/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5938 - acc: 0.7128 - val_loss: 0.6312 - val_acc: 0.6738\n",
      "Epoch 35/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5828 - acc: 0.7202 - val_loss: 0.6389 - val_acc: 0.6582\n",
      "Epoch 36/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5865 - acc: 0.7209 - val_loss: 0.6648 - val_acc: 0.6738\n",
      "Epoch 37/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5831 - acc: 0.7292 - val_loss: 0.6301 - val_acc: 0.6879\n",
      "Epoch 38/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5821 - acc: 0.7272 - val_loss: 0.6335 - val_acc: 0.6695\n",
      "Epoch 39/100\n",
      "6341/6341 [==============================] - 68s 11ms/step - loss: 0.5734 - acc: 0.7355 - val_loss: 0.6335 - val_acc: 0.6695\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0123629281297.\n",
      "score: 0.611628400011\n",
      "acc: 0.669503546099\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 84s 13ms/step - loss: 0.9719 - acc: 0.5095 - val_loss: 0.7086 - val_acc: 0.5418\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7401 - acc: 0.5573 - val_loss: 0.6628 - val_acc: 0.6496\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.6968 - acc: 0.6132 - val_loss: 0.6259 - val_acc: 0.6851\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6348 - acc: 0.6840 - val_loss: 0.6690 - val_acc: 0.5674\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6090 - acc: 0.6980 - val_loss: 0.6382 - val_acc: 0.7121\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5951 - acc: 0.7108 - val_loss: 0.7135 - val_acc: 0.6851\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5861 - acc: 0.7190 - val_loss: 0.5773 - val_acc: 0.7248\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5715 - acc: 0.7349 - val_loss: 0.5802 - val_acc: 0.6936\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5501 - acc: 0.7469 - val_loss: 0.5805 - val_acc: 0.7248\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.5661 - acc: 0.7335 - val_loss: 0.7990 - val_acc: 0.6270\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5709 - acc: 0.7404 - val_loss: 0.5903 - val_acc: 0.7064\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.5442 - acc: 0.7529 - val_loss: 0.6186 - val_acc: 0.7007\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5812 - acc: 0.7404 - val_loss: 0.5997 - val_acc: 0.7035\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5526 - acc: 0.7445 - val_loss: 0.6619 - val_acc: 0.7106\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.5680 - acc: 0.7363 - val_loss: 0.6014 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0298893414438.\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.4972 - acc: 0.7912 - val_loss: 0.6699 - val_acc: 0.7149\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4655 - acc: 0.8065 - val_loss: 0.6405 - val_acc: 0.7177\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4706 - acc: 0.8070 - val_loss: 0.5838 - val_acc: 0.7177\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4432 - acc: 0.8163 - val_loss: 0.6332 - val_acc: 0.7121\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4315 - acc: 0.8242 - val_loss: 0.5873 - val_acc: 0.7234\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4205 - acc: 0.8309 - val_loss: 0.6496 - val_acc: 0.7305\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4148 - acc: 0.8372 - val_loss: 0.6434 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0149446707219.\n",
      "score: 0.617452250685\n",
      "acc: 0.731914893617\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 156s 25ms/step - loss: 0.7432 - acc: 0.5097 - val_loss: 0.7380 - val_acc: 0.5021\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.7276 - acc: 0.5138 - val_loss: 0.8112 - val_acc: 0.4993\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.6822 - acc: 0.6050 - val_loss: 0.7841 - val_acc: 0.5518\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.6638 - acc: 0.6378 - val_loss: 0.6464 - val_acc: 0.5702\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.6554 - acc: 0.6433 - val_loss: 0.7135 - val_acc: 0.6695\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.6536 - acc: 0.6508 - val_loss: 0.7805 - val_acc: 0.5943\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.6448 - acc: 0.6531 - val_loss: 0.6494 - val_acc: 0.6723\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6451 - acc: 0.6665 - val_loss: 0.8425 - val_acc: 0.5631\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6410 - acc: 0.6633 - val_loss: 0.6562 - val_acc: 0.6440\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.6243 - acc: 0.6721 - val_loss: 0.9205 - val_acc: 0.5787\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.6414 - acc: 0.6608 - val_loss: 0.7922 - val_acc: 0.6241\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.6799 - acc: 0.6409 - val_loss: 0.7564 - val_acc: 0.5149\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0218775272369.\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.5911 - acc: 0.6877 - val_loss: 0.6217 - val_acc: 0.6752\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.5633 - acc: 0.7261 - val_loss: 0.7160 - val_acc: 0.6411\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.5509 - acc: 0.7336 - val_loss: 0.5705 - val_acc: 0.7035\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.5262 - acc: 0.7497 - val_loss: 0.6121 - val_acc: 0.6525\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.5407 - acc: 0.7488 - val_loss: 0.7013 - val_acc: 0.6738\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5212 - acc: 0.7546 - val_loss: 0.6248 - val_acc: 0.7007\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.5205 - acc: 0.7587 - val_loss: 0.6701 - val_acc: 0.7234\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5136 - acc: 0.7641 - val_loss: 0.6337 - val_acc: 0.7163\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5035 - acc: 0.7649 - val_loss: 0.6211 - val_acc: 0.6809\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5098 - acc: 0.7705 - val_loss: 0.6155 - val_acc: 0.6823\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4967 - acc: 0.7781 - val_loss: 0.7021 - val_acc: 0.6979\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0109387636185.\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4446 - acc: 0.8087 - val_loss: 0.6395 - val_acc: 0.7035\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.4021 - acc: 0.8363 - val_loss: 0.6300 - val_acc: 0.7050\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.3859 - acc: 0.8402 - val_loss: 0.6899 - val_acc: 0.6993\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.3654 - acc: 0.8519 - val_loss: 0.7145 - val_acc: 0.7078\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.3336 - acc: 0.8648 - val_loss: 0.8713 - val_acc: 0.6993\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.3360 - acc: 0.8675 - val_loss: 0.8592 - val_acc: 0.6950\n",
      "Epoch 30/100\n",
      "6341/6341 [==============================] - 140s 22ms/step - loss: 0.3142 - acc: 0.8753 - val_loss: 0.8365 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00546938180923.\n",
      "score: 0.831681145294\n",
      "acc: 0.695035460993\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 83s 13ms/step - loss: 0.7263 - acc: 0.4991 - val_loss: 0.7158 - val_acc: 0.5021\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.6658 - acc: 0.6368 - val_loss: 0.6176 - val_acc: 0.7149\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5973 - acc: 0.7087 - val_loss: 0.5979 - val_acc: 0.7007\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5833 - acc: 0.7207 - val_loss: 0.5826 - val_acc: 0.7064\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.5535 - acc: 0.7374 - val_loss: 0.5782 - val_acc: 0.6993\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5362 - acc: 0.7526 - val_loss: 0.6023 - val_acc: 0.7035\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5266 - acc: 0.7661 - val_loss: 0.5593 - val_acc: 0.7248\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5117 - acc: 0.7792 - val_loss: 0.5733 - val_acc: 0.7206\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.5009 - acc: 0.7754 - val_loss: 0.6211 - val_acc: 0.7106\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4860 - acc: 0.7885 - val_loss: 0.6128 - val_acc: 0.7291\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4740 - acc: 0.7933 - val_loss: 0.5936 - val_acc: 0.7262\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.4578 - acc: 0.8114 - val_loss: 0.6049 - val_acc: 0.6894\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4429 - acc: 0.8108 - val_loss: 0.5959 - val_acc: 0.7277\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4286 - acc: 0.8235 - val_loss: 0.6003 - val_acc: 0.7305\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.4090 - acc: 0.8357 - val_loss: 0.6591 - val_acc: 0.7333\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0116350091994.\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3566 - acc: 0.8705 - val_loss: 0.6675 - val_acc: 0.7305\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.3156 - acc: 0.8902 - val_loss: 0.6850 - val_acc: 0.7390\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.2888 - acc: 0.8995 - val_loss: 0.7686 - val_acc: 0.7447\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2717 - acc: 0.9107 - val_loss: 0.8826 - val_acc: 0.7277\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2580 - acc: 0.9200 - val_loss: 0.8202 - val_acc: 0.7262\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.2334 - acc: 0.9237 - val_loss: 0.9084 - val_acc: 0.7234\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2120 - acc: 0.9366 - val_loss: 0.9982 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00581750459969.\n",
      "score: 0.966065152982\n",
      "acc: 0.721985815603\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 47s 7ms/step - loss: 0.7917 - acc: 0.4950 - val_loss: 0.7325 - val_acc: 0.4993\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 34s 5ms/step - loss: 0.7307 - acc: 0.5061 - val_loss: 0.7179 - val_acc: 0.5291\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7233 - acc: 0.5482 - val_loss: 0.7034 - val_acc: 0.5986\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.7088 - acc: 0.5873 - val_loss: 0.6817 - val_acc: 0.6993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6703 - acc: 0.6414 - val_loss: 0.6462 - val_acc: 0.6738\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6363 - acc: 0.6904 - val_loss: 0.5834 - val_acc: 0.7362\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5758 - acc: 0.7422 - val_loss: 0.5740 - val_acc: 0.7291\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5436 - acc: 0.7699 - val_loss: 0.6093 - val_acc: 0.7319\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4849 - acc: 0.7967 - val_loss: 0.5856 - val_acc: 0.7177\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4708 - acc: 0.8123 - val_loss: 0.7762 - val_acc: 0.7064\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4554 - acc: 0.8167 - val_loss: 0.6119 - val_acc: 0.7348\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4565 - acc: 0.8163 - val_loss: 0.6260 - val_acc: 0.7518\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4058 - acc: 0.8502 - val_loss: 0.6401 - val_acc: 0.7305\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4067 - acc: 0.8418 - val_loss: 0.8012 - val_acc: 0.6766\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4249 - acc: 0.8358 - val_loss: 0.6085 - val_acc: 0.6879\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0170522425324.\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.3519 - acc: 0.8773 - val_loss: 0.7239 - val_acc: 0.7560\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.2901 - acc: 0.9057 - val_loss: 0.7709 - val_acc: 0.7475\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.2516 - acc: 0.9238 - val_loss: 0.9213 - val_acc: 0.7362\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.2360 - acc: 0.9311 - val_loss: 1.0218 - val_acc: 0.7390\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.2073 - acc: 0.9464 - val_loss: 1.0824 - val_acc: 0.7348\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.1934 - acc: 0.9506 - val_loss: 1.1919 - val_acc: 0.7262\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.1750 - acc: 0.9582 - val_loss: 1.1734 - val_acc: 0.7489\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00852612126619.\n",
      "score: 1.12332769826\n",
      "acc: 0.748936170213\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 89s 14ms/step - loss: 0.7535 - acc: 0.4974 - val_loss: 0.7208 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.7356 - acc: 0.5045 - val_loss: 0.7208 - val_acc: 0.5007\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.7295 - acc: 0.5013 - val_loss: 0.7211 - val_acc: 0.5007\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7330 - acc: 0.5006 - val_loss: 0.7212 - val_acc: 0.5007\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7275 - acc: 0.5023 - val_loss: 0.7223 - val_acc: 0.4936\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7314 - acc: 0.4974 - val_loss: 0.7217 - val_acc: 0.5021\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7325 - acc: 0.5018 - val_loss: 0.7213 - val_acc: 0.5007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7317 - acc: 0.4990 - val_loss: 0.7211 - val_acc: 0.5007\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.7299 - acc: 0.5021 - val_loss: 0.7198 - val_acc: 0.5163\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.7337 - acc: 0.4941 - val_loss: 0.7209 - val_acc: 0.5007\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.7303 - acc: 0.4963 - val_loss: 0.7208 - val_acc: 0.5007\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7344 - acc: 0.4994 - val_loss: 0.7206 - val_acc: 0.5007\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.7320 - acc: 0.5012 - val_loss: 0.7210 - val_acc: 0.5007\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.7301 - acc: 0.5017 - val_loss: 0.7214 - val_acc: 0.5007\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7337 - acc: 0.4974 - val_loss: 0.7214 - val_acc: 0.4993\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7325 - acc: 0.4980 - val_loss: 0.7218 - val_acc: 0.5007\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7368 - acc: 0.4983 - val_loss: 0.7206 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0191903077066.\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.7252 - acc: 0.4999 - val_loss: 0.7208 - val_acc: 0.5007\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7279 - acc: 0.4991 - val_loss: 0.7205 - val_acc: 0.5007\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7257 - acc: 0.5002 - val_loss: 0.7210 - val_acc: 0.5007\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.7260 - acc: 0.4987 - val_loss: 0.7210 - val_acc: 0.5007\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7262 - acc: 0.4983 - val_loss: 0.7214 - val_acc: 0.5007\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.7255 - acc: 0.5017 - val_loss: 0.7207 - val_acc: 0.5007\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7262 - acc: 0.4998 - val_loss: 0.7214 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0095951538533.\n",
      "score: 0.703251775359\n",
      "acc: 0.500709219858\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 163s 26ms/step - loss: 0.7031 - acc: 0.5240 - val_loss: 0.6826 - val_acc: 0.5858\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.6321 - acc: 0.6592 - val_loss: 0.6584 - val_acc: 0.6142\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5351 - acc: 0.7433 - val_loss: 0.5474 - val_acc: 0.7248\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4767 - acc: 0.7811 - val_loss: 0.5821 - val_acc: 0.7504\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4375 - acc: 0.8068 - val_loss: 0.4587 - val_acc: 0.7816\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 140s 22ms/step - loss: 0.4243 - acc: 0.8144 - val_loss: 0.9099 - val_acc: 0.6099\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.4058 - acc: 0.8298 - val_loss: 0.4817 - val_acc: 0.7745\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.3986 - acc: 0.8298 - val_loss: 0.5353 - val_acc: 0.7716\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.3654 - acc: 0.8510 - val_loss: 0.5110 - val_acc: 0.7589\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.3351 - acc: 0.8686 - val_loss: 0.5046 - val_acc: 0.7915\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.3138 - acc: 0.8760 - val_loss: 0.4794 - val_acc: 0.7943\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.2806 - acc: 0.8934 - val_loss: 0.4568 - val_acc: 0.7972\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.2646 - acc: 0.9006 - val_loss: 0.5688 - val_acc: 0.7872\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.2467 - acc: 0.9038 - val_loss: 0.5942 - val_acc: 0.7645\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.2162 - acc: 0.9262 - val_loss: 0.6690 - val_acc: 0.7546\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.1949 - acc: 0.9336 - val_loss: 0.6721 - val_acc: 0.7759\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1675 - acc: 0.9467 - val_loss: 0.8919 - val_acc: 0.7660\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.1479 - acc: 0.9536 - val_loss: 0.7868 - val_acc: 0.7901\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.1311 - acc: 0.9601 - val_loss: 0.8799 - val_acc: 0.7957\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 139s 22ms/step - loss: 0.1191 - acc: 0.9653 - val_loss: 1.0112 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00213689776137.\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.0718 - acc: 0.9856 - val_loss: 1.0609 - val_acc: 0.8043\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.0505 - acc: 0.9924 - val_loss: 1.2649 - val_acc: 0.7972\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.0410 - acc: 0.9946 - val_loss: 1.6745 - val_acc: 0.7972\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.0389 - acc: 0.9956 - val_loss: 1.7529 - val_acc: 0.7986\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.0396 - acc: 0.9964 - val_loss: 1.7039 - val_acc: 0.8028\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.0410 - acc: 0.9957 - val_loss: 1.8866 - val_acc: 0.7929\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.0445 - acc: 0.9950 - val_loss: 1.7155 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00106844888069.\n",
      "score: 1.70379126813\n",
      "acc: 0.792907801418\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 164s 26ms/step - loss: 0.7085 - acc: 0.5204 - val_loss: 0.6900 - val_acc: 0.5887\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.6261 - acc: 0.6642 - val_loss: 0.6068 - val_acc: 0.6738\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5376 - acc: 0.7455 - val_loss: 0.7613 - val_acc: 0.6482\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.4933 - acc: 0.7781 - val_loss: 0.5119 - val_acc: 0.7418\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.4698 - acc: 0.7925 - val_loss: 0.5313 - val_acc: 0.7532\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.4526 - acc: 0.8048 - val_loss: 0.6257 - val_acc: 0.7220\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.4315 - acc: 0.8220 - val_loss: 0.7435 - val_acc: 0.6539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.4281 - acc: 0.8155 - val_loss: 0.4824 - val_acc: 0.7674\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3979 - acc: 0.8390 - val_loss: 0.6878 - val_acc: 0.6709\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3935 - acc: 0.8343 - val_loss: 0.4910 - val_acc: 0.7688\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.3834 - acc: 0.8432 - val_loss: 0.5256 - val_acc: 0.7574\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3596 - acc: 0.8537 - val_loss: 0.5800 - val_acc: 0.7674\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.3461 - acc: 0.8601 - val_loss: 0.6598 - val_acc: 0.7220\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3462 - acc: 0.8656 - val_loss: 0.5783 - val_acc: 0.7560\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.3308 - acc: 0.8718 - val_loss: 0.5072 - val_acc: 0.7532\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.3450 - acc: 0.8642 - val_loss: 0.6070 - val_acc: 0.7901\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00935710407794.\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.2995 - acc: 0.8839 - val_loss: 0.5991 - val_acc: 0.7447\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.2515 - acc: 0.9125 - val_loss: 0.6630 - val_acc: 0.7518\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.2211 - acc: 0.9188 - val_loss: 0.8254 - val_acc: 0.7418\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1968 - acc: 0.9347 - val_loss: 0.8024 - val_acc: 0.7631\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1847 - acc: 0.9385 - val_loss: 0.8818 - val_acc: 0.7674\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.1637 - acc: 0.9461 - val_loss: 0.9724 - val_acc: 0.7206\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1483 - acc: 0.9486 - val_loss: 0.9639 - val_acc: 0.7461\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00467855203897.\n",
      "score: 0.954007958782\n",
      "acc: 0.74609929078\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 56s 9ms/step - loss: 0.7267 - acc: 0.4985 - val_loss: 0.7141 - val_acc: 0.5660\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6983 - acc: 0.5968 - val_loss: 0.6515 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6039 - acc: 0.6952 - val_loss: 0.5889 - val_acc: 0.7121\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.5586 - acc: 0.7319 - val_loss: 0.5789 - val_acc: 0.7149\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5488 - acc: 0.7425 - val_loss: 0.5756 - val_acc: 0.7234\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.5335 - acc: 0.7480 - val_loss: 0.5746 - val_acc: 0.7149\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.5136 - acc: 0.7612 - val_loss: 0.5832 - val_acc: 0.7007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5047 - acc: 0.7680 - val_loss: 0.6242 - val_acc: 0.6440\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4890 - acc: 0.7806 - val_loss: 0.5818 - val_acc: 0.7064\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.4757 - acc: 0.7866 - val_loss: 0.5950 - val_acc: 0.7220\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4667 - acc: 0.7937 - val_loss: 0.5872 - val_acc: 0.6936\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4556 - acc: 0.7948 - val_loss: 0.5897 - val_acc: 0.7277\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4344 - acc: 0.8119 - val_loss: 0.5729 - val_acc: 0.7206\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4270 - acc: 0.8130 - val_loss: 0.5991 - val_acc: 0.7064\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4111 - acc: 0.8204 - val_loss: 0.5883 - val_acc: 0.7291\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.3957 - acc: 0.8343 - val_loss: 0.6237 - val_acc: 0.6965\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.3776 - acc: 0.8461 - val_loss: 0.6920 - val_acc: 0.6865\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.3608 - acc: 0.8500 - val_loss: 0.5905 - val_acc: 0.7433\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.3578 - acc: 0.8595 - val_loss: 0.6157 - val_acc: 0.7277\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.3231 - acc: 0.8764 - val_loss: 0.7544 - val_acc: 0.7418\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.3191 - acc: 0.8749 - val_loss: 0.6747 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00535047193989.\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.2508 - acc: 0.9167 - val_loss: 0.7409 - val_acc: 0.7333\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.2249 - acc: 0.9264 - val_loss: 0.7489 - val_acc: 0.7504\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.2048 - acc: 0.9349 - val_loss: 0.8695 - val_acc: 0.7504\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.1889 - acc: 0.9448 - val_loss: 0.9033 - val_acc: 0.7603\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.1785 - acc: 0.9464 - val_loss: 0.9664 - val_acc: 0.7475\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.1682 - acc: 0.9519 - val_loss: 1.1006 - val_acc: 0.7404\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.1533 - acc: 0.9569 - val_loss: 1.1136 - val_acc: 0.7489\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00267523596995.\n",
      "score: 1.08089257523\n",
      "acc: 0.748936170213\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 161s 25ms/step - loss: 0.7063 - acc: 0.5466 - val_loss: 0.6161 - val_acc: 0.6667\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.6205 - acc: 0.6754 - val_loss: 0.6367 - val_acc: 0.6411\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.5895 - acc: 0.7053 - val_loss: 0.5823 - val_acc: 0.7206\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.5324 - acc: 0.7426 - val_loss: 0.6685 - val_acc: 0.6340\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.5142 - acc: 0.7590 - val_loss: 0.5110 - val_acc: 0.7504\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.4812 - acc: 0.7822 - val_loss: 0.5060 - val_acc: 0.7730\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.4777 - acc: 0.7873 - val_loss: 0.5550 - val_acc: 0.7206\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.4564 - acc: 0.8003 - val_loss: 0.6879 - val_acc: 0.7277\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.4291 - acc: 0.8145 - val_loss: 0.6218 - val_acc: 0.7035\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.4211 - acc: 0.8188 - val_loss: 0.7283 - val_acc: 0.7305\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 364s 57ms/step - loss: 0.4104 - acc: 0.8308 - val_loss: 0.6767 - val_acc: 0.7404\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 508s 80ms/step - loss: 0.4046 - acc: 0.8290 - val_loss: 0.5490 - val_acc: 0.7759\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 514s 81ms/step - loss: 0.3961 - acc: 0.8341 - val_loss: 0.5763 - val_acc: 0.7589\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 523s 82ms/step - loss: 0.3756 - acc: 0.8462 - val_loss: 0.5389 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0130491117015.\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 521s 82ms/step - loss: 0.3157 - acc: 0.8716 - val_loss: 0.5995 - val_acc: 0.7645\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 532s 84ms/step - loss: 0.2654 - acc: 0.9011 - val_loss: 0.6673 - val_acc: 0.7560\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 516s 81ms/step - loss: 0.2295 - acc: 0.9155 - val_loss: 0.7382 - val_acc: 0.7362\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 518s 82ms/step - loss: 0.2203 - acc: 0.9234 - val_loss: 0.7597 - val_acc: 0.7475\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 522s 82ms/step - loss: 0.1937 - acc: 0.9333 - val_loss: 0.8657 - val_acc: 0.7532\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 518s 82ms/step - loss: 0.1781 - acc: 0.9393 - val_loss: 0.9286 - val_acc: 0.7475\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 512s 81ms/step - loss: 0.1574 - acc: 0.9491 - val_loss: 1.0920 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00652455585077.\n",
      "score: 1.07862403138\n",
      "acc: 0.730496453901\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 325s 51ms/step - loss: 0.7262 - acc: 0.5132 - val_loss: 0.7002 - val_acc: 0.5730\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 264s 42ms/step - loss: 0.6771 - acc: 0.6191 - val_loss: 0.6229 - val_acc: 0.6851\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 254s 40ms/step - loss: 0.6185 - acc: 0.6857 - val_loss: 0.6340 - val_acc: 0.6539\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 266s 42ms/step - loss: 0.6118 - acc: 0.7007 - val_loss: 0.5979 - val_acc: 0.7035\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 261s 41ms/step - loss: 0.6070 - acc: 0.7049 - val_loss: 0.6265 - val_acc: 0.6879\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 267s 42ms/step - loss: 0.5856 - acc: 0.7198 - val_loss: 0.5904 - val_acc: 0.7064\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 262s 41ms/step - loss: 0.5831 - acc: 0.7215 - val_loss: 0.5912 - val_acc: 0.7149\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 263s 41ms/step - loss: 0.5631 - acc: 0.7371 - val_loss: 0.5931 - val_acc: 0.7191\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 263s 41ms/step - loss: 0.5556 - acc: 0.7445 - val_loss: 0.5845 - val_acc: 0.7078\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 263s 41ms/step - loss: 0.5472 - acc: 0.7575 - val_loss: 0.5726 - val_acc: 0.7149\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 248s 39ms/step - loss: 0.5434 - acc: 0.7562 - val_loss: 0.6166 - val_acc: 0.7064\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 258s 41ms/step - loss: 0.5446 - acc: 0.7589 - val_loss: 0.6019 - val_acc: 0.7191\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 265s 42ms/step - loss: 0.5470 - acc: 0.7519 - val_loss: 0.6141 - val_acc: 0.6936\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 267s 42ms/step - loss: 0.5533 - acc: 0.7516 - val_loss: 0.5929 - val_acc: 0.6908\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 263s 41ms/step - loss: 0.5418 - acc: 0.7521 - val_loss: 0.6352 - val_acc: 0.6922\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 264s 42ms/step - loss: 0.5856 - acc: 0.7261 - val_loss: 0.6494 - val_acc: 0.6766\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 255s 40ms/step - loss: 0.5669 - acc: 0.7313 - val_loss: 0.5746 - val_acc: 0.6993\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 254s 40ms/step - loss: 0.5598 - acc: 0.7504 - val_loss: 0.6323 - val_acc: 0.6723\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0302959736437.\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 252s 40ms/step - loss: 0.5577 - acc: 0.7392 - val_loss: 0.5931 - val_acc: 0.6922\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 251s 40ms/step - loss: 0.5394 - acc: 0.7612 - val_loss: 0.6013 - val_acc: 0.6993\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 248s 39ms/step - loss: 0.5240 - acc: 0.7709 - val_loss: 0.5835 - val_acc: 0.7106\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 256s 40ms/step - loss: 0.4984 - acc: 0.7850 - val_loss: 0.5839 - val_acc: 0.7050\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 256s 40ms/step - loss: 0.5041 - acc: 0.7786 - val_loss: 0.5903 - val_acc: 0.7163\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 265s 42ms/step - loss: 0.4969 - acc: 0.7936 - val_loss: 0.6361 - val_acc: 0.6780\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 261s 41ms/step - loss: 0.4928 - acc: 0.7928 - val_loss: 0.6679 - val_acc: 0.6979\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0151479868218.\n",
      "score: 0.645276779765\n",
      "acc: 0.697872340426\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 590s 93ms/step - loss: 0.6946 - acc: 0.5528 - val_loss: 0.7309 - val_acc: 0.5574\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.5858 - acc: 0.7082 - val_loss: 0.9284 - val_acc: 0.5532\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 536s 84ms/step - loss: 0.5187 - acc: 0.7620 - val_loss: 0.7722 - val_acc: 0.6312\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 523s 82ms/step - loss: 0.4835 - acc: 0.7819 - val_loss: 0.6956 - val_acc: 0.6908\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 531s 84ms/step - loss: 0.4419 - acc: 0.8089 - val_loss: 0.5819 - val_acc: 0.7589\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 534s 84ms/step - loss: 0.4091 - acc: 0.8298 - val_loss: 0.5833 - val_acc: 0.7716\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 531s 84ms/step - loss: 0.3745 - acc: 0.8425 - val_loss: 0.6873 - val_acc: 0.7333\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 535s 84ms/step - loss: 0.3437 - acc: 0.8617 - val_loss: 0.4594 - val_acc: 0.7787\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.3165 - acc: 0.8765 - val_loss: 0.5154 - val_acc: 0.7745\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.2926 - acc: 0.8888 - val_loss: 0.5483 - val_acc: 0.7830\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 535s 84ms/step - loss: 0.2563 - acc: 0.9040 - val_loss: 0.5459 - val_acc: 0.7645\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.2399 - acc: 0.9093 - val_loss: 0.8333 - val_acc: 0.7475\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.2055 - acc: 0.9287 - val_loss: 0.6426 - val_acc: 0.7887\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 533s 84ms/step - loss: 0.1773 - acc: 0.9399 - val_loss: 0.8108 - val_acc: 0.7518\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 527s 83ms/step - loss: 0.1455 - acc: 0.9521 - val_loss: 0.7437 - val_acc: 0.7844\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 531s 84ms/step - loss: 0.1255 - acc: 0.9620 - val_loss: 0.8831 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00320048211142.\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 527s 83ms/step - loss: 0.0741 - acc: 0.9823 - val_loss: 1.1183 - val_acc: 0.7844\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 529s 83ms/step - loss: 0.0461 - acc: 0.9937 - val_loss: 1.4864 - val_acc: 0.7830\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 536s 85ms/step - loss: 0.0425 - acc: 0.9935 - val_loss: 1.6549 - val_acc: 0.7787\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 531s 84ms/step - loss: 0.0405 - acc: 0.9937 - val_loss: 1.5525 - val_acc: 0.7816\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 530s 84ms/step - loss: 0.0437 - acc: 0.9953 - val_loss: 1.6780 - val_acc: 0.7773\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 534s 84ms/step - loss: 0.0440 - acc: 0.9943 - val_loss: 1.7918 - val_acc: 0.7546\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 527s 83ms/step - loss: 0.0421 - acc: 0.9932 - val_loss: 1.8068 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00160024105571.\n",
      "score: 1.79466395291\n",
      "acc: 0.758865248227\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 192s 30ms/step - loss: 0.8035 - acc: 0.5053 - val_loss: 0.7426 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 135s 21ms/step - loss: 0.7538 - acc: 0.5007 - val_loss: 0.7428 - val_acc: 0.5007\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 110s 17ms/step - loss: 0.7589 - acc: 0.5070 - val_loss: 0.7425 - val_acc: 0.5007\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.7576 - acc: 0.4969 - val_loss: 0.7517 - val_acc: 0.4993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7563 - acc: 0.5056 - val_loss: 0.7398 - val_acc: 0.5035\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7537 - acc: 0.5207 - val_loss: 0.7040 - val_acc: 0.6057\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.7175 - acc: 0.5985 - val_loss: 0.6560 - val_acc: 0.7007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6940 - acc: 0.6354 - val_loss: 0.6565 - val_acc: 0.6809\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6834 - acc: 0.6504 - val_loss: 0.6254 - val_acc: 0.7050\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6653 - acc: 0.6742 - val_loss: 0.6316 - val_acc: 0.6894\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6465 - acc: 0.6841 - val_loss: 0.6104 - val_acc: 0.7121\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6555 - acc: 0.6876 - val_loss: 0.6215 - val_acc: 0.6823\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6487 - acc: 0.6841 - val_loss: 0.6432 - val_acc: 0.6965\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 41s 7ms/step - loss: 0.6424 - acc: 0.6868 - val_loss: 0.6403 - val_acc: 0.7007\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.6301 - acc: 0.7109 - val_loss: 0.6195 - val_acc: 0.7092\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 40s 6ms/step - loss: 0.6251 - acc: 0.7176 - val_loss: 0.6437 - val_acc: 0.7021\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6191 - acc: 0.7212 - val_loss: 0.6371 - val_acc: 0.7092\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.5941 - acc: 0.7411 - val_loss: 0.6274 - val_acc: 0.7092\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5893 - acc: 0.7511 - val_loss: 0.6136 - val_acc: 0.7248\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0234727170318.\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 41s 6ms/step - loss: 0.5276 - acc: 0.7933 - val_loss: 0.6287 - val_acc: 0.7291\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5126 - acc: 0.8016 - val_loss: 0.6282 - val_acc: 0.7277\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.5099 - acc: 0.8054 - val_loss: 0.6614 - val_acc: 0.7376\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.4923 - acc: 0.8174 - val_loss: 0.6499 - val_acc: 0.7220\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4669 - acc: 0.8287 - val_loss: 0.6806 - val_acc: 0.7234\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4525 - acc: 0.8406 - val_loss: 0.6797 - val_acc: 0.7362\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4464 - acc: 0.8434 - val_loss: 0.6706 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0117363585159.\n",
      "score: 0.598330522387\n",
      "acc: 0.731914893617\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 92s 15ms/step - loss: 1.0502 - acc: 0.5047 - val_loss: 0.7753 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.8252 - acc: 0.4871 - val_loss: 0.7078 - val_acc: 0.5035\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.7998 - acc: 0.4958 - val_loss: 0.8084 - val_acc: 0.4993\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.8069 - acc: 0.5047 - val_loss: 0.7772 - val_acc: 0.4993\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.8455 - acc: 0.4991 - val_loss: 0.7066 - val_acc: 0.5390\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.8342 - acc: 0.5064 - val_loss: 0.8237 - val_acc: 0.4993\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.8497 - acc: 0.5013 - val_loss: 0.7651 - val_acc: 0.4965\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.8755 - acc: 0.4980 - val_loss: 0.7197 - val_acc: 0.4965\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.8721 - acc: 0.5065 - val_loss: 0.7377 - val_acc: 0.4993\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.8679 - acc: 0.4990 - val_loss: 0.8662 - val_acc: 0.5007\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.8508 - acc: 0.5035 - val_loss: 0.7432 - val_acc: 0.4993\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.8481 - acc: 0.5018 - val_loss: 0.7340 - val_acc: 0.5050\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.8381 - acc: 0.4936 - val_loss: 0.7949 - val_acc: 0.5035\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0434889756143.\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.8110 - acc: 0.5149 - val_loss: 0.7118 - val_acc: 0.4567\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.7663 - acc: 0.5010 - val_loss: 0.7207 - val_acc: 0.5007\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.7594 - acc: 0.4875 - val_loss: 0.7258 - val_acc: 0.4908\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.7619 - acc: 0.4912 - val_loss: 0.7105 - val_acc: 0.4837\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.7575 - acc: 0.5207 - val_loss: 0.7123 - val_acc: 0.5021\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.7589 - acc: 0.5013 - val_loss: 0.7122 - val_acc: 0.5135\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.7647 - acc: 0.4925 - val_loss: 0.7243 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0217444878072.\n",
      "score: 0.710252016402\n",
      "acc: 0.500709219858\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 160s 25ms/step - loss: 0.7146 - acc: 0.5094 - val_loss: 0.7339 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.6439 - acc: 0.6415 - val_loss: 0.6297 - val_acc: 0.6837\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6023 - acc: 0.6945 - val_loss: 0.6015 - val_acc: 0.6780\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.5559 - acc: 0.7420 - val_loss: 0.6477 - val_acc: 0.6468\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.5206 - acc: 0.7606 - val_loss: 0.6025 - val_acc: 0.7163\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.5123 - acc: 0.7627 - val_loss: 0.5952 - val_acc: 0.7121\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 139s 22ms/step - loss: 0.5014 - acc: 0.7713 - val_loss: 0.5810 - val_acc: 0.7106\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.4981 - acc: 0.7732 - val_loss: 0.6976 - val_acc: 0.6950\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.4899 - acc: 0.7821 - val_loss: 0.8589 - val_acc: 0.6355\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.4920 - acc: 0.7825 - val_loss: 0.5759 - val_acc: 0.7262\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4978 - acc: 0.7773 - val_loss: 0.5928 - val_acc: 0.6993\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.4837 - acc: 0.7805 - val_loss: 0.6125 - val_acc: 0.6525\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.4762 - acc: 0.7903 - val_loss: 0.5802 - val_acc: 0.7163\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 156s 25ms/step - loss: 0.4722 - acc: 0.7846 - val_loss: 0.6470 - val_acc: 0.7333\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.4733 - acc: 0.7909 - val_loss: 0.6314 - val_acc: 0.6794\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.4691 - acc: 0.7866 - val_loss: 0.6268 - val_acc: 0.6936\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.4667 - acc: 0.7914 - val_loss: 0.6800 - val_acc: 0.7021\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4636 - acc: 0.7871 - val_loss: 0.6546 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0185061059892.\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.4468 - acc: 0.8101 - val_loss: 0.6015 - val_acc: 0.7291\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.4201 - acc: 0.8204 - val_loss: 0.6862 - val_acc: 0.7248\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 150s 24ms/step - loss: 0.4131 - acc: 0.8242 - val_loss: 0.6164 - val_acc: 0.7092\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.4083 - acc: 0.8287 - val_loss: 0.6361 - val_acc: 0.7007\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4073 - acc: 0.8226 - val_loss: 0.6700 - val_acc: 0.7135\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.3865 - acc: 0.8384 - val_loss: 0.6196 - val_acc: 0.7206\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.3917 - acc: 0.8420 - val_loss: 0.6184 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00925305299461.\n",
      "score: 0.612247478119\n",
      "acc: 0.731914893617\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 93s 15ms/step - loss: 0.7034 - acc: 0.5020 - val_loss: 0.6985 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 75s 12ms/step - loss: 0.7005 - acc: 0.4912 - val_loss: 0.6981 - val_acc: 0.5021\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 78s 12ms/step - loss: 0.6894 - acc: 0.5419 - val_loss: 0.6363 - val_acc: 0.6766\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.6471 - acc: 0.6439 - val_loss: 0.5664 - val_acc: 0.7206\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5906 - acc: 0.6904 - val_loss: 0.5443 - val_acc: 0.7418\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.5740 - acc: 0.7045 - val_loss: 0.5260 - val_acc: 0.7234\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.5463 - acc: 0.7299 - val_loss: 0.5024 - val_acc: 0.7319\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.5089 - acc: 0.7538 - val_loss: 0.4601 - val_acc: 0.7759\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.5012 - acc: 0.7617 - val_loss: 0.5528 - val_acc: 0.7191\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4876 - acc: 0.7743 - val_loss: 0.5074 - val_acc: 0.7816\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.4631 - acc: 0.7866 - val_loss: 0.4597 - val_acc: 0.7716\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.4398 - acc: 0.7934 - val_loss: 0.4678 - val_acc: 0.7716\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 76s 12ms/step - loss: 0.4104 - acc: 0.8085 - val_loss: 0.4716 - val_acc: 0.7787\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 69s 11ms/step - loss: 0.4225 - acc: 0.8158 - val_loss: 0.4583 - val_acc: 0.8057\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 73s 12ms/step - loss: 0.4001 - acc: 0.8243 - val_loss: 0.5273 - val_acc: 0.7560\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3734 - acc: 0.8368 - val_loss: 0.4752 - val_acc: 0.8014\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3592 - acc: 0.8387 - val_loss: 0.4743 - val_acc: 0.7915\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.3519 - acc: 0.8448 - val_loss: 0.5208 - val_acc: 0.8043\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3406 - acc: 0.8560 - val_loss: 0.4928 - val_acc: 0.7887\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 70s 11ms/step - loss: 0.3220 - acc: 0.8576 - val_loss: 0.5342 - val_acc: 0.7801\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.3140 - acc: 0.8622 - val_loss: 0.5761 - val_acc: 0.7972\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.3047 - acc: 0.8734 - val_loss: 0.5907 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00677212234586.\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2674 - acc: 0.8855 - val_loss: 0.6710 - val_acc: 0.7872\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 73s 11ms/step - loss: 0.2304 - acc: 0.8992 - val_loss: 0.7818 - val_acc: 0.7787\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 72s 11ms/step - loss: 0.2166 - acc: 0.9085 - val_loss: 0.9360 - val_acc: 0.8000\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 71s 11ms/step - loss: 0.2118 - acc: 0.9087 - val_loss: 0.9622 - val_acc: 0.7915\n",
      "Epoch 27/100\n",
      "6341/6341 [==============================] - 74s 12ms/step - loss: 0.2071 - acc: 0.9117 - val_loss: 1.0363 - val_acc: 0.7972\n",
      "Epoch 28/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.2020 - acc: 0.9076 - val_loss: 1.0063 - val_acc: 0.7773\n",
      "Epoch 29/100\n",
      "6341/6341 [==============================] - 77s 12ms/step - loss: 0.1842 - acc: 0.9196 - val_loss: 1.1548 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00338606117293.\n",
      "score: 1.14819205954\n",
      "acc: 0.785815602837\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 55s 9ms/step - loss: 0.9010 - acc: 0.5072 - val_loss: 0.7232 - val_acc: 0.5007\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.7397 - acc: 0.5471 - val_loss: 0.7169 - val_acc: 0.5702\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.7011 - acc: 0.6160 - val_loss: 0.6364 - val_acc: 0.7078\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6413 - acc: 0.6792 - val_loss: 0.5967 - val_acc: 0.7305\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.6396 - acc: 0.6806 - val_loss: 0.5844 - val_acc: 0.7262\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 39s 6ms/step - loss: 0.6200 - acc: 0.7043 - val_loss: 0.6708 - val_acc: 0.5929\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.6162 - acc: 0.7081 - val_loss: 0.6240 - val_acc: 0.7007\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.6007 - acc: 0.7297 - val_loss: 0.6015 - val_acc: 0.7050\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.6048 - acc: 0.7242 - val_loss: 0.5946 - val_acc: 0.7319\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5895 - acc: 0.7349 - val_loss: 0.6034 - val_acc: 0.7248\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.5846 - acc: 0.7448 - val_loss: 0.7403 - val_acc: 0.6879\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5979 - acc: 0.7294 - val_loss: 0.6612 - val_acc: 0.7121\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5914 - acc: 0.7431 - val_loss: 0.6025 - val_acc: 0.7291\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0293366089463.\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.5252 - acc: 0.7750 - val_loss: 0.6049 - val_acc: 0.7305\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.5051 - acc: 0.7958 - val_loss: 0.6340 - val_acc: 0.7262\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 36s 6ms/step - loss: 0.4969 - acc: 0.8041 - val_loss: 0.6082 - val_acc: 0.7433\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 37s 6ms/step - loss: 0.4736 - acc: 0.8128 - val_loss: 0.6528 - val_acc: 0.7191\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4787 - acc: 0.8152 - val_loss: 0.6139 - val_acc: 0.7433\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 35s 6ms/step - loss: 0.4464 - acc: 0.8290 - val_loss: 0.6425 - val_acc: 0.7021\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 38s 6ms/step - loss: 0.4493 - acc: 0.8298 - val_loss: 0.6391 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0146683044732.\n",
      "score: 0.585464410864\n",
      "acc: 0.726241134752\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 158s 25ms/step - loss: 0.6975 - acc: 0.5330 - val_loss: 0.7150 - val_acc: 0.5064\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6649 - acc: 0.6174 - val_loss: 0.7328 - val_acc: 0.5220\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.6078 - acc: 0.6911 - val_loss: 0.7924 - val_acc: 0.6539\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.5425 - acc: 0.7467 - val_loss: 0.6201 - val_acc: 0.6766\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.4979 - acc: 0.7789 - val_loss: 0.5354 - val_acc: 0.7475\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.4696 - acc: 0.7928 - val_loss: 0.5830 - val_acc: 0.7348\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.4461 - acc: 0.8073 - val_loss: 0.4960 - val_acc: 0.7730\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 155s 24ms/step - loss: 0.4349 - acc: 0.8134 - val_loss: 0.4997 - val_acc: 0.7475\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.4134 - acc: 0.8221 - val_loss: 0.5557 - val_acc: 0.7447\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 156s 25ms/step - loss: 0.3866 - acc: 0.8391 - val_loss: 0.5734 - val_acc: 0.7050\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.3683 - acc: 0.8464 - val_loss: 0.5107 - val_acc: 0.7816\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.3425 - acc: 0.8617 - val_loss: 0.5563 - val_acc: 0.7645\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 149s 23ms/step - loss: 0.3216 - acc: 0.8708 - val_loss: 0.6209 - val_acc: 0.7376\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 148s 23ms/step - loss: 0.2910 - acc: 0.8876 - val_loss: 0.5405 - val_acc: 0.7816\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 144s 23ms/step - loss: 0.2720 - acc: 0.8953 - val_loss: 0.5549 - val_acc: 0.7801\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00317180971615.\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 147s 23ms/step - loss: 0.2076 - acc: 0.9245 - val_loss: 0.5698 - val_acc: 0.7887\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 154s 24ms/step - loss: 0.1503 - acc: 0.9510 - val_loss: 0.6630 - val_acc: 0.7901\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.1162 - acc: 0.9647 - val_loss: 0.8270 - val_acc: 0.7830\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.0885 - acc: 0.9778 - val_loss: 0.9429 - val_acc: 0.7801\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.0682 - acc: 0.9834 - val_loss: 1.1073 - val_acc: 0.7830\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.0642 - acc: 0.9853 - val_loss: 1.1666 - val_acc: 0.7830\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 143s 22ms/step - loss: 0.0569 - acc: 0.9885 - val_loss: 1.5086 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00158590485808.\n",
      "score: 1.49952831959\n",
      "acc: 0.760283687943\n",
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 157s 25ms/step - loss: 0.6616 - acc: 0.5938 - val_loss: 0.5853 - val_acc: 0.6922\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.5653 - acc: 0.7146 - val_loss: 0.6113 - val_acc: 0.6851\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 141s 22ms/step - loss: 0.5490 - acc: 0.7276 - val_loss: 0.5967 - val_acc: 0.6823\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 146s 23ms/step - loss: 0.4937 - acc: 0.7639 - val_loss: 0.5341 - val_acc: 0.7305\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.4571 - acc: 0.7951 - val_loss: 0.5821 - val_acc: 0.7149\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.4338 - acc: 0.8078 - val_loss: 0.5893 - val_acc: 0.7220\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.4220 - acc: 0.8172 - val_loss: 0.7483 - val_acc: 0.6553\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 143s 22ms/step - loss: 0.4149 - acc: 0.8182 - val_loss: 0.5549 - val_acc: 0.7404\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 143s 23ms/step - loss: 0.4211 - acc: 0.8073 - val_loss: 0.5979 - val_acc: 0.7461\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.3986 - acc: 0.8253 - val_loss: 0.7118 - val_acc: 0.7262\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 142s 22ms/step - loss: 0.3656 - acc: 0.8410 - val_loss: 0.5800 - val_acc: 0.7404\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 145s 23ms/step - loss: 0.3721 - acc: 0.8396 - val_loss: 0.6558 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0109546557069.\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.3019 - acc: 0.8759 - val_loss: 0.6005 - val_acc: 0.7447\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.2673 - acc: 0.8932 - val_loss: 0.7077 - val_acc: 0.7362\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 149s 24ms/step - loss: 0.2386 - acc: 0.9081 - val_loss: 0.7495 - val_acc: 0.7447\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.2112 - acc: 0.9159 - val_loss: 0.7130 - val_acc: 0.7404\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 151s 24ms/step - loss: 0.1909 - acc: 0.9286 - val_loss: 0.7699 - val_acc: 0.7220\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 153s 24ms/step - loss: 0.1573 - acc: 0.9428 - val_loss: 1.0405 - val_acc: 0.7262\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 152s 24ms/step - loss: 0.1570 - acc: 0.9401 - val_loss: 0.8330 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00547732785344.\n",
      "score: 0.828268636076\n",
      "acc: 0.731914893617\n"
     ]
    }
   ],
   "source": [
    "from hyperas import optim\n",
    "\n",
    "from keras import optimizers as opt\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Dot, Dropout, LSTM\n",
    "from keras.layers import Embedding, GlobalAveragePooling1D, Input, Multiply\n",
    "from tangle.layers import TimespanGuidedNeuralAttention\n",
    "\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=50,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='hyperparam_tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "705/705 [==============================] - 7s 10ms/step\n",
      "[0.511931981762924, 0.7943262411347518]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'dr_rate_0_1': 0.8010934391495235, 'dr_rate_0': 0.34691402700128554, 'batch_size': 1, 'l2': 0.0009996198898434667, 'lr': 0.001169490205654279, 'n_recurrent_2': 3, 'n_recurrent_1': 2, 'n_recurrent': 2, 'embedding_trainable': 1}\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_valid, y_valid))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data():\n",
    "    \"\"\"Test set not returned on purpose.\"\"\"\n",
    "    \n",
    "    labelsfile = '../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv'\n",
    "    datafile = '../../tmp/item_days_raw_data_.pkl'\n",
    "    dataset = utils.load_data_labels(datafile, labelsfile)\n",
    "    padded_mbs_seq, padded_timespan_seq, _ = utils.tokenize(dataset)\n",
    "    maxlen = padded_mbs_seq.shape[1]\n",
    "\n",
    "    # Split in training, validation, test sets\n",
    "    _, _, ts_set = utils.train_validation_test_split(\n",
    "                   [padded_mbs_seq, padded_timespan_seq], dataset['Class'],\n",
    "                   test_size=0.4, validation_size=0.1,\n",
    "                   verbose=False, random_state0=1, random_state1=0)\n",
    "    \n",
    "    return ts_set[0], ts_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on the test set\n",
      "Test scores:\n",
      " * Log-Loss\tnan\n",
      " * Accuracy:\t0.837377607493\n",
      " * Precision:\t0.861047835991\n",
      " * Recall:\t0.804597701149\n",
      " * AUC: \t0.914321484229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samu/miniconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1769: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/samu/miniconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1769: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "print('Evaluate on the test set')\n",
    "x_test, y_test = test_data()\n",
    "y_pred = best_model.predict(x_test).ravel()\n",
    "\n",
    "loss = metrics.log_loss(y_test, y_pred)\n",
    "acc = metrics.accuracy_score(y_test, y_pred > 0.5)\n",
    "prec = metrics.precision_score(y_test, y_pred > 0.5)\n",
    "rcll = metrics.recall_score(y_test, y_pred > 0.5)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print('Test scores:\\n * Log-Loss\\t{}\\n * Accuracy:\\t{}\\n '\n",
    "      '* Precision:\\t{}\\n * Recall:\\t{}\\n * AUC: \\t{}'.format(loss, acc, prec, rcll, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
