{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import mbspbs10pc.model as mbs_model\n",
    "from mbspbs10pc import read_activations, utils\n",
    "reload(read_activations)\n",
    "reload(utils);\n",
    "\n",
    "root = 'dl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsfile = '../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv'\n",
    "datafile = '../../tmp/item_days_raw_data_.pkl'\n",
    "dataset = utils.load_data_labels(datafile, labelsfile)\n",
    "padded_mbs_seq, padded_timestamp_seq, _ = utils.tokenize(dataset)\n",
    "maxlen = padded_mbs_seq.shape[1]\n",
    "\n",
    "# Split in training, validation, test sets\n",
    "tr_set, v_set, ts_set = utils.train_validation_test_split(\n",
    "    [padded_mbs_seq, padded_timestamp_seq], dataset['Class'],\n",
    "    test_size=0.4, validation_size=0.1,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6341, 250)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_set[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2774, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = 50\n",
    "embedding = pd.read_csv('../../tmp/embedding.{}d.csv'.format(D), header=0, index_col=0)\n",
    "embedding_matrix = embedding.values\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samu/miniconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "('hx: ', TensorShape([Dimension(None), Dimension(64), Dimension(250)]))\n",
      "('tx: ', TensorShape([Dimension(None), Dimension(64), Dimension(250)]))\n",
      "('gamma: ', TensorShape([Dimension(None), Dimension(64), Dimension(250)]))\n",
      "('beta: ', TensorShape([Dimension(None), Dimension(64), Dimension(250)]))\n",
      "('delta: ', TensorShape([Dimension(None), Dimension(64), Dimension(250)]))\n",
      "('alpha: ', TensorShape([Dimension(None), Dimension(250), Dimension(64)]))\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM\n",
    "reload(mbs_model);\n",
    "\n",
    "model = mbs_model.build_model(mbs_input_shape=(maxlen,),\n",
    "                              timestamp_input_shape=(maxlen, 1),\n",
    "                              vocabulary_size=2774,\n",
    "                              embedding_size=50,\n",
    "                              recurrent_units=32,\n",
    "                              dense_units=32,\n",
    "                              bidirectional=True,\n",
    "                              LSTMLayer=CuDNNLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers as opt\n",
    "model.compile(optimizer=opt.RMSprop(lr=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.get_layer('mbs_embedding').set_weights([embedding_matrix])\n",
    "# model.get_layer('mbs_embedding').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mbs_input (InputLayer)          (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mbs_embedding (Embedding)       (None, 250, 50)      138700      mbs_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "timestamp_input (InputLayer)    (None, 250, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mbs_lstm (Bidirectional)        (None, 250, 64)      21504       mbs_embedding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "timestamp_lstm (Bidirectional)  (None, 250, 64)      8960        timestamp_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tsg_attention (TimestampGuidedA (None, 250, 64)      219500      mbs_lstm[0][0]                   \n",
      "                                                                 timestamp_lstm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "contribution (Multiply)         (None, 250, 64)      0           tsg_attention[0][0]              \n",
      "                                                                 mbs_lstm[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "context (Dot)                   (None, 64, 50)       0           contribution[0][0]               \n",
      "                                                                 mbs_embedding[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pooling (GlobalAveragePooling1D (None, 50)           0           context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 50)           0           pooling[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fc (Dense)                      (None, 32)           1632        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32)           0           fc[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "fc_output (Dense)               (None, 1)            33          dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 390,329\n",
      "Trainable params: 390,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import SVG\n",
    "# from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, show_shapes=True, to_file='model_dot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6341 samples, validate on 705 samples\n",
      "Epoch 1/100\n",
      "6341/6341 [==============================] - 10s 2ms/step - loss: 0.7415 - acc: 0.5455 - val_loss: 0.7271 - val_acc: 0.5816\n",
      "Epoch 2/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.7126 - acc: 0.6056 - val_loss: 0.7079 - val_acc: 0.6113\n",
      "Epoch 3/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.6811 - acc: 0.6549 - val_loss: 0.6826 - val_acc: 0.6298\n",
      "Epoch 4/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.6500 - acc: 0.6868 - val_loss: 0.6669 - val_acc: 0.6752\n",
      "Epoch 5/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.6185 - acc: 0.7149 - val_loss: 0.6382 - val_acc: 0.6993\n",
      "Epoch 6/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.5895 - acc: 0.7415 - val_loss: 0.6521 - val_acc: 0.6993\n",
      "Epoch 7/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.5636 - acc: 0.7636 - val_loss: 0.6280 - val_acc: 0.7021\n",
      "Epoch 8/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.5456 - acc: 0.7794 - val_loss: 0.6149 - val_acc: 0.7390\n",
      "Epoch 9/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.5121 - acc: 0.8021 - val_loss: 0.6377 - val_acc: 0.7319\n",
      "Epoch 10/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.4831 - acc: 0.8193 - val_loss: 0.6154 - val_acc: 0.7333\n",
      "Epoch 11/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.4617 - acc: 0.8336 - val_loss: 0.6035 - val_acc: 0.7390\n",
      "Epoch 12/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.4319 - acc: 0.8518 - val_loss: 0.6106 - val_acc: 0.7560\n",
      "Epoch 13/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.4132 - acc: 0.8609 - val_loss: 0.6320 - val_acc: 0.7631\n",
      "Epoch 14/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3905 - acc: 0.8743 - val_loss: 0.6966 - val_acc: 0.7574\n",
      "Epoch 15/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3623 - acc: 0.8929 - val_loss: 0.7208 - val_acc: 0.7404\n",
      "Epoch 16/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3665 - acc: 0.8935 - val_loss: 0.7062 - val_acc: 0.7447\n",
      "Epoch 17/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3763 - acc: 0.8901 - val_loss: 0.7340 - val_acc: 0.7418\n",
      "Epoch 18/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3325 - acc: 0.9068 - val_loss: 0.7616 - val_acc: 0.7532\n",
      "Epoch 19/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.3219 - acc: 0.9101 - val_loss: 0.7609 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00499999988824.\n",
      "Epoch 20/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.2480 - acc: 0.9524 - val_loss: 0.9804 - val_acc: 0.7461\n",
      "Epoch 21/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.2164 - acc: 0.9650 - val_loss: 1.1022 - val_acc: 0.7376\n",
      "Epoch 22/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.1964 - acc: 0.9730 - val_loss: 1.2226 - val_acc: 0.7447\n",
      "Epoch 23/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.1808 - acc: 0.9809 - val_loss: 1.3528 - val_acc: 0.7546\n",
      "Epoch 24/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.1681 - acc: 0.9861 - val_loss: 1.5011 - val_acc: 0.7447\n",
      "Epoch 25/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.1684 - acc: 0.9853 - val_loss: 1.6281 - val_acc: 0.7362\n",
      "Epoch 26/100\n",
      "6341/6341 [==============================] - 8s 1ms/step - loss: 0.1519 - acc: 0.9910 - val_loss: 1.7198 - val_acc: 0.7489\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00249999994412.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=1),\n",
    "             EarlyStopping(monitor='val_loss', patience=15)] \n",
    "\n",
    "h = model.fit(tr_set[0], tr_set[1],\n",
    "              epochs=100,\n",
    "              callbacks=callbacks,\n",
    "              batch_size=128,\n",
    "              validation_data=(v_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7415355008269988,\n",
       " 0.7126054115296162,\n",
       " 0.6811000337417974,\n",
       " 0.6499722977388434,\n",
       " 0.6185210241426938,\n",
       " 0.5894521322090193,\n",
       " 0.5636254733170156,\n",
       " 0.5455558370141422,\n",
       " 0.5121134301969783,\n",
       " 0.4830955838559272,\n",
       " 0.4617035014079283,\n",
       " 0.4319354021489066,\n",
       " 0.4132120693647378,\n",
       " 0.39053342307033156,\n",
       " 0.36226994437461507,\n",
       " 0.36654407820891854,\n",
       " 0.37625442767459083,\n",
       " 0.33251860825689483,\n",
       " 0.3219303521254972,\n",
       " 0.24798405457842032,\n",
       " 0.21644545226062514,\n",
       " 0.19636878264315064,\n",
       " 0.1807588684274052,\n",
       " 0.1681482324103812,\n",
       " 0.16841792120784638,\n",
       " 0.15189221195854274]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-11498f15e577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h1' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import History\n",
    "\n",
    "history = History()\n",
    "history.history = {}\n",
    "history.epoch = h1.epoch + h2.epoch\n",
    "\n",
    "for k in ['loss', 'val_loss', 'acc', 'val_acc']:\n",
    "    history.history[k] = h1.history[k] + h2.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "t = history.epoch\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(t, history.history['loss'], label='loss', color='C0')\n",
    "plt.plot(t, history.history['val_loss'], label='val_loss', color='C1')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t, history.history['acc'], label='acc', color='C2')\n",
    "plt.plot(t, history.history['val_acc'], label='val_acc', color='C3')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d03b3eed4832>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict([X_test, X_test_t.reshape(len(y_test), maxlen, 1)]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = metrics.log_loss(y_test, y_pred)\n",
    "acc = metrics.accuracy_score(y_test, y_pred > 0.5)\n",
    "prec = metrics.precision_score(y_test, y_pred > 0.5)\n",
    "rcll = metrics.recall_score(y_test, y_pred > 0.5)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "print('Test scores:\\n * Log-Loss\\t{}\\n * Accuracy:\\t{}\\n '\n",
    "      '* Precision:\\t{}\\n * Recall:\\t{}\\n * AUC: \\t{}'.format(loss, acc, prec, rcll, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbspbs10pc.plotting import *\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred > 0.5)\n",
    "plt.figure(dpi=100)\n",
    "plot_confusion_matrix(cnf_matrix, classes=['METONLY', 'METX'],\n",
    "                      title='Confusion matrix', cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOP results so far [6341 training / 705 validation / 4698 test]**\n",
    "\n",
    "Test scores:\n",
    " * Log-Loss\t0.425300993082\n",
    " * Accuracy:\t0.810131971052\n",
    " * Precision:\t0.817983413357\n",
    " * Recall:\t0.797786292039\n",
    " * AUC: \t0.894714579232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbspbs10pc import read_activations\n",
    "reload(read_activations);\n",
    "\n",
    "_x_test = [X_test, X_test_t.reshape(len(y_test), maxlen, 1)]\n",
    "a = read_activations.get_activations(model, _x_test, print_shape_only=True, layer_name='attention_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos_idx = np.where(np.logical_and(y_test == 1, y_pred >= 0.5))[0]\n",
    "true_neg_idx = np.where(np.logical_and(y_test == 0, y_pred < 0.5))[0]\n",
    "false_pos_idx = np.where(np.logical_and(y_test == 1, y_pred < 0.5))[0]\n",
    "false_neg_idx = np.where(np.logical_and(y_test == 0, y_pred >= 0.5))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att(att, idx):\n",
    "    return np.mean(np.mean(att[0][idx, :, :], axis=0), axis=0)\n",
    "\n",
    "true_pos_att = get_att(a, true_pos_idx)\n",
    "true_neg_att = get_att(a, true_neg_idx)\n",
    "false_pos_att = get_att(a, false_pos_idx)\n",
    "false_neg_att = get_att(a, false_neg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.title('true pos att')\n",
    "plt.plot(np.arange(445), true_pos_att, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.title('true neg att')\n",
    "plt.plot(np.arange(445), true_neg_att, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.title('false pos att')\n",
    "plt.plot(np.arange(445), false_pos_att, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.title('false neg att')\n",
    "plt.plot(np.arange(445), false_neg_att, 'o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
