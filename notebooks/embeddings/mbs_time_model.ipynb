{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "root = 'dl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIN</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568483</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923748</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035328</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239386</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244533</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CLASS\n",
       "PIN           \n",
       "568483       1\n",
       "923748       0\n",
       "2035328      0\n",
       "2239386      1\n",
       "2244533      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('../../tmp/1_METONLY_vs_METX/matched_CEM_table.csv', header=0).rename({'Unnamed: 0': 'PIN'}, axis=1)[['PIN', 'CLASS']].set_index('PIN')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568483</th>\n",
       "      <td>10990 0 23 16 725 0 10990 0 10990 0 10990 0 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923748</th>\n",
       "      <td>66653 0 65070 0 66515 5 10962 1 105 1 56807 42...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035328</th>\n",
       "      <td>66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239386</th>\n",
       "      <td>10991 0 23 105 73928 0 66560 0 66515 0 66551 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244533</th>\n",
       "      <td>10990 0 23 74 23 0 10990 1 73928 0 66500 0 665...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Seq  Class\n",
       "PIN                                                              \n",
       "568483   10990 0 23 16 725 0 10990 0 10990 0 10990 0 10...      1\n",
       "923748   66653 0 65070 0 66515 5 10962 1 105 1 56807 42...      0\n",
       "2035328  66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...      0\n",
       "2239386  10991 0 23 105 73928 0 66560 0 66515 0 66551 0...      1\n",
       "2244533  10990 0 23 74 23 0 10990 1 73928 0 66500 0 665...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = jl.load(open('../../tmp/item_days_raw_data_.pkl', 'rb')).loc[labels.index, 'seq']\n",
    "df = pd.DataFrame(columns=['Seq', 'Class'], index=data.index)\n",
    "df.loc[:, 'Seq'] = data\n",
    "df.loc[:, 'Class'] = labels['CLASS']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate MBS items and timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in df.index:\n",
    "    _tmp = df.loc[idx, 'Seq'].split(' ')\n",
    "    df.loc[idx, 'mbs_seq'] = ' '.join(_tmp[::2])\n",
    "    df.loc[idx, 'times_seq'] = ' '.join(_tmp[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq</th>\n",
       "      <th>Class</th>\n",
       "      <th>mbs_seq</th>\n",
       "      <th>times_seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568483</th>\n",
       "      <td>10990 0 23 16 725 0 10990 0 10990 0 10990 0 10...</td>\n",
       "      <td>1</td>\n",
       "      <td>10990 23 725 10990 10990 10990 10993 23 85311 ...</td>\n",
       "      <td>0 16 0 0 0 0 0 15 0 0 13 0 0 0 22 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923748</th>\n",
       "      <td>66653 0 65070 0 66515 5 10962 1 105 1 56807 42...</td>\n",
       "      <td>0</td>\n",
       "      <td>66653 65070 66515 10962 105 56807 10990 23 109...</td>\n",
       "      <td>0 0 5 1 1 42 0 26 35 0 0 0 9 0 0 0 5 0 0 0 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035328</th>\n",
       "      <td>66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>66536 74995 66512 66551 66608 66716 66560 7392...</td>\n",
       "      <td>0 0 0 0 0 0 0 9 1 10 9 138 1 3 31 24 63 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239386</th>\n",
       "      <td>10991 0 23 105 73928 0 66560 0 66515 0 66551 0...</td>\n",
       "      <td>1</td>\n",
       "      <td>10991 23 73928 66560 66515 66551 66536 2517 10...</td>\n",
       "      <td>0 105 0 0 0 0 4 2 27 1 1 7 0 18 132 0 0 0 1 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244533</th>\n",
       "      <td>10990 0 23 74 23 0 10990 1 73928 0 66500 0 665...</td>\n",
       "      <td>1</td>\n",
       "      <td>10990 23 23 10990 73928 66500 66560 66551 23 1...</td>\n",
       "      <td>0 74 0 1 0 0 0 2 0 87 0 1 0 0 0 0 0 2 0 6 0 8 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Seq  Class  \\\n",
       "PIN                                                                 \n",
       "568483   10990 0 23 16 725 0 10990 0 10990 0 10990 0 10...      1   \n",
       "923748   66653 0 65070 0 66515 5 10962 1 105 1 56807 42...      0   \n",
       "2035328  66536 0 74995 0 66512 0 66551 0 66608 0 66716 ...      0   \n",
       "2239386  10991 0 23 105 73928 0 66560 0 66515 0 66551 0...      1   \n",
       "2244533  10990 0 23 74 23 0 10990 1 73928 0 66500 0 665...      1   \n",
       "\n",
       "                                                   mbs_seq  \\\n",
       "PIN                                                          \n",
       "568483   10990 23 725 10990 10990 10990 10993 23 85311 ...   \n",
       "923748   66653 65070 66515 10962 105 56807 10990 23 109...   \n",
       "2035328  66536 74995 66512 66551 66608 66716 66560 7392...   \n",
       "2239386  10991 23 73928 66560 66515 66551 66536 2517 10...   \n",
       "2244533  10990 23 23 10990 73928 66500 66560 66551 23 1...   \n",
       "\n",
       "                                                 times_seq  \n",
       "PIN                                                         \n",
       "568483   0 16 0 0 0 0 0 15 0 0 13 0 0 0 22 0 0 0 0 0 0 ...  \n",
       "923748   0 0 5 1 1 42 0 26 35 0 0 0 9 0 0 0 5 0 0 0 21 ...  \n",
       "2035328  0 0 0 0 0 0 0 9 1 10 9 138 1 3 31 24 63 0 0 0 ...  \n",
       "2239386  0 105 0 0 0 0 4 2 27 1 1 7 0 18 132 0 0 0 1 0 ...  \n",
       "2244533  0 74 0 1 0 0 0 2 0 87 0 1 0 0 0 0 0 2 0 6 0 8 ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773\n",
      "(11744, 445)\n"
     ]
    }
   ],
   "source": [
    "# Define tokenizer object\n",
    "tokenizer = Tokenizer(char_level=False, lower=False, split=' ')\n",
    "\n",
    "# Fit on corpus and extract tokenized sequences\n",
    "tokenizer.fit_on_texts(df['mbs_seq'])\n",
    "n_feat = len(tokenizer.word_index.keys())\n",
    "print(n_feat)\n",
    "seq = tokenizer.texts_to_sequences(df['mbs_seq'])\n",
    "\n",
    "# Pad tokenized sequences\n",
    "lengths = [len(x) for x in seq]\n",
    "maxlen = int(np.percentile(lengths, 95))\n",
    "p_seq = pad_sequences(seq, maxlen=maxlen)\n",
    "print(p_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11744, 445)\n"
     ]
    }
   ],
   "source": [
    "t_seq = [map(int, df.loc[idx, 'times_seq'].split(' ')) for idx in df.index]\n",
    "p_t_seq = pad_sequences(t_seq, maxlen=maxlen)\n",
    "print(p_t_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - Validation - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5872 learn / 5872 test\n",
      "5284 training / 588 validation\n"
     ]
    }
   ],
   "source": [
    "# Full dataset\n",
    "y = df['Class'].ravel()\n",
    "X = p_seq\n",
    "X_t = p_t_seq\n",
    "\n",
    "# Learn / Test\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "learn_idx, test_idx = next(sss.split(X, y))\n",
    "\n",
    "X_learn, y_learn = X[learn_idx, :], y[learn_idx]\n",
    "X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "X_learn_t = X_t[learn_idx, :]\n",
    "X_test_t = X_t[test_idx, :]\n",
    "\n",
    "print('{} learn / {} test'.format(len(y_learn), len(y_test)))\n",
    "\n",
    "# Training / Validation\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=1)\n",
    "train_idx, valid_idx = next(sss.split(X_learn, y_learn))\n",
    "\n",
    "X_train, y_train = X_learn[train_idx, :], y_learn[train_idx]\n",
    "X_valid, y_valid = X_learn[valid_idx, :], y_learn[valid_idx]\n",
    "\n",
    "X_train_t = X_learn_t[train_idx, :]\n",
    "X_valid_t = X_learn_t[valid_idx, :]\n",
    "\n",
    "print('{} training / {} validation'.format(len(y_train), len(y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 100\n",
    "embedding = pd.read_csv('../../tmp/embedding.{}d.csv'.format(D), header=0, index_col=0)\n",
    "embedding_matrix = embedding.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-Model: LSTM(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 443, 64)           256       \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import CuDNNLSTM, LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, 3, activation='relu', input_shape=(maxlen, 1)))\n",
    "model.add(LSTM(32, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5284 samples, validate on 588 samples\n",
      "Epoch 1/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6772 - acc: 0.5719 - val_loss: 0.6573 - val_acc: 0.6241\n",
      "Epoch 2/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6621 - acc: 0.6103 - val_loss: 0.6651 - val_acc: 0.6088\n",
      "Epoch 3/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6589 - acc: 0.6147 - val_loss: 0.6532 - val_acc: 0.6156\n",
      "Epoch 4/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6499 - acc: 0.6240 - val_loss: 0.6678 - val_acc: 0.6241\n",
      "Epoch 5/100\n",
      "5284/5284 [==============================] - 47s 9ms/step - loss: 0.6532 - acc: 0.6221 - val_loss: 0.6540 - val_acc: 0.6361\n",
      "Epoch 6/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6445 - acc: 0.6347 - val_loss: 0.6560 - val_acc: 0.6293\n",
      "Epoch 7/100\n",
      "5284/5284 [==============================] - 45s 8ms/step - loss: 0.6475 - acc: 0.6344 - val_loss: 0.6601 - val_acc: 0.6310\n",
      "Epoch 8/100\n",
      "5284/5284 [==============================] - 48s 9ms/step - loss: 0.6461 - acc: 0.6404 - val_loss: 0.6481 - val_acc: 0.6276\n",
      "Epoch 9/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6440 - acc: 0.6313 - val_loss: 0.6544 - val_acc: 0.6327\n",
      "Epoch 10/100\n",
      "5284/5284 [==============================] - 45s 8ms/step - loss: 0.6443 - acc: 0.6332 - val_loss: 0.6495 - val_acc: 0.6344\n",
      "Epoch 11/100\n",
      "5284/5284 [==============================] - 43s 8ms/step - loss: 0.6404 - acc: 0.6372 - val_loss: 0.6503 - val_acc: 0.6344\n",
      "Epoch 12/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6399 - acc: 0.6461 - val_loss: 0.6456 - val_acc: 0.6344\n",
      "Epoch 13/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6399 - acc: 0.6366 - val_loss: 0.6457 - val_acc: 0.6361\n",
      "Epoch 14/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6376 - acc: 0.6472 - val_loss: 0.6458 - val_acc: 0.6361\n",
      "Epoch 15/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6357 - acc: 0.6472 - val_loss: 0.6461 - val_acc: 0.6344\n",
      "Epoch 16/100\n",
      "5284/5284 [==============================] - 45s 9ms/step - loss: 0.6376 - acc: 0.6433 - val_loss: 0.6460 - val_acc: 0.6395\n",
      "Epoch 17/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6381 - acc: 0.6463 - val_loss: 0.6447 - val_acc: 0.6327\n",
      "Epoch 18/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6334 - acc: 0.6488 - val_loss: 0.6461 - val_acc: 0.6310\n",
      "Epoch 19/100\n",
      "5284/5284 [==============================] - 45s 9ms/step - loss: 0.6343 - acc: 0.6522 - val_loss: 0.6454 - val_acc: 0.6361\n",
      "Epoch 20/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6314 - acc: 0.6493 - val_loss: 0.6425 - val_acc: 0.6412\n",
      "Epoch 21/100\n",
      "5284/5284 [==============================] - 45s 9ms/step - loss: 0.6310 - acc: 0.6556 - val_loss: 0.6417 - val_acc: 0.6429\n",
      "Epoch 22/100\n",
      "5284/5284 [==============================] - 45s 8ms/step - loss: 0.6311 - acc: 0.6592 - val_loss: 0.6432 - val_acc: 0.6327\n",
      "Epoch 23/100\n",
      "5284/5284 [==============================] - 45s 8ms/step - loss: 0.6306 - acc: 0.6508 - val_loss: 0.6434 - val_acc: 0.6412\n",
      "Epoch 24/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6328 - acc: 0.6554 - val_loss: 0.6419 - val_acc: 0.6412\n",
      "Epoch 25/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6289 - acc: 0.6548 - val_loss: 0.6397 - val_acc: 0.6446\n",
      "Epoch 26/100\n",
      "5284/5284 [==============================] - 43s 8ms/step - loss: 0.6294 - acc: 0.6554 - val_loss: 0.6412 - val_acc: 0.6412\n",
      "Epoch 27/100\n",
      "5284/5284 [==============================] - 45s 9ms/step - loss: 0.6283 - acc: 0.6559 - val_loss: 0.6398 - val_acc: 0.6361\n",
      "Epoch 28/100\n",
      "5284/5284 [==============================] - 43s 8ms/step - loss: 0.6264 - acc: 0.6580 - val_loss: 0.6408 - val_acc: 0.6480\n",
      "Epoch 29/100\n",
      "5284/5284 [==============================] - 43s 8ms/step - loss: 0.6277 - acc: 0.6537 - val_loss: 0.6413 - val_acc: 0.6514\n",
      "Epoch 30/100\n",
      "5284/5284 [==============================] - 43s 8ms/step - loss: 0.6269 - acc: 0.6573 - val_loss: 0.6421 - val_acc: 0.6497\n",
      "Epoch 31/100\n",
      "5284/5284 [==============================] - 44s 8ms/step - loss: 0.6266 - acc: 0.6607 - val_loss: 0.6419 - val_acc: 0.6361\n",
      "Epoch 32/100\n",
      "5284/5284 [==============================] - 45s 9ms/step - loss: 0.6302 - acc: 0.6567 - val_loss: 0.6379 - val_acc: 0.6514\n",
      "Epoch 33/100\n",
      "5284/5284 [==============================] - 46s 9ms/step - loss: 0.6252 - acc: 0.6578 - val_loss: 0.6380 - val_acc: 0.6378\n",
      "Epoch 34/100\n",
      "5120/5284 [============================>.] - ETA: 1s - loss: 0.6230 - acc: 0.6648"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=15)] \n",
    "\n",
    "history = model.fit(X_train_t.reshape(5284, 445, 1), y_train,\n",
    "                    epochs=100,\n",
    "                    callbacks=callbacks,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_valid_t.reshape(588, 445, 1),\n",
    "                                     y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "t = history.epoch\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(t, history.history['loss'], label='loss', color='C0')\n",
    "plt.plot(t, history.history['val_loss'], label='val_loss', color='C1')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(t, history.history['acc'], label='acc', color='C2')\n",
    "plt.plot(t, history.history['val_acc'], label='val_acc', color='C3')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(loc=1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_t.reshape(5872, 445, 1), y_test)\n",
    "print('test_loss: {:1.4f} - test_acc: {:1.4f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
