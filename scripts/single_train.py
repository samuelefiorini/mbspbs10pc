#!/usr/bin/env python
"""Train bidirectional timestamp-guided attention model.

Train the keras model on the data extracted by `extract_sequences.py` and
matched by CEM (see `matching_step1.py` and `matching_step2.R`).
"""

from __future__ import print_function

import argparse
import os
import warnings
from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd
from keras import optimizers as opt
from keras.layers import CuDNNLSTM
from keras.utils import plot_model
from mbspbs10pc.fit_utils import concatenate_history, get_callbacks
from mbspbs10pc.model import build_model
from mbspbs10pc.plotting import (plot_confusion_matrix, plot_history,
                                 plot_roc_curve)
from mbspbs10pc.utils import (load_data_labels, tokenize,
                              train_validation_test_split)
from sklearn import metrics


def parse_arguments():
    """"Parse input arguments."""
    parser = argparse.ArgumentParser(description='Bi-Timestamp-guided model '
                                                 'training.')
    parser.add_argument('-l', '--labels', type=str,
                        help='Path to the labels csv file generated by '
                             '`matching_step2.R`.',
                        default=None)
    parser.add_argument('-d', '--data', type=str,
                        help='Path to the data pkl file generated by '
                        '`extract_sequences.py`.',
                        default=None)
    parser.add_argument('-e', '--embedding', type=str,
                        help='Path to the embedding matrix csv file.',
                        default=None)
    parser.add_argument('-o', '--output', type=str,
                        help='Ouput file name root.',
                        default=None)
    args = parser.parse_args()
    return args


def init_main():
    """Initialize the main routine."""
    args = parse_arguments()

    if args.labels is None or not os.path.exists(args.labels):
        raise ValueError('{} labels file not found'.format(args.labels))

    if args.data is None or not os.path.exists(args.data):
        raise ValueError('{} data file not found'.format(args.data))

    # Check output filename
    if args.output is None:
        args.output = 'out_' + str(datetime.now())

    return args


def fit_model(model, training_set, validation_set, outputfile,
              fine_tune_embedding=False):
    # Start training
    print('* Training model...')
    callbacks = get_callbacks(RLRP_patience=3, ES_patience=12,
                              MC_filepath=outputfile)

    history = model.fit(x=training_set[0], y=training_set[1],
                        epochs=100,
                        callbacks=callbacks,
                        batch_size=128,
                        validation_data=validation_set)

    if fine_tune_embedding:
        print(print('* Fine-tuning the embedding layer...'))
        # Fine-tune the embedding layers
        model.get_layer('mbs_embedding').trainable = True

        # Re-compile the model
        model.compile(optimizer=opt.RMSprop(lr=0.001),
                      loss='binary_crossentropy',
                      metrics=['acc'])

        callbacks = get_callbacks(RLRP_patience=5, ES_patience=10,
                                  MC_filepath=outputfile + '_finetuned')

        history_ft = model.fit(x=training_set[0], y=training_set[1],
                               epochs=200,
                               callbacks=callbacks,
                               batch_size=128,
                               validation_data=validation_set,
                               initial_epoch=history.epoch[-1])
        history = concatenate_history([history, history_ft])

    print('* Saving training history...', end=' ')
    plt.figure(dpi=100)
    plot_history(history)
    plt.savefig(outputfile + '_loss_history.png')
    print(u'\u2713')
    return model


def main():
    """Main train.py routine."""
    print('-------------------------------------------------------------------')
    print('MBS - PBS 10% dataset utility: single_train.py')
    print('-------------------------------------------------------------------')
    args = init_main()

    # Load data
    print('* Loading {} and {}...'.format(args.data, args.labels), end=' ')
    dataset = load_data_labels(args.data, args.labels)
    print(u'\u2713')

    # Load embedding matrix
    print('* Loading {}...'.format(args.embedding), end=' ')
    embedding_matrix = pd.read_csv(
        args.embedding, header=0, index_col=0).values
    print(u'\u2713')

    # Tokenize and pad
    print('* Preparing data...', end=' ')
    padded_mbs_seq, padded_timestamp_seq, _ = tokenize(dataset)
    maxlen = padded_mbs_seq.shape[1]

    # Split in training, validation, test sets
    tr_set, v_set, ts_set = train_validation_test_split(
        [padded_mbs_seq, padded_timestamp_seq], dataset['Class'],
        test_size=0.4, validation_size=0.1,
        verbose=False, random_state0=42, random_state1=420)
    print(u'\u2713')

    # Build the model
    print('* Building model...', end=' ')
    model = build_model(mbs_input_shape=(maxlen,),
                        timestamp_input_shape=(maxlen, 1),
                        vocabulary_size=embedding_matrix.shape[0],
                        embedding_size=embedding_matrix.shape[1],
                        recurrent_units=64,
                        dense_units=64,
                        bidirectional=True,
                        LSTMLayer=CuDNNLSTM)

    # Initialize the embedding matrix
    model.get_layer('mbs_embedding').set_weights([embedding_matrix])
    model.get_layer('mbs_embedding').trainable = True

    # Compile the model
    model.compile(optimizer=opt.RMSprop(lr=0.004),
                  loss='binary_crossentropy',
                  metrics=['acc'])
    print(u'\u2713')

    # Print the summary to file
    print('* Saving model summary and graph structure...', end=' ')
    filename = args.output + '_summary.txt'
    with open(filename, 'w') as f:
        model.summary(print_fn=lambda x: f.write(x + '\n'))

    # Save the model dotfile
    plot_model(model, show_shapes=True, to_file=args.output + '_dot.png')
    print(u'\u2713')

    # Fit the model
    # model = fit_model(model, tr_set, v_set, outputfile=args.output,
    #                   fine_tune_embedding=False)

    # Test set evaluation
    print('* Evaluate on test set...')
    model.load_weights(args.output + '_weights.h5')
    y_test = ts_set[1]
    y_pred = model.predict(ts_set[0]).ravel()

    # Plot non-normalized confusion matrix
    cnf_matrix = metrics.confusion_matrix(y_test, y_pred > 0.5)
    plt.figure(dpi=100)
    plot_confusion_matrix(cnf_matrix, classes=['METONLY', 'METX'],
                          title='Confusion matrix', cmap=plt.cm.Blues)
    plt.savefig(args.output + '_cm.png')

    # Save stats
    loss = metrics.log_loss(y_test, y_pred)
    acc = metrics.accuracy_score(y_test, y_pred > 0.5)
    prec = metrics.precision_score(y_test, y_pred > 0.5)
    rcll = metrics.recall_score(y_test, y_pred > 0.5)
    auc = metrics.roc_auc_score(y_test, y_pred)
    print('Test scores:\n * Log-Loss\t{:1.5f}\n * Accuracy:\t{:1.5f}\n '
          '* Precision:\t{:1.5f}\n * Recall:\t{:1.5f}\n * AUC:'
          '\t{:1.5f}'.format(loss, acc, prec, rcll, auc),
          file=open(args.output + '_stats.txt', 'w'))

    # Plot ROC curve
    plt.figure(dpi=100)
    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)
    plot_roc_curve([fpr], [tpr], [auc])
    plt.savefig(args.output + '_roc.png')

################################################################################


if __name__ == '__main__':
    warnings.filterwarnings('ignore')
    main()
